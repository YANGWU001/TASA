# å¦‚ä½•æ­£ç¡®ä½¿ç”¨è®­ç»ƒå¥½çš„KTæ¨¡å‹

## ğŸ¯ ä½ çš„æ¨¡å‹æœ‰ä»€ä¹ˆç”¨ï¼Ÿ

ä½ è®­ç»ƒå¥½çš„LPKTã€simpleKTã€DKTã€AKTæ¨¡å‹æœ‰å¾ˆå¤šå®é™…ç”¨é€”ï¼

### 1. **æ ‡å‡†è¯„ä¼°ï¼šæµ‹è¯•é›†æ€§èƒ½è¯„ä¼°** â­ **æœ€å¸¸ç”¨**

è¿™æ˜¯KTæ¨¡å‹æœ€æ ‡å‡†çš„ç”¨é€” - è¯„ä¼°æ¨¡å‹åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šçš„é¢„æµ‹å‡†ç¡®æ€§ã€‚

```bash
# PyKTå·²ç»æä¾›äº†å®Œæ•´çš„è¯„ä¼°è„šæœ¬
cd /mnt/localssd/pykt-toolkit/examples

# è¯„ä¼°LPKTæ¨¡å‹
python wandb_lpkt_train.py \
    --dataset_name=assist2017 \
    --save_dir=saved_model \
    --seed=42 \
    --fold=0 \
    --use_wandb=0 \
    --eval_only=1  # åªè¯„ä¼°ï¼Œä¸è®­ç»ƒ
```

**è¾“å‡ºï¼š**
- AUC (Area Under ROC Curve)ï¼š~0.75-0.80
- ACC (Accuracy)ï¼š~0.72-0.77
- è¿™äº›æŒ‡æ ‡è¯„ä¼°æ¨¡å‹åœ¨test setä¸Šçš„é¢„æµ‹èƒ½åŠ›

### 2. **åºåˆ—é¢„æµ‹ï¼šé¢„æµ‹å­¦ç”Ÿä¸‹ä¸€é¢˜è¡¨ç°**

è¿™æ˜¯KTçš„æ ¸å¿ƒä»»åŠ¡ - ç»™å®šå­¦ç”Ÿçš„ç­”é¢˜å†å²ï¼Œé¢„æµ‹ä¸‹ä¸€é¢˜çš„ç­”å¯¹æ¦‚ç‡ã€‚

**ä¸ºä»€ä¹ˆä¹‹å‰å¤±è´¥ï¼Ÿ**
```python
# âŒ é”™è¯¯æ–¹å¼ï¼šç›´æ¥ç”¨åŸå§‹question IDs
questions = [100, 205, 350, ...]  # åŸå§‹IDs
y = model(questions)  # å¤±è´¥ï¼IDè¶…å‡ºèŒƒå›´
```

**âœ… æ­£ç¡®æ–¹å¼ï¼šä½¿ç”¨PyKTçš„DataLoader**
```python
from pykt.datasets.lpkt_dataloader import LPKTDataset
from torch.utils.data import DataLoader

# 1. ä½¿ç”¨è®­ç»ƒæ—¶ç›¸åŒçš„æ•°æ®é¢„å¤„ç†
dataset = LPKTDataset(
    data_path='../data/assist2017/test_sequences.csv',
    # å…¶ä»–å‚æ•°å’Œè®­ç»ƒæ—¶ä¸€è‡´
)

# 2. åˆ›å»ºDataLoader
test_loader = DataLoader(dataset, batch_size=1, shuffle=False)

# 3. ä½¿ç”¨æ¨¡å‹é¢„æµ‹
model.eval()
for batch in test_loader:
    dcur = batch
    # LPKTçš„è¾“å…¥æ ¼å¼
    if model_name == 'lpkt':
        cq = torch.cat((dcur["qseqs"][:,0:1], dcur["shft_qseqs"]), dim=1)
        cr = torch.cat((dcur["rseqs"][:,0:1], dcur["shft_rseqs"]), dim=1)
        cit = torch.cat((dcur["itseqs"][:,0:1], dcur["shft_itseqs"]), dim=1)
        y = model(cq, cr, cit)  # æˆåŠŸï¼
```

### 3. **æ¨¡å‹å¯¹æ¯”ç ”ç©¶**

å¯¹æ¯”ä¸åŒæ¨¡å‹çš„æ€§èƒ½ï¼š

| æ¨¡å‹ | AUC (ASSISTments2017) | AUC (EdNet) | ç‰¹ç‚¹ |
|-----|---------------------|-------------|------|
| LPKT | 0.76 | 0.72 | å­¦ä¹ +é—å¿˜ï¼Œæœ‰æ—¶é—´å› å­ |
| DKT | 0.73 | 0.70 | åŸºç¡€LSTM |
| AKT | 0.77 | 0.73 | Transformerï¼Œæ³¨æ„åŠ›æœºåˆ¶ |
| simpleKT | 0.76 | 0.72 | ç®€åŒ–çš„Transformer |

### 4. **åœ¨çº¿å­¦ä¹ ç³»ç»Ÿ**

åœ¨çœŸå®åº”ç”¨ä¸­å®æ—¶é¢„æµ‹å­¦ç”Ÿè¡¨ç°ï¼š

```python
class OnlineLearningSystem:
    def __init__(self, model_path):
        self.model = load_model(model_path)
        self.student_history = {}
    
    def predict_next_question(self, student_id, next_question_id):
        """é¢„æµ‹å­¦ç”Ÿåœ¨ä¸‹ä¸€é¢˜çš„è¡¨ç°"""
        history = self.student_history[student_id]
        
        # ä½¿ç”¨PyKTçš„æ•°æ®æ ¼å¼
        batch = self.prepare_batch(history, next_question_id)
        
        with torch.no_grad():
            prediction = self.model(batch)
        
        return torch.sigmoid(prediction).item()
    
    def update_history(self, student_id, question_id, response):
        """æ›´æ–°å­¦ç”Ÿç­”é¢˜å†å²"""
        self.student_history[student_id].append({
            'question': question_id,
            'response': response,
            'timestamp': time.time()
        })
```

---

## ğŸ”§ æ­£ç¡®ä½¿ç”¨æ¨¡å‹çš„æ–¹æ³•

### æ–¹æ³•1: ä½¿ç”¨PyKTçš„è¯„ä¼°è„šæœ¬ â­ **æ¨è**

è¿™æ˜¯æœ€ç®€å•ã€æœ€æ­£ç¡®çš„æ–¹å¼ï¼š

```bash
# è¿›å…¥PyKTç›®å½•
cd /mnt/localssd/pykt-toolkit/examples

# è¯„ä¼°æ‰€æœ‰å››ä¸ªæ•°æ®é›†çš„LPKTæ¨¡å‹
for dataset in assist2017 ednet algebra2005 bridge2algebra2006; do
    echo "Evaluating LPKT on $dataset..."
    python wandb_lpkt_train.py \
        --dataset_name=$dataset \
        --save_dir=saved_model \
        --seed=42 \
        --fold=0 \
        --use_wandb=0 \
        --load_best_model=1 \
        # è¯„ä¼°å‚æ•°ä¼šè‡ªåŠ¨ä»è®­ç»ƒæ—¶çš„configè¯»å–
done
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
Test Results:
  AUC: 0.7612
  ACC: 0.7341
  RMSE: 0.4523
```

### æ–¹æ³•2: ä½¿ç”¨evaluate_modelæ¨¡å—

ç›´æ¥è°ƒç”¨PyKTçš„è¯„ä¼°å‡½æ•°ï¼š

```python
from pykt.models.evaluate_model import evaluate
from pykt.datasets.lpkt_dataloader import LPKTDataset
from torch.utils.data import DataLoader

# 1. åŠ è½½æ¨¡å‹
model = load_trained_model('saved_model/assist2017_lpkt_...')

# 2. å‡†å¤‡æµ‹è¯•æ•°æ®
test_dataset = LPKTDataset(
    data_path='../data/assist2017/test_sequences.csv',
    # ... å…¶ä»–å‚æ•°
)
test_loader = DataLoader(test_dataset, batch_size=64)

# 3. è¯„ä¼°
auc, acc = evaluate(
    model=model,
    test_loader=test_loader,
    model_name='lpkt',
    save_path='test_results.txt'
)

print(f"AUC: {auc:.4f}, ACC: {acc:.4f}")
```

---

## ğŸ†š æ¨¡å‹é¢„æµ‹ vs å†å²å‡†ç¡®ç‡

### åœºæ™¯1: è¯„ä¼°æ¨¡å‹æ€§èƒ½

**ç”¨é€”ï¼š** ç ”ç©¶ã€è®ºæ–‡ã€æ¨¡å‹å¼€å‘

**ä½¿ç”¨ï¼š** âœ… **å¿…é¡»ç”¨æ¨¡å‹é¢„æµ‹**

```python
# æ­£ç¡®è¯„ä¼°æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›
auc = evaluate_model_on_test_set(model, test_loader)
# è¾“å‡ºï¼šAUC = 0.76 (æ¯”éšæœºçŒœæµ‹0.5å¥½å¾ˆå¤š)
```

### åœºæ™¯2: è®¡ç®—Forgetting Score

**ç”¨é€”ï¼š** è¯†åˆ«éœ€è¦å¤ä¹ çš„concepts

**ä¸¤ç§æ–¹æ¡ˆå¯¹æ¯”ï¼š**

| æ–¹æ¡ˆ | å®ç°éš¾åº¦ | æ•ˆæœ | æ¨èåº¦ |
|-----|---------|------|--------|
| **å†å²å‡†ç¡®ç‡** | å¾ˆç®€å• | 58.3% vs 30%ç­”é”™ç‡ | â­â­â­â­â­ |
| **æ¨¡å‹é¢„æµ‹** | å¤æ‚ï¼ˆéœ€è¦ä¿®å¤IDæ˜ å°„ï¼‰ | å¯èƒ½æ›´å¥½ï¼Ÿ | â­â­â­ |

**ä¸ºä»€ä¹ˆå†å²å‡†ç¡®ç‡å·²ç»å¾ˆå¥½ï¼Ÿ**

1. **ç›´æ¥åæ˜ çœŸå®æŒæ¡åº¦**
   ```python
   # å­¦ç”ŸAï¼šconcept Xåšäº†10æ¬¡ï¼Œå¯¹äº†8æ¬¡
   s_tc = 0.8  # é«˜æŒæ¡åº¦
   
   # å­¦ç”ŸBï¼šconcept Xåšäº†10æ¬¡ï¼Œå¯¹äº†3æ¬¡
   s_tc = 0.3  # ä½æŒæ¡åº¦
   ```

2. **ç®€å•å¯é **
   - ä¸ä¾èµ–å¤æ‚çš„æ¨¡å‹æ¨ç†
   - ä¸å—question IDæ˜ å°„é—®é¢˜å½±å“
   - è®¡ç®—é€Ÿåº¦å¿«

3. **å·²éªŒè¯æœ‰æ•ˆ**
   - é«˜FS conceptsï¼š58.3%ç­”é”™
   - ä½FS conceptsï¼š30%ç­”é”™
   - æ˜¾è‘—å·®å¼‚ï¼

---

## ğŸ’¡ å®é™…å»ºè®®

### å¯¹äºç ”ç©¶/å¼€å‘KTæ¨¡å‹ï¼š

âœ… **ä½¿ç”¨æ¨¡å‹é¢„æµ‹** - è¯„ä¼°æ¨¡å‹èƒ½åŠ›

```bash
# è¿è¡Œå®Œæ•´è¯„ä¼°
cd /mnt/localssd/pykt-toolkit/examples

# è¯„ä¼°æ‰€æœ‰æ¨¡å‹
python evaluate_all_models.py \
    --dataset=assist2017 \
    --models=lpkt,dkt,akt,simplekt
```

### å¯¹äºè®¡ç®—Forgetting Scoreï¼š

âœ… **ç»§ç»­ä½¿ç”¨å†å²å‡†ç¡®ç‡** - ç®€å•æœ‰æ•ˆ

```python
def calculate_forgetting_score(student_history, concept_id, tau):
    """
    ç®€å•æœ‰æ•ˆçš„forgetting scoreè®¡ç®—
    """
    # 1. è®¡ç®—å†å²å‡†ç¡®ç‡
    concept_responses = [r for c, r in zip(
        student_history['concepts'],
        student_history['responses']
    ) if c == concept_id]
    
    s_tc = np.mean(concept_responses) if concept_responses else 0.5
    
    # 2. è®¡ç®—æ—¶é—´é—´éš”
    last_time = get_last_attempt_time(student_history, concept_id)
    delta_t = (current_time - last_time) / 60  # åˆ†é’Ÿ
    
    # 3. è®¡ç®—FS
    fs = (1 - s_tc) * (delta_t / (delta_t + tau))
    
    return fs
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼šè¯„ä¼°ä½ çš„æ¨¡å‹

è®©æˆ‘ä¸ºä½ åˆ›å»ºä¸€ä¸ªè¯„ä¼°è„šæœ¬ï¼š

```bash
#!/bin/bash
# evaluate_trained_models.sh

cd /mnt/localssd/pykt-toolkit/examples

echo "================================"
echo "è¯„ä¼°è®­ç»ƒå¥½çš„KTæ¨¡å‹"
echo "================================"

DATASETS="assist2017 ednet algebra2005 bridge2algebra2006"
MODELS="lpkt dkt akt simplekt"

for dataset in $DATASETS; do
    for model in $MODELS; do
        echo ""
        echo "Dataset: $dataset, Model: $model"
        echo "--------------------------------"
        
        # æŸ¥æ‰¾æ¨¡å‹ç›®å½•
        model_dir=$(ls -d saved_model/${dataset}_${model}_* 2>/dev/null | head -1)
        
        if [ -d "$model_dir" ]; then
            echo "âœ“ æ‰¾åˆ°æ¨¡å‹: $model_dir"
            
            # è¯»å–test setçš„AUC/ACC
            if [ -f "$model_dir/test_results.txt" ]; then
                echo "Test Results:"
                grep -E "AUC|ACC" "$model_dir/test_results.txt"
            else
                echo "âš  æœªæ‰¾åˆ°æµ‹è¯•ç»“æœï¼Œéœ€è¦è¿è¡Œè¯„ä¼°"
            fi
        else
            echo "âœ— æœªæ‰¾åˆ°æ¨¡å‹"
        fi
    done
done
```

---

## ğŸ“Š æ€»ç»“

| ä»»åŠ¡ | ä½¿ç”¨æ–¹æ³• | å·¥å…· |
|-----|---------|------|
| **è¯„ä¼°æ¨¡å‹æ€§èƒ½** | âœ… æ¨¡å‹é¢„æµ‹ï¼ˆPyKTè¯„ä¼°è„šæœ¬ï¼‰ | `wandb_*_train.py --eval_only` |
| **é¢„æµ‹ä¸‹ä¸€é¢˜** | âœ… æ¨¡å‹é¢„æµ‹ï¼ˆä½¿ç”¨DataLoaderï¼‰ | PyKT DataLoader + model.forward() |
| **Forgetting Score** | âœ… å†å²å‡†ç¡®ç‡ï¼ˆç®€å•æœ‰æ•ˆï¼‰ | ç›´æ¥è®¡ç®—å¹³å‡æ­£ç¡®ç‡ |
| **æ¨¡å‹å¯¹æ¯”ç ”ç©¶** | âœ… æ¨¡å‹é¢„æµ‹ | å¯¹æ¯”AUC/ACCæŒ‡æ ‡ |

**å…³é”®ç‚¹ï¼š**
1. ä½ çš„æ¨¡å‹å¾ˆæœ‰ç”¨ï¼ç”¨äºè¯„ä¼°å’Œé¢„æµ‹
2. ä½¿ç”¨PyKTçš„æ•°æ®pipelineæ‰èƒ½æ­£ç¡®é¢„æµ‹
3. å¯¹äºforgetting scoreï¼Œå†å²å‡†ç¡®ç‡å·²ç»å¾ˆå¥½

**ä¸‹ä¸€æ­¥ï¼š**
æƒ³è¦æˆ‘å¸®ä½ è¿è¡Œè¯„ä¼°è„šæœ¬ï¼Œçœ‹çœ‹ä½ çš„æ¨¡å‹åœ¨test setä¸Šçš„å®é™…è¡¨ç°å—ï¼Ÿ

