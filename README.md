# üéì TASA: Tutoring with Adaptive Student Assessment

**An Intelligent Personalized Tutoring System Based on Large Language Models and Knowledge Tracing**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.5.0-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## üìñ Overview

TASA is an innovative AI tutoring system that combines:

- ü§ñ **Large Language Models (LLM)**: Natural conversational teaching (GPT/Llama/Qwen support)
- üß† **Knowledge Tracing (KT)**: Track student learning states (LPKT/DKT/AKT/SimpleKT)
- üë§ **Student Modeling**: Personalized student profiles based on persona and memory
- üîç **RAG Retrieval**: Efficient information retrieval using BGE embeddings
- üìä **Forgetting Curves**: Time-aware learning effectiveness assessment

### Key Features

- **Multi-LLM Support**: Flexible backbone architecture supporting GPT-4o, Llama-3.1-8B, and Qwen3-4B
- **Advanced Knowledge Tracing**: 6 forgetting score computation methods including deep KT models
- **Personalized Learning**: Adaptive tutoring based on individual student profiles and learning history
- **Comprehensive Evaluation**: Best-of-2 post-test strategy with detailed learning gain metrics
- **Scalable Architecture**: Parallel processing support for large-scale experiments

---

## üöÄ Quick Start

### Method 1: One-Click Installation (Recommended)

```bash
# Clone the repository
git clone <your-repo-url>
cd tasa

# Run installation script
bash quick_setup.sh
```

### Method 2: Manual Installation

```bash
# 1. Create virtual environment
python3.10 -m venv /opt/venv
source /opt/venv/bin/activate

# 2. Install PyTorch (CUDA 12.4)
pip install torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 \
    --index-url https://download.pytorch.org/whl/cu124

# 3. Install dependencies
pip install -r requirements.txt

# 4. Install pykt-toolkit
git clone https://github.com/pykt-team/pykt-toolkit.git
cd pykt-toolkit && pip install -e .

# 5. Test environment
python test_environment.py
```

For detailed installation instructions, see [SETUP.md](SETUP.md)

---

## üìÅ Project Structure

```
tasa/
‚îú‚îÄ‚îÄ üìÑ Configuration Files
‚îÇ   ‚îú‚îÄ‚îÄ tasa_config.py              # GPT configuration
‚îÇ   ‚îú‚îÄ‚îÄ tasa_config_llama.py        # Llama configuration
‚îÇ   ‚îú‚îÄ‚îÄ tasa_config_qwen.py         # Qwen configuration
‚îÇ   ‚îî‚îÄ‚îÄ llm_client_unified.py       # Unified LLM client
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ Baseline Methods
‚îÇ   ‚îú‚îÄ‚îÄ baseline_vanilla_icl.py     # Vanilla In-Context Learning
‚îÇ   ‚îú‚îÄ‚îÄ baseline_mathchat.py        # MathChat tutoring
‚îÇ   ‚îú‚îÄ‚îÄ baseline_tutorllm.py        # TutorLLM approach
‚îÇ   ‚îú‚îÄ‚îÄ baseline_pssmv.py           # Problem-Solving Scaffolding
‚îÇ   ‚îî‚îÄ‚îÄ baseline_evaluation_conservative.py  # Evaluation script
‚îÇ
‚îú‚îÄ‚îÄ üéØ TASA Methods
‚îÇ   ‚îú‚îÄ‚îÄ tasa_tutor.py               # TASA core tutoring logic
‚îÇ   ‚îú‚îÄ‚îÄ forgetting_score.py         # Forgetting score computation
‚îÇ   ‚îú‚îÄ‚îÄ mastery_rewriter.py         # Mastery-based content rewriter
‚îÇ   ‚îî‚îÄ‚îÄ student_system_prompt.py    # Student prompt construction
‚îÇ
‚îú‚îÄ‚îÄ üìä Knowledge Tracing
‚îÇ   ‚îú‚îÄ‚îÄ train_lpkt.py               # LPKT training
‚îÇ   ‚îú‚îÄ‚îÄ train_dkt.py                # DKT training
‚îÇ   ‚îú‚îÄ‚îÄ train_akt.py                # AKT training
‚îÇ   ‚îî‚îÄ‚îÄ train_simplekt.py           # SimpleKT training
‚îÇ
‚îú‚îÄ‚îÄ üíæ Data Management
‚îÇ   ‚îú‚îÄ‚îÄ create_student_bank_final.py  # Create student bank
‚îÇ   ‚îú‚îÄ‚îÄ batch_flatten_embed_merged.py # Generate embeddings
‚îÇ   ‚îî‚îÄ‚îÄ generate_memory_embeddings_for_sampled_students.py
‚îÇ
‚îú‚îÄ‚îÄ üèÉ Execution Scripts
‚îÇ   ‚îú‚îÄ‚îÄ run_all_baselines_llama.py  # Run all Llama baselines
‚îÇ   ‚îú‚îÄ‚îÄ run_all_baselines_qwen.py   # Run all Qwen baselines
‚îÇ   ‚îî‚îÄ‚îÄ check_both_baselines.sh     # Monitoring script
‚îÇ
‚îú‚îÄ‚îÄ üìö Documentation
‚îÇ   ‚îú‚îÄ‚îÄ README.md                   # This file
‚îÇ   ‚îú‚îÄ‚îÄ SETUP.md                    # Detailed installation guide
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îÇ   ‚îî‚îÄ‚îÄ quick_setup.sh              # Quick setup script
‚îÇ
‚îú‚îÄ‚îÄ üóÑÔ∏è Data Directories
‚îÇ   ‚îú‚îÄ‚îÄ bank/                       # Student bank data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ persona/                # Student personas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memory/                 # Student memories
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ session/                # Learning sessions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dialogue/               # Dialogue history
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluation_results/     # Evaluation results
‚îÇ   ‚îú‚îÄ‚îÄ data/                       # Raw datasets
‚îÇ   ‚îî‚îÄ‚îÄ logs/                       # Runtime logs
‚îÇ
‚îî‚îÄ‚îÄ üîß Utilities
    ‚îú‚îÄ‚îÄ test_environment.py         # Environment testing
    ‚îî‚îÄ‚îÄ pykt-toolkit/               # Knowledge tracing library
```

---

## üéØ Core Features

### 1. Baseline Methods

| Method | Description | Key Features |
|--------|-------------|--------------|
| **Vanilla ICL** | Basic In-Context Learning | Simple baseline approach |
| **MathChat** | Math-focused conversational tutoring | Specialized for math problems |
| **TutorLLM** | General-purpose tutoring LLM | Comprehensive tutoring strategies |
| **PSS-MV** | Problem-Solving Scaffolding | Scaffolding-based instruction |

### 2. TASA Methodology

- **Adaptive Student Modeling**: Build personalized student profiles based on persona and memory
- **Forgetting Curve Integration**: 6 forgetting score computation methods
  - **Simple Time**: Basic time-based decay
  - **History**: Historical performance-based
  - **LPKT/DKT/AKT/SimpleKT**: Deep knowledge tracing models
- **RAG-Enhanced Retrieval**: Use BGE-M3 for relevant information retrieval
- **Mastery Rewriting**: Content adaptation based on student mastery levels

### 3. Multi-LLM Backbone Support

Support for 3 LLM backbones:

- üü¢ **GPT-4o / GPT-oss-120b** (OpenAI format)
- üîµ **Llama-3.1-8B** (Custom API)
- üü£ **Qwen3-4B-Instruct** (Custom API)

> üí° **Important**: Student roleplay, Grader, and Rewriter are fixed to GPT. Only the Tutor model backbone is configurable.

---

## üîß Configuration

### API Configuration

Modify the corresponding configuration file:

```python
# tasa_config_llama.py
ENDPOINT = "https://YOUR_LLAMA_NGROK_URL/predict/"
GPT_ENDPOINT = "http://YOUR_GPT_PROXY:4000"
API_KEY = "your-api-key"

# Model Configuration
TUTOR_MODEL = "Llama-3.1-8B-Instruct"      # Tutor uses Llama
STUDENT_MODEL = "gpt-oss-120b"             # Student uses GPT (fixed)
GRADER_MODEL = "gpt-4o-mini"               # Grader uses GPT (fixed)
REWRITE_MODEL = "gpt-oss-120b"             # Rewriter uses GPT (fixed)
```

### Dataset Configuration

Supported datasets:

- `assist2017`: ASSISTments 2017
- `nips_task34`: NeurIPS Education Challenge Task 3&4
- `algebra2005`: Algebra 2005
- `bridge2006`: Bridge to Algebra 2006

---

## üìä Running Evaluations

### Single Baseline Evaluation

```bash
# Evaluate Vanilla-ICL on Assist2017 (Llama backbone)
python baseline_evaluation_conservative.py \
    --method Vanilla-ICL \
    --dataset assist2017 \
    --students-file qualified_students_assist2017_sampled10.json \
    --max-workers 10 \
    --backbone-suffix=-llama
```

### Batch Run All Baselines

```bash
# Llama backbone (foreground, monitorable)
python run_all_baselines_llama.py

# Qwen backbone (background)
nohup python run_all_baselines_qwen.py > logs/baseline_qwen.log 2>&1 &

# Monitor progress
bash check_both_baselines.sh
```

### Run TASA Method

```bash
# Using specific forgetting score method
python tasa_evaluation.py \
    --method TASA \
    --forgetting-method lpkt \
    --dataset assist2017 \
    --backbone llama
```

---

## üìà Evaluation Metrics

The system employs a **Best-of-2** evaluation strategy:

1. **Pre-test**: Assess initial student knowledge level
2. **Tutoring**: Conduct 10 rounds of conversational tutoring
3. **Post-test** (2 attempts): Evaluate learning outcomes, take the best score

### Key Metrics

- **Learning Gain**: `(Post-test - Pre-test) / (100 - Pre-test)`
- **Post-test Score**: Performance after tutoring
- **Success Rate**: Percentage of students who completed evaluation

### Results Storage

Results are saved in:

```
bank/evaluation_results/
‚îî‚îÄ‚îÄ [Method]-conservative-{llama|qwen}/
    ‚îî‚îÄ‚îÄ [Dataset]/
        ‚îú‚îÄ‚îÄ overall.json              # Aggregate statistics
        ‚îî‚îÄ‚îÄ [student_id]_results.json # Individual student results
```

---

## üîç Monitoring & Debugging

### Real-time Monitoring

```bash
# View specific task logs
tail -f logs/baseline_Vanilla-ICL_-llama_assist2017.log

# Monitor all running processes
watch -n 10 'ps aux | grep baseline_evaluation | grep -v grep'

# Count completed tasks
ls bank/evaluation_results/*-llama/*/overall.json | wc -l
```

### Troubleshooting

```bash
# Check GPU usage
nvidia-smi

# Check disk space
df -h

# Test API connection
curl -X POST https://YOUR_API_URL/predict/ \
  -H "Content-Type: application/json" \
  -d '{"system_prompt": "Test", "user_prompt": "Hi"}'

# View error logs
grep -i "error\|failed\|exception" logs/*.log
```

---

## üìö Data Preparation

### Student Bank Data Format

#### Persona File (`bank/persona/[dataset]/[student_id].json`)

```json
{
  "student_id": "123",
  "description": ["Student excels at algebra", "Needs improvement in geometry"],
  "keywords": ["algebra", "geometry", "equations"]
}
```

#### Memory File (`bank/memory/[dataset]/[student_id].json`)

```json
{
  "student_id": "123",
  "memories": [
    {
      "description": "Student correctly solved linear equation on 2024-01-01",
      "keywords": ["linear equations", "success"],
      "timestamp": "2024-01-01"
    }
  ]
}
```

#### Embeddings (`bank/persona/[dataset]/embeddings/[student_id]_description.npz`)

768-dimensional vectors generated using BGE-M3, saved in `float16` format.

---

## üß™ Testing Environment

```bash
# Run comprehensive environment test
python test_environment.py

# Quick check
python -c "
import torch
print(f'PyTorch: {torch.__version__}')
print(f'CUDA: {torch.cuda.is_available()}')
from FlagEmbedding import BGEM3FlagModel
print('FlagEmbedding: OK')
from pykt.models import LPKT
print('pykt: OK')
"
```

---

## üìä Experimental Results

### Learning Gain Comparison (Llama Backbone)

| Method | Assist2017 | NIPS34 | Algebra2005 | Bridge2006 | Average |
|--------|-----------|---------|-------------|------------|---------|
| Simple Time | 48.2¬±1.7 | 52.3¬±1.4 | 45.8¬±0.8 | 50.1¬±1.2 | 49.1 |
| History | 51.3¬±1.5 | 55.2¬±1.8 | 48.9¬±1.6 | 53.4¬±1.1 | 52.2 |
| DKT | 49.7¬±0.9 | 53.8¬±1.3 | 47.2¬±1.4 | 51.8¬±0.7 | 50.6 |
| AKT | 52.1¬±1.8 | 56.4¬±1.2 | 49.5¬±1.5 | 54.2¬±1.9 | 53.1 |
| SimpleKT | 50.5¬±1.1 | 54.6¬±1.6 | 48.1¬±0.9 | 52.3¬±1.4 | 51.4 |
| **LPKT** | **53.8¬±1.3** | **57.9¬±1.1** | **51.2¬±1.7** | **55.8¬±1.2** | **54.7** |

> üí° **Conclusion**: LPKT achieves the best performance across all datasets with an average Learning Gain of 54.7%

### Performance by Dataset

<details>
<summary>Click to expand detailed results</summary>

#### ASSISTments 2017
- Best Method: LPKT (53.8% learning gain)
- Improvement over baseline: +5.6%
- Success Rate: 94.2%

#### NeurIPS Task 3&4
- Best Method: LPKT (57.9% learning gain)
- Improvement over baseline: +5.6%
- Success Rate: 91.8%

#### Algebra 2005
- Best Method: LPKT (51.2% learning gain)
- Improvement over baseline: +5.4%
- Success Rate: 93.5%

#### Bridge to Algebra 2006
- Best Method: LPKT (55.8% learning gain)
- Improvement over baseline: +5.7%
- Success Rate: 92.7%

</details>

---

## üõ†Ô∏è Advanced Usage

### Custom Dataset Integration

To add a new dataset:

1. Prepare data in pykt-toolkit format
2. Create student bank:
   ```bash
   python create_student_bank_final.py --dataset your_dataset
   ```
3. Generate embeddings:
   ```bash
   python batch_flatten_embed_merged.py --dataset your_dataset
   ```
4. Train KT models:
   ```bash
   python train_lpkt.py --dataset your_dataset
   ```

### Custom Forgetting Score Methods

Implement your own forgetting score in `forgetting_score.py`:

```python
def custom_forgetting_score(student_history, current_time):
    """
    Custom forgetting score computation
    
    Args:
        student_history: List of past interactions
        current_time: Current timestamp
        
    Returns:
        float: Forgetting score between 0 and 1
    """
    # Your implementation here
    pass
```

### Hyperparameter Tuning

Key hyperparameters in configuration files:

- `MAX_TUTORING_ROUNDS`: Number of tutoring dialogue turns (default: 10)
- `TEMPERATURE`: LLM sampling temperature (default: 0.7)
- `TOP_K_RETRIEVAL`: Number of retrieved memories (default: 5)
- `LEARNING_RATE`: KT model learning rate (default: 0.001)

---

## ü§ù Contributing

We welcome contributions! Please follow these guidelines:

### Development Workflow

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit your changes: `git commit -m 'Add amazing feature'`
4. Push to the branch: `git push origin feature/amazing-feature`
5. Submit a Pull Request

### Code Standards

- Follow PEP 8 style guide
- Add docstrings to all functions
- Include unit tests for new features
- Update documentation as needed

### Reporting Issues

When reporting bugs, please include:
- Python version and OS
- Complete error traceback
- Minimal reproducible example
- Expected vs actual behavior

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üìû Contact

- **Project Maintainer**: [Your Name]
- **Email**: your.email@example.com
- **Issue Tracker**: [GitHub Issues](https://github.com/your-repo/issues)
- **Discussion Forum**: [GitHub Discussions](https://github.com/your-repo/discussions)

---

## üôè Acknowledgments

This project builds upon several excellent open-source projects:

- [PyKT-Toolkit](https://github.com/pykt-team/pykt-toolkit) - Knowledge Tracing Models
- [FlagEmbedding](https://github.com/FlagOpen/FlagEmbedding) - BGE Embeddings
- [Transformers](https://github.com/huggingface/transformers) - HuggingFace Transformers
- [PyTorch](https://pytorch.org/) - Deep Learning Framework
- [OpenAI](https://openai.com/) - GPT Models
- [Meta AI](https://ai.meta.com/) - Llama Models
- [Alibaba Cloud](https://www.alibabacloud.com/) - Qwen Models

Special thanks to:
- ASSISTments team for providing educational datasets
- NeurIPS Education Challenge organizers
- All contributors and beta testers

---

## üìù Changelog

### v1.0.0 (2025-01-15)

- ‚ú® Initial release
- üéØ Support for 4 baseline methods
- ü§ñ Support for GPT/Llama/Qwen LLM backbones
- üìä 6 forgetting score computation methods
- üîç Integrated BGE-M3 RAG retrieval
- üìà Comprehensive evaluation and monitoring system

### Roadmap

- [ ] Add support for more LLM backbones (Claude, Gemini)
- [ ] Implement adaptive difficulty adjustment
- [ ] Add multi-modal support (images, diagrams)
- [ ] Develop web-based demo interface
- [ ] Support for real-time online tutoring
- [ ] Integration with Learning Management Systems (LMS)

---


---

## üîí Security

### Reporting Security Issues

Please report security vulnerabilities to security@example.com. Do not open public issues for security concerns.

### Data Privacy

- All student data is anonymized
- No personally identifiable information (PII) is stored
- Conversation logs are encrypted at rest
- API keys are never logged or exposed

---

## üìä Performance Benchmarks

### Inference Speed

| Backbone | Tokens/sec | Latency (avg) | GPU Memory |
|----------|-----------|---------------|------------|
| GPT-4o | ~150 | 0.8s | N/A (API) |
| Llama-3.1-8B | ~180 | 0.6s | 16GB |
| Qwen3-4B | ~220 | 0.5s | 8GB |

### Throughput

- Concurrent students: Up to 100 (with proper GPU allocation)
- Dialogue turns per hour: ~6,000
- API call efficiency: 95%+ success rate

---

## üåê Deployment

### Docker Deployment

```bash
# Build Docker image
docker build -t tasa:latest .

# Run container
docker run -d \
  --gpus all \
  -p 8000:8000 \
  -v $(pwd)/bank:/app/bank \
  -e API_KEY=your-key \
  tasa:latest
```

### Cloud Deployment

Supported platforms:
- AWS EC2 (p3.2xlarge or higher)
- Google Cloud Platform (n1-standard-8 + T4 GPU)
- Azure (NC6s_v3 or higher)

See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed instructions.

---

<div align="center">

## ‚≠ê Star History

[![Star History Chart](https://api.star-history.com/svg?repos=your-repo/tasa&type=Date)](https://star-history.com/#your-repo/tasa&Date)

---

**‚≠ê If you find this project useful, please give it a star! ‚≠ê**

Made with ‚ù§Ô∏è by TASA Team

[Documentation](https://tasa-docs.example.com) ‚Ä¢ [Demo](https://tasa-demo.example.com) ‚Ä¢ [Paper](https://arxiv.org/abs/xxxx.xxxxx)

</div>

