# Multi-Backbone Experiment Plan

## ğŸ“‹ å®éªŒæ¦‚è§ˆ

### ç›®æ ‡
1. æµ‹è¯•ä¸åŒForgetting Score Methodå¯¹TASAæ•ˆæœçš„å½±å“
2. åœ¨Llama-3.1-8Bå’ŒQwen3-4Bä¸Šè¿è¡ŒTASAå’ŒBaselines
3. å¯¹æ¯”GPT-OSS-120Bã€Llamaã€Qwenä¸‰ç§backboneçš„æ•ˆæœ

### å®éªŒé…ç½®
- **Datasets**: assist2017, algebra2005, bridge2006, nips_task34
- **TASA Backbones**: gpt-oss-120b, llama-3.1-8b, qwen3-4b
- **Baseline Methods**: Vanilla-ICL, MathChat, TutorLLM, PSS-MV
- **Forgetting Score Methods**: simple_time, history, lpkt, dkt, akt, simplekt
- **Max Workers**: TASA=30, Baselines=40

## ğŸ”§ å·²åˆ›å»ºçš„æ–‡ä»¶

### 1. `/mnt/localssd/llm_client.py`
**ä½œç”¨**: ç»Ÿä¸€çš„LLMå®¢æˆ·ç«¯æ¥å£
- æ”¯æŒGPTã€Llamaã€Qwenä¸‰ç§backbone
- è‡ªåŠ¨å¤„ç†ä¸åŒAPIæ ¼å¼
- ç»Ÿä¸€çš„chat_completionæ¥å£

### 2. `/mnt/localssd/tasa_config.py` (å·²ä¿®æ”¹)
**æ–°å¢é…ç½®**:
```python
FORGETTING_SCORE_METHOD = "simple_time"  # å¯é€‰: history, lpkt, dkt, akt, simplekt
```

### 3. `/mnt/localssd/tasa_rewrite.py` (å·²ä¿®æ”¹)
**æ”¹è¿›**:
- æ”¯æŒä»sessionçš„methodsä¸­è¯»å–å¯¹åº”methodçš„FSå€¼å’Œlevel
- Levelæ˜ å°„: medium â†’ moderate
- Promptæ›´æ–°: è¯´æ˜FSèŒƒå›´(0-1)å’Œå«ä¹‰(è¶Šå¤§è¶Šé—å¿˜)

**Promptç¤ºä¾‹**:
```
Forgetting Score: 0.3294 (range: 0-1, where higher values indicate more forgetting)
Forgetting Level: moderate - moderate (some knowledge retained)
```

### 4. `/mnt/localssd/test_forgetting_methods.py`
**ä½œç”¨**: æµ‹è¯•ä¸åŒFS methodåœ¨llamaä¸Šçš„æ•ˆæœ
- è‡ªåŠ¨æµ‹è¯•6ç§FS method
- åœ¨æ‰€æœ‰4ä¸ªdatasetä¸Šè¿è¡Œ
- è‡ªåŠ¨é€‰å‡ºæœ€å¥½çš„method
- ä¿å­˜ç»“æœåˆ°`best_forgetting_method.txt`

### 5. `/mnt/localssd/run_all_experiments_with_backbones.py`
**ä½œç”¨**: Masterå®éªŒè„šæœ¬
**æµç¨‹**:
1. å¤‡ä»½æ—§çš„GPT-OSS-120Bç»“æœ
2. åœ¨llamaä¸Šæµ‹è¯•æ‰€æœ‰FS method
3. é€‰å‡ºæœ€å¥½çš„FS method
4. ç”¨æœ€å¥½çš„methodè¿è¡Œæ‰€æœ‰å®éªŒ:
   - GPT-OSS-120B (é‡æ–°è·‘ï¼Œä½¿ç”¨æ–°çš„FS method)
   - Llama-3.1-8B
   - Qwen3-4B
5. ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š

## ğŸ“Š Forgetting Scoreè¯¦è§£

### å½“å‰å®ç° (å·²ä¿®æ”¹)

**Methodæ•°æ®æ ¼å¼** (æ¥è‡ªsession):
```json
{
  "history": {
    "s_tc": 0.6667,
    "fs": 0.3294,      // Forgetting Score: 0-1
    "level": "medium"  // low/medium/high
  },
  "lpkt": {...},
  "dkt": {...},
  "akt": {...},
  "simplekt": {...}
}
```

**ä½¿ç”¨æ–¹å¼**:
- **æ•°å€¼**: ç›´æ¥ä½¿ç”¨methodçš„`fs`å€¼ï¼ˆ0-1èŒƒå›´ï¼Œè¶Šå¤§è¶Šé—å¿˜ï¼‰
- **Level**: ä½¿ç”¨methodçš„`level`ï¼Œæ˜ å°„mediumâ†’moderate
- **Prompt**: åŒæ—¶æä¾›æ•°å€¼å’Œlevel

**Levelæ˜ å°„**:
- Method: `low`, `medium`, `high`
- TASA: `low`, `moderate`, `high`
- æ˜ å°„: `medium` â†’ `moderate`

### Simple Time Method (æ—§ç‰ˆæœ¬)
```python
forgetting_score = 1 - 1 / (1 + delta_t_days / 7)
```
- åªä¾èµ–æ—¶é—´
- ä¸è€ƒè™‘å­¦ä¹ è´¨é‡
- 7å¤©åŠè¡°æœŸ

## ğŸš€ æ‰§è¡Œæµç¨‹

### ç­‰PSS-MVå®Œæˆåæ‰§è¡Œ

#### Step 1: å¤‡ä»½å½“å‰GPTç»“æœ
```bash
# è‡ªåŠ¨æ‰§è¡Œï¼Œå¤‡ä»½åˆ°å¸¦æ—¶é—´æˆ³çš„ç›®å½•
/mnt/localssd/bank/evaluation_results/TASA-best-of-2_OLD_simple_time_YYYYMMDD_HHMMSS/
```

#### Step 2: æµ‹è¯•FS Methods (Llama)
```bash
python3 /mnt/localssd/test_forgetting_methods.py
```
**è¾“å‡º**:
- `forgetting_method_comparison_llama-3.1-8b.json`: è¯¦ç»†ç»“æœ
- `best_forgetting_method.txt`: æœ€å¥½çš„methodåç§°

#### Step 3: è¿è¡Œæ‰€æœ‰å®éªŒ
```bash
python3 /mnt/localssd/run_all_experiments_with_backbones.py
```

## ğŸ“ ç»“æœå­˜å‚¨ç»“æ„

**æ–°çš„å‘½åè§„åˆ™**ï¼šæ ¹æ®backboneæ˜ç¡®æ ‡æ³¨

```
/mnt/localssd/bank/evaluation_results/
# TASAç»“æœ
â”œâ”€â”€ TASA-best-of-2/                    # GPT-OSS-120B (é»˜è®¤ï¼Œä¸å¸¦æ ‡æ³¨)
â”œâ”€â”€ TASA-best-of-2_OLD_simple_time_*/  # GPT (æ—§ç‰ˆæœ¬å¤‡ä»½)
â”œâ”€â”€ TASA-llama-best-of-2/              # Llama-3.1-8B
â”œâ”€â”€ TASA-qwen-best-of-2/               # Qwen3-4B

# Baselineç»“æœ (GPT-OSS-120Bï¼Œé»˜è®¤ä¸å¸¦æ ‡æ³¨)
â”œâ”€â”€ Vanilla-ICL-conservative/
â”œâ”€â”€ MathChat-conservative/
â”œâ”€â”€ TutorLLM-conservative/
â”œâ”€â”€ PSS-MV-conservative/

# Baselineç»“æœ (Llama-3.1-8B)
â”œâ”€â”€ Vanilla-ICL-llama-conservative/
â”œâ”€â”€ MathChat-llama-conservative/
â”œâ”€â”€ TutorLLM-llama-conservative/
â”œâ”€â”€ PSS-MV-llama-conservative/

# Baselineç»“æœ (Qwen3-4B)
â”œâ”€â”€ Vanilla-ICL-qwen-conservative/
â”œâ”€â”€ MathChat-qwen-conservative/
â”œâ”€â”€ TutorLLM-qwen-conservative/
â””â”€â”€ PSS-MV-qwen-conservative/
```

**å‘½åè§„åˆ™è¯´æ˜**ï¼š
- **GPT-OSS-120B**: ä¸å¸¦æ ‡æ³¨ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
- **Llama-3.1-8B**: æ·»åŠ `-llama`åç¼€
- **Qwen3-4B**: æ·»åŠ `-qwen`åç¼€
- å…¶ä»–æ¨¡å‹: æ·»åŠ `-{backbone}`åç¼€

## â±ï¸ é¢„è®¡æ—¶é—´

### å•ä¸ªDataset (ä»¥assist2017ä¸ºä¾‹ï¼Œ189å­¦ç”Ÿ)
- **TASA (1æ¬¡)**: ~30åˆ†é’Ÿ (max_workers=30)
- **Baseline (1ä¸ªmethod)**: ~31åˆ†é’Ÿ (max_workers=40)

### æ€»æ—¶é—´ä¼°ç®—
1. **æµ‹è¯•FS Methods** (llama, 6 methods Ã— 4 datasets): ~12å°æ—¶
2. **TASA All Backbones** (3 backbones Ã— 4 datasets): ~6å°æ—¶
3. **Baselines All Backbones** (3 backbones Ã— 4 methods Ã— 4 datasets): ~24å°æ—¶

**æ€»è®¡**: ~42å°æ—¶

## ğŸ“ˆ é¢„æœŸè¾“å‡º

### 1. FS Methodå¯¹æ¯”æŠ¥å‘Š
```json
{
  "simple_time": {"avg_gain": 0.34},
  "history": {"avg_gain": 0.36},
  "lpkt": {"avg_gain": 0.35},
  "dkt": {"avg_gain": 0.37},  // â† å‡è®¾æœ€å¥½
  "akt": {"avg_gain": 0.35},
  "simplekt": {"avg_gain": 0.33}
}
```

### 2. Backboneå¯¹æ¯”æŠ¥å‘Š
```json
{
  "gpt-oss-120b": {
    "TASA": {"assist2017": 0.419, ...},
    "Baselines": {...}
  },
  "llama-3.1-8b": {...},
  "qwen3-4b": {...}
}
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **Baselineä¸ä¾èµ–FS Method**: Baselineåªæ”¹TUTOR_MODEL
2. **GPTéœ€è¦é‡è·‘**: æ—§ç‰ˆæœ¬ç”¨çš„æ˜¯simple_timeï¼Œæ–°ç‰ˆæœ¬ç”¨æœ€å¥½çš„method
3. **API URLs**: Llamaå’ŒQwenéœ€è¦ç¡®ä¿ngrok URLså¯ç”¨
4. **å¹¶å‘æ§åˆ¶**: TASA=30, Baselines=40ï¼Œé¿å…APIé™æµ
5. **é”™è¯¯å¤„ç†**: å¦‚æœæŸä¸ªmethodä¸å­˜åœ¨ï¼Œè‡ªåŠ¨fallbackåˆ°simple_time

## âœ… TODO

- [x] åˆ›å»ºLLM Client
- [x] ä¿®æ”¹TASA Configæ”¯æŒFS Method
- [x] ä¿®æ”¹TASA Rewriteä½¿ç”¨Method FS
- [x] åˆ›å»ºFS Methodæµ‹è¯•è„šæœ¬
- [x] åˆ›å»ºMasterå®éªŒè„šæœ¬
- [ ] åˆ›å»ºBaseline with Backboneè„šæœ¬
- [ ] ç­‰å¾…PSS-MVå®Œæˆ
- [ ] æ‰§è¡Œå®éªŒ

## ğŸ” ç›‘æ§å‘½ä»¤

```bash
# æŸ¥çœ‹å½“å‰baselineè¿›åº¦
tail -f /mnt/localssd/logs/baselines_max40_v4.log

# æŸ¥çœ‹è¿›ç¨‹
ps aux | grep baseline_evaluation

# æŸ¥çœ‹GPUä½¿ç”¨
nvidia-smi

# æŸ¥çœ‹FS methodæµ‹è¯•è¿›åº¦
tail -f /mnt/localssd/logs/TASA_llama-3.1-8b_*_*.log
```

