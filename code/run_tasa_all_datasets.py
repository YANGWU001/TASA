#!/usr/bin/env python3
"""
å¯¹æ‰€æœ‰æ•°æ®é›†è¿è¡ŒTASAè¯„ä¼°
æ¯ä¸ªæ•°æ®é›†ä½¿ç”¨å…¶è¿‡æ»¤åçš„å­¦ç”Ÿåˆ—è¡¨ï¼ˆPre-teståœ¨20%-60%ï¼‰
"""

import os
import sys
import json
import subprocess
import time
from datetime import datetime

def check_student_list(dataset):
    """æ£€æŸ¥å­¦ç”Ÿåˆ—è¡¨æ˜¯å¦å­˜åœ¨"""
    filtered_file = f'/mnt/localssd/qualified_students_{dataset}_20to60.json'
    
    if not os.path.exists(filtered_file):
        print(f"âŒ {dataset} çš„å­¦ç”Ÿåˆ—è¡¨ä¸å­˜åœ¨: {filtered_file}")
        return None
    
    with open(filtered_file) as f:
        data = json.load(f)
    
    return data

def run_tasa_for_dataset(dataset, max_workers=10):
    """å¯¹å•ä¸ªæ•°æ®é›†è¿è¡ŒTASAè¯„ä¼°"""
    print(f"\n\n{'#'*80}")
    print(f"# TASAè¯„ä¼°: {dataset}")
    print(f"{'#'*80}\n")
    
    # æ£€æŸ¥å­¦ç”Ÿåˆ—è¡¨
    data = check_student_list(dataset)
    if not data:
        return False
    
    student_count = data['filtered_count']
    
    print(f"{'='*80}")
    print(f"ğŸ“Š {dataset} è¯„ä¼°é…ç½®")
    print(f"{'='*80}")
    print(f"  å­¦ç”Ÿæ•°: {student_count}ä¸ª")
    print(f"  æ¡ä»¶: Pre-teståœ¨20%-60%")
    print(f"  å¹¶è¡Œåº¦: {max_workers} workers")
    print(f"  æ–¹æ³•: TASA-best-of-2")
    
    # é¢„ä¼°æ—¶é—´
    estimated_time = (student_count * 6.5) / max_workers  # åˆ†é’Ÿ
    print(f"  é¢„è®¡æ—¶é—´: {estimated_time:.0f}åˆ†é’Ÿ ({estimated_time/60:.1f}å°æ—¶)")
    
    # æ„å»ºå‘½ä»¤
    # éœ€è¦å…ˆåˆ›å»ºè¯¥æ•°æ®é›†çš„å­¦ç”Ÿåˆ—è¡¨æ–‡ä»¶
    cmd = f"""
cd /mnt/localssd && /opt/venv/bin/python3 -c "
import sys
sys.path.insert(0, '/mnt/localssd')

from run_tasa_batch_best_of_two import run_batch_evaluation
import json

# è¯»å–å­¦ç”Ÿåˆ—è¡¨
with open('qualified_students_{dataset}_20to60.json') as f:
    data = json.load(f)

student_ids = [s['student_id'] for s in data['students']]

print(f'å°†è¯„ä¼° {{len(student_ids)}} ä¸ªå­¦ç”Ÿ')

# è¿è¡Œè¯„ä¼°
results = run_batch_evaluation(
    student_ids=student_ids,
    dataset='{dataset}',
    max_workers={max_workers}
)

print(f'\\nâœ… {dataset} è¯„ä¼°å®Œæˆï¼')
"
"""
    
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
    log_file = f'/mnt/localssd/logs/tasa_{dataset}.log'
    print(f"  æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    print(f"\n{'='*80}")
    print(f"ğŸš€ å¼€å§‹è¯„ä¼° {dataset}")
    print(f"{'='*80}")
    
    start_time = time.time()
    
    # è¿è¡Œå‘½ä»¤
    with open(log_file, 'w') as log:
        result = subprocess.run(
            cmd,
            shell=True,
            stdout=log,
            stderr=subprocess.STDOUT
        )
    
    elapsed = time.time() - start_time
    
    print(f"\nâ±ï¸  å®é™…ç”¨æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ")
    
    if result.returncode == 0:
        print(f"âœ… {dataset} è¯„ä¼°å®Œæˆ")
        
        # è¯»å–ç»“æœç»Ÿè®¡
        overall_file = f'/mnt/localssd/bank/evaluation_results/TASA-best-of-2/{dataset}/overall.json'
        if os.path.exists(overall_file):
            with open(overall_file) as f:
                overall = json.load(f)
            
            print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
            print(f"   å­¦ç”Ÿæ•°: {overall['num_students']}")
            print(f"   å¹³å‡Gain: {overall['overall']['avg_learning_gain']*100:.1f}%")
            print(f"   ä¸­ä½æ•°: {overall['overall']['median_learning_gain']*100:.1f}%")
        
        return True
    else:
        print(f"âŒ {dataset} è¯„ä¼°å¤±è´¥ (exit code: {result.returncode})")
        print(f"   æŸ¥çœ‹æ—¥å¿—: {log_file}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å¯¹æ‰€æœ‰æ•°æ®é›†è¿è¡ŒTASAè¯„ä¼°')
    parser.add_argument('--datasets', nargs='+', 
                       default=['assist2017', 'algebra2005', 'bridge2006', 'nips_task34'],
                       help='è¦è¯„ä¼°çš„æ•°æ®é›†åˆ—è¡¨')
    parser.add_argument('--max-workers', type=int, default=10,
                       help='æ¯ä¸ªæ•°æ®é›†çš„å¹¶è¡Œåº¦')
    parser.add_argument('--skip-assist2017', action='store_true',
                       help='è·³è¿‡assist2017ï¼ˆå¦‚æœå·²ç»åœ¨è¿è¡Œï¼‰')
    
    args = parser.parse_args()
    
    datasets = args.datasets
    if args.skip_assist2017 and 'assist2017' in datasets:
        datasets.remove('assist2017')
        print("â­ï¸  è·³è¿‡assist2017ï¼ˆå‡è®¾å·²åœ¨è¿è¡Œï¼‰")
    
    print("="*80)
    print("ğŸš€ TASAå¤šæ•°æ®é›†è¯„ä¼°")
    print("="*80)
    print(f"æ•°æ®é›†: {', '.join(datasets)}")
    print(f"å¹¶è¡Œåº¦: {args.max_workers} workers per dataset")
    print(f"å¤„ç†æ¨¡å¼: ä¸²è¡Œï¼ˆä¸€ä¸ªæ¥ä¸€ä¸ªï¼‰")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    overall_start = time.time()
    results = {}
    
    for i, dataset in enumerate(datasets, 1):
        print(f"\n\n{'='*80}")
        print(f"å¤„ç†è¿›åº¦: {i}/{len(datasets)}")
        print(f"{'='*80}")
        
        success = run_tasa_for_dataset(dataset, args.max_workers)
        results[dataset] = success
        
        if not success:
            print(f"\nâš ï¸  {dataset} è¯„ä¼°å¤±è´¥ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªæ•°æ®é›†")
    
    # æ€»ç»“
    overall_time = time.time() - overall_start
    
    print(f"\n\n{'='*80}")
    print("ğŸ“Š æ‰€æœ‰æ•°æ®é›†è¯„ä¼°æ€»ç»“")
    print(f"{'='*80}")
    print(f"æ€»ç”¨æ—¶: {overall_time/60:.1f}åˆ†é’Ÿ ({overall_time/3600:.1f}å°æ—¶)")
    print(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    print(f"\nç»“æœ:")
    for dataset in datasets:
        status = "âœ… æˆåŠŸ" if results.get(dataset) else "âŒ å¤±è´¥"
        print(f"  {dataset}: {status}")
        
        # æ˜¾ç¤ºç»“æœç»Ÿè®¡
        overall_file = f'/mnt/localssd/bank/evaluation_results/TASA-best-of-2/{dataset}/overall.json'
        if os.path.exists(overall_file):
            with open(overall_file) as f:
                data = json.load(f)
            print(f"     â†’ {data['num_students']}ä¸ªå­¦ç”Ÿ, å¹³å‡Gain={data['overall']['avg_learning_gain']*100:.1f}%")
    
    print(f"\n{'='*80}")
    print("âœ… å¤šæ•°æ®é›†TASAè¯„ä¼°å®Œæˆï¼")
    print(f"{'='*80}")
    
    # ä¿å­˜æ€»ç»“
    summary_file = '/mnt/localssd/tasa_all_datasets_summary.json'
    summary = {
        'datasets': list(results.keys()),
        'start_time': datetime.now().isoformat(),
        'total_time_minutes': overall_time / 60,
        'results': results,
        'max_workers': args.max_workers
    }
    
    # æ·»åŠ æ¯ä¸ªæ•°æ®é›†çš„ç»Ÿè®¡
    for dataset in datasets:
        overall_file = f'/mnt/localssd/bank/evaluation_results/TASA-best-of-2/{dataset}/overall.json'
        if os.path.exists(overall_file):
            with open(overall_file) as f:
                data = json.load(f)
            summary[dataset] = {
                'num_students': data['num_students'],
                'avg_learning_gain': data['overall']['avg_learning_gain'],
                'median_learning_gain': data['overall']['median_learning_gain']
            }
    
    with open(summary_file, 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"\nğŸ’¾ æ€»ç»“å·²ä¿å­˜: {summary_file}")

if __name__ == "__main__":
    main()

