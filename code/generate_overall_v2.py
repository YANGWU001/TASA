#!/usr/bin/env python3
"""
ç”Ÿæˆoverall.json - V2
ä¸ºæ¯ä¸ªæ–¹æ³•ç‹¬ç«‹è®¡ç®—level
"""

import os
import json
import argparse
import numpy as np
from collections import defaultdict

def load_method_data(dataset, method):
    """åŠ è½½æŸä¸ªæ–¹æ³•çš„æ•°æ®"""
    file_path = f'/mnt/localssd/bank/forgetting/{dataset}/{method}.json'
    
    if not os.path.exists(file_path):
        print(f"  âš ï¸  {method}.json ä¸å­˜åœ¨ï¼Œè·³è¿‡")
        return None
    
    try:
        with open(file_path) as f:
            data = json.load(f)
        print(f"  âœ… {method:10} - {len(data)} å­¦ç”Ÿ")
        return data
    except Exception as e:
        print(f"  âŒ {method:10} - åŠ è½½å¤±è´¥: {e}")
        return None

def calculate_method_levels(method_data):
    """ä¸ºæŸä¸ªæ–¹æ³•ç‹¬ç«‹è®¡ç®—level"""
    all_fs_values = []
    
    for uid, concepts in method_data.items():
        for concept_text, concept_info in concepts.items():
            if 'fs' in concept_info and concept_info['fs'] is not None:
                all_fs_values.append(concept_info['fs'])
    
    if not all_fs_values:
        return {}
    
    # è®¡ç®—33%å’Œ67%åˆ†ä½ç‚¹
    q33 = np.percentile(all_fs_values, 33)
    q67 = np.percentile(all_fs_values, 67)
    
    # ä¸ºæ¯ä¸ªuid-conceptåˆ†é…level
    levels = {}
    for uid, concepts in method_data.items():
        if uid not in levels:
            levels[uid] = {}
        
        for concept_text, concept_info in concepts.items():
            fs = concept_info.get('fs')
            if fs is not None:
                if fs < q33:
                    levels[uid][concept_text] = 'low'
                elif fs < q67:
                    levels[uid][concept_text] = 'medium'
                else:
                    levels[uid][concept_text] = 'high'
    
    print(f"    Levelé˜ˆå€¼: low<{q33:.6f}, medium<{q67:.6f}, high>={q67:.6f}")
    
    return levels

def generate_overall(dataset):
    """ç”Ÿæˆoverall.json with independent levels"""
    print("="*100)
    print(f"ğŸ“Š ç”Ÿæˆ Overall.json V2 for {dataset.upper()}")
    print("   - æ¯ä¸ªæ–¹æ³•ç‹¬ç«‹è®¡ç®—level")
    print("="*100)
    print()
    
    # 1. åŠ è½½æ‰€æœ‰æ–¹æ³•çš„æ•°æ®
    print("ğŸ“‚ åŠ è½½æ•°æ®...")
    methods = ['history', 'lpkt', 'dkt', 'akt', 'simplekt']
    method_data = {}
    
    for method in methods:
        data = load_method_data(dataset, method)
        if data is not None:
            method_data[method] = data
    
    if 'history' not in method_data:
        print("âŒ History.json ä¸å­˜åœ¨ï¼Œæ— æ³•ä½œä¸ºåŸºå‡†ï¼")
        return
    
    print(f"\nâœ… æˆåŠŸåŠ è½½ {len(method_data)} ä¸ªæ–¹æ³•")
    print()
    
    # 2. ä¸ºæ¯ä¸ªæ–¹æ³•è®¡ç®—ç‹¬ç«‹çš„level
    print("ğŸ“Š ä¸ºæ¯ä¸ªæ–¹æ³•ç‹¬ç«‹è®¡ç®—level...")
    method_levels = {}
    
    for method in method_data.keys():
        print(f"  Processing {method}...")
        method_levels[method] = calculate_method_levels(method_data[method])
    
    print()
    
    # 3. ä»¥historyä¸ºåŸºå‡†ï¼Œæ•´åˆæ‰€æœ‰æ–¹æ³•
    print("ğŸ”„ æ•´åˆæ•°æ®...")
    history_data = method_data['history']
    overall_data = {}
    
    total_students = len(history_data)
    total_concepts = 0
    missing_stats = defaultdict(int)
    
    for uid, concepts in history_data.items():
        overall_data[uid] = {}
        
        for concept_text, history_info in concepts.items():
            total_concepts += 1
            
            # åˆ›å»ºconceptæ¡ç›®ï¼ŒåŒ…å«æ‰€æœ‰æ–¹æ³•çš„s_tcã€fså’Œlevel
            concept_entry = {
                'methods': {}
            }
            
            # æ·»åŠ æ‰€æœ‰æ–¹æ³•çš„s_tcã€fså’Œç‹¬ç«‹çš„level
            for method in methods:
                if method not in method_data:
                    missing_stats[method] += 1
                    continue
                
                # æ£€æŸ¥è¯¥å­¦ç”Ÿçš„è¯¥conceptåœ¨è¯¥æ–¹æ³•ä¸­æ˜¯å¦å­˜åœ¨
                if uid in method_data[method] and concept_text in method_data[method][uid]:
                    method_info = method_data[method][uid][concept_text]
                    
                    # è·å–è¯¥æ–¹æ³•ç‹¬ç«‹è®¡ç®—çš„level
                    method_level = None
                    if method in method_levels and uid in method_levels[method] and concept_text in method_levels[method][uid]:
                        method_level = method_levels[method][uid][concept_text]
                    
                    concept_entry['methods'][method] = {
                        's_tc': method_info.get('s_tc'),
                        'fs': method_info.get('fs'),
                        'level': method_level
                    }
                else:
                    missing_stats[method] += 1
            
            # æ·»åŠ å…±åŒå­—æ®µï¼ˆæ¥è‡ªhistoryï¼‰
            concept_entry['delta_t'] = history_info.get('delta_t')
            concept_entry['tau'] = history_info.get('tau')
            concept_entry['last_response'] = history_info.get('last_response')
            concept_entry['num_attempts'] = history_info.get('num_attempts')
            
            overall_data[uid][concept_text] = concept_entry
    
    print(f"  âœ… æ•´åˆå®Œæˆ: {total_students} å­¦ç”Ÿ, {total_concepts} conceptæ¡ç›®")
    
    # 4. ç»Ÿè®¡ç¼ºå¤±æƒ…å†µ
    if missing_stats:
        print(f"\nğŸ“Š æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡:")
        for method in methods:
            if method in method_data:
                missing = missing_stats.get(method, 0)
                coverage = (total_concepts - missing) / total_concepts * 100
                print(f"  {method:10} - è¦†ç›–ç‡: {coverage:5.1f}% ({total_concepts - missing}/{total_concepts})")
    
    # 5. ä¿å­˜
    print(f"\nğŸ’¾ ä¿å­˜åˆ°Bank...")
    output_dir = f'/mnt/localssd/bank/forgetting/{dataset}'
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, 'overall.json')
    
    with open(output_file, 'w') as f:
        json.dump(overall_data, f, indent=2)
    
    file_size = os.path.getsize(output_file) / 1024 / 1024
    print(f"  âœ… å·²ä¿å­˜: {output_file}")
    print(f"  ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.1f}MB")
    
    # 6. ç¤ºä¾‹æ•°æ®
    print(f"\nğŸ“‹ æ•°æ®ç¤ºä¾‹:")
    sample_uid = list(overall_data.keys())[0]
    sample_concept = list(overall_data[sample_uid].keys())[0]
    sample_data = overall_data[sample_uid][sample_concept]
    
    print(f"  å­¦ç”ŸID: {sample_uid}")
    print(f"  Concept: {sample_concept}")
    print(f"  Methods:")
    for method, values in sample_data['methods'].items():
        print(f"    {method:10} - s_tc={values['s_tc']:.4f}, fs={values['fs']:.4f}, level={values.get('level', 'N/A')}")
    print(f"  å…±åŒå­—æ®µ:")
    print(f"    delta_t={sample_data['delta_t']}, tau={sample_data['tau']}")
    print(f"    last_response={sample_data['last_response']}, num_attempts={sample_data['num_attempts']}")

def main():
    parser = argparse.ArgumentParser(description='Generate overall.json with independent levels for each method')
    parser.add_argument('--dataset', type=str, required=True,
                       help='Dataset name')
    
    args = parser.parse_args()
    
    generate_overall(args.dataset)
    
    print("\n" + "="*100)
    print("âœ… å®Œæˆï¼")
    print("="*100)

if __name__ == '__main__':
    main()
