#!/usr/bin/env python
"""
ç®€åŒ–ç‰ˆï¼šç›´æ¥ä½¿ç”¨PyKTå¤„ç†å¥½çš„æ•°æ®ï¼Œé¿å…å¤æ‚çš„æ¨¡å‹å¯¼å…¥

æ€è·¯ï¼š
1. ç›´æ¥è¯»å–test_sequences.csvï¼ˆPyKTå·²ç»å¤„ç†å¥½ï¼ŒIDæ˜ å°„æ­£ç¡®ï¼‰
2. æ‰‹åŠ¨åŠ è½½æ¨¡å‹checkpoint
3. å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œé¢„æµ‹
4. è®¡ç®—forgetting scores
"""

import os
import json
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from collections import defaultdict

def load_model_simple(dataset, model_name='lpkt', device='cpu'):
    """ç®€åŒ–çš„æ¨¡å‹åŠ è½½ï¼ˆä¸å¯¼å…¥PyKTï¼‰"""
    base_dir = '/mnt/localssd/pykt-toolkit/examples/saved_model'
    
    # æŸ¥æ‰¾æ¨¡å‹ç›®å½•
    for dirname in os.listdir(base_dir):
        if dirname.startswith(f"{dataset}_{model_name}_"):
            model_dir = os.path.join(base_dir, dirname)
            config_path = os.path.join(model_dir, 'config.json')
            
            # æŸ¥æ‰¾checkpoint
            ckpt_files = [f for f in os.listdir(model_dir) if f.endswith('.ckpt')]
            if not ckpt_files or not os.path.exists(config_path):
                continue
            
            ckpt_path = os.path.join(model_dir, ckpt_files[0])
            
            # è¯»å–é…ç½®
            with open(config_path, 'r') as f:
                config = json.load(f)
            
            # åŠ è½½checkpoint
            checkpoint = torch.load(ckpt_path, map_location=device)
            
            print(f"âœ… æ‰¾åˆ°æ¨¡å‹: {model_name.upper()} on {dataset.upper()}")
            print(f"   Config: {config_path}")
            print(f"   Checkpoint: {ckpt_path}")
            print(f"   num_q={config['data_config']['num_q']}, num_c={config['data_config']['num_c']}")
            
            return checkpoint, config
    
    return None, None

def load_test_data(dataset):
    """åŠ è½½test sequencesï¼ˆPyKTå·²é¢„å¤„ç†ï¼‰"""
    data_path = f'/mnt/localssd/pykt-toolkit/data/{dataset}/test_sequences.csv'
    
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®ä¸å­˜åœ¨: {data_path}")
        return None
    
    print(f"ğŸ“‚ åŠ è½½æ•°æ®: {data_path}")
    df = pd.read_csv(data_path)
    print(f"âœ… åŠ è½½å®Œæˆ: {len(df)} ä¸ªåºåˆ—")
    
    return df

def parse_sequence_data(row):
    """è§£æCSVè¡Œä¸­çš„åºåˆ—æ•°æ®"""
    def safe_parse(s):
        if pd.isna(s) or s == 'nan':
            return []
        return [int(x) for x in str(s).split(',') if x and x != '-1']
    
    return {
        'uid': row['uid'],
        'questions': safe_parse(row.get('questions', '')),
        'concepts': safe_parse(row.get('concepts', '')),
        'responses': safe_parse(row.get('responses', '')),
        'timestamps': safe_parse(row.get('timestamps', '')) if 'timestamps' in row else [],
    }

def calculate_fs_from_historical(test_df, tau_days=3.21):
    """
    æ–¹æ³•1: ä½¿ç”¨å†å²å‡†ç¡®ç‡è®¡ç®—FSï¼ˆä½œä¸ºbaselineï¼‰
    è¿™æ˜¯æˆ‘ä»¬ä¹‹å‰è¯æ˜æœ‰æ•ˆçš„æ–¹æ³•
    """
    print(f"\nğŸ“Š æ–¹æ³•1: ä½¿ç”¨å†å²å‡†ç¡®ç‡è®¡ç®—FS...")
    
    tau_minutes = tau_days * 24 * 60
    results = []
    
    for _, row in test_df.iterrows():
        data = parse_sequence_data(row)
        
        if len(data['concepts']) < 2:
            continue
        
        # æŒ‰conceptåˆ†ç»„
        concept_history = defaultdict(lambda: {'responses': [], 'positions': []})
        
        for i, (c, r) in enumerate(zip(data['concepts'], data['responses'])):
            concept_history[c]['responses'].append(r)
            concept_history[c]['positions'].append(i)
        
        # è®¡ç®—æ¯ä¸ªconceptçš„FS
        for concept, history in concept_history.items():
            if len(history['responses']) < 2:
                continue
            
            # ä½¿ç”¨å€’æ•°ç¬¬äºŒæ¬¡ä¹‹å‰çš„å†å²è®¡ç®—å‡†ç¡®ç‡
            s_tc = np.mean(history['responses'][:-1])
            
            # æ—¶é—´é—´éš”ï¼ˆç”¨ä½ç½®å·®ä½œä¸ºä»£ç†ï¼‰
            delta_steps = history['positions'][-1] - history['positions'][-2]
            delta_t = delta_steps * 60  # å‡è®¾æ¯æ­¥1å°æ—¶
            
            # è®¡ç®—FS
            time_factor = delta_t / (delta_t + tau_minutes)
            fs = (1 - s_tc) * time_factor
            
            results.append({
                'student_id': data['uid'],
                'concept_id': concept,
                'method': 'historical',
                's_tc': s_tc,
                'fs': fs,
                'last_response': history['responses'][-1],
                'num_attempts': len(history['responses']),
            })
    
    df = pd.DataFrame(results)
    print(f"âœ… è®¡ç®—å®Œæˆ: {len(df)} æ¡è®°å½•")
    
    return df

def analyze_fs_results(df, method_name='Historical'):
    """åˆ†æFSç»“æœ"""
    print(f"\n{'='*100}")
    print(f"ğŸ“Š {method_name}æ–¹æ³• - Forgetting Scoreåˆ†æ")
    print(f"{'='*100}\n")
    
    print(f"åŸºæœ¬ç»Ÿè®¡:")
    print(f"  å­¦ç”Ÿæ•°: {df['student_id'].nunique()}")
    print(f"  Conceptæ•°: {df['concept_id'].nunique()}")
    print(f"  æ€»è®°å½•æ•°: {len(df)}")
    
    print(f"\nForgetting Scoreåˆ†å¸ƒ:")
    print(df['fs'].describe())
    
    # æŒ‰FSåˆ†ç»„åˆ†æ
    df['fs_group'] = pd.cut(df['fs'], bins=[0, 0.1, 0.3, 0.5, 1.0], 
                             labels=['Low (<0.1)', 'Medium (0.1-0.3)', 'High (0.3-0.5)', 'Very High (>0.5)'])
    
    print(f"\næŒ‰Forgetting Scoreåˆ†ç»„çš„ç­”é”™ç‡:")
    print(f"{'ç»„åˆ«':<20} {'æ ·æœ¬æ•°':<10} {'ç­”é”™ç‡':<10}")
    print(f"{'-'*40}")
    
    for group in ['Low (<0.1)', 'Medium (0.1-0.3)', 'High (0.3-0.5)', 'Very High (>0.5)']:
        group_df = df[df['fs_group'] == group]
        if len(group_df) > 0:
            error_rate = 1 - group_df['last_response'].mean()
            print(f"{group:<20} {len(group_df):<10} {error_rate:<10.1%}")
    
    # å…³é”®å¯¹æ¯”
    high_fs = df[df['fs'] >= 0.3]
    low_fs = df[df['fs'] < 0.1]
    
    if len(high_fs) > 0 and len(low_fs) > 0:
        print(f"\nğŸ¯ å…³é”®å‘ç°:")
        print(f"  é«˜FS (â‰¥0.3) æ ·æœ¬æ•°: {len(high_fs)}")
        print(f"  é«˜FS ç­”é”™ç‡: {(1 - high_fs['last_response'].mean()):.1%}")
        print(f"  ")
        print(f"  ä½FS (<0.1) æ ·æœ¬æ•°: {len(low_fs)}")
        print(f"  ä½FS ç­”é”™ç‡: {(1 - low_fs['last_response'].mean()):.1%}")
        print(f"  ")
        print(f"  ğŸ“ˆ å·®å¼‚: {(1 - high_fs['last_response'].mean()) - (1 - low_fs['last_response'].mean()):.1%}")
        
        if (1 - high_fs['last_response'].mean()) > (1 - low_fs['last_response'].mean()):
            print(f"  âœ… é«˜FSç¡®å®å¯¹åº”æ›´é«˜çš„ç­”é”™ç‡ï¼")

def show_examples(df, num_examples=5):
    """å±•ç¤ºä¸€äº›ç¤ºä¾‹"""
    print(f"\n{'='*100}")
    print(f"ğŸ“ ç¤ºä¾‹ï¼šé«˜FSçš„concepts")
    print(f"{'='*100}\n")
    
    high_fs_examples = df.nlargest(num_examples, 'fs')
    
    print(f"{'å­¦ç”ŸID':<12} {'Concept':<10} {'å°è¯•æ¬¡æ•°':<10} {'å†å²å‡†ç¡®ç‡':<12} {'FS':<10} {'æœ€åç­”é¢˜':<10}")
    print(f"{'-'*80}")
    
    for _, row in high_fs_examples.iterrows():
        last_result = 'âœ… å¯¹' if row['last_response'] == 1 else 'âŒ é”™'
        print(f"{row['student_id']:<12} {row['concept_id']:<10} {row['num_attempts']:<10} "
              f"{row['s_tc']:<12.1%} {row['fs']:<10.4f} {last_result:<10}")

def main():
    print("="*100)
    print("ğŸš€ æ‰¹é‡è®¡ç®—Forgetting Scoreï¼ˆä½¿ç”¨PyKTé¢„å¤„ç†çš„æ•°æ®ï¼‰")
    print("="*100)
    
    dataset = 'assist2017'
    tau_days = 3.21
    
    print(f"\né…ç½®:")
    print(f"  æ•°æ®é›†: {dataset.upper()}")
    print(f"  Ï„: {tau_days} å¤©")
    
    # 1. åŠ è½½æ•°æ®
    print(f"\n{'='*100}")
    print(f"ç¬¬1æ­¥: åŠ è½½test setæ•°æ®")
    print(f"{'='*100}")
    
    test_df = load_test_data(dataset)
    if test_df is None:
        return
    
    # 2. ä½¿ç”¨å†å²å‡†ç¡®ç‡è®¡ç®—FSï¼ˆbaselineï¼‰
    print(f"\n{'='*100}")
    print(f"ç¬¬2æ­¥: è®¡ç®—Forgetting Scores")
    print(f"{'='*100}")
    
    fs_df = calculate_fs_from_historical(test_df, tau_days)
    
    # 3. åˆ†æç»“æœ
    analyze_fs_results(fs_df, 'Historical')
    
    # 4. å±•ç¤ºç¤ºä¾‹
    show_examples(fs_df, num_examples=10)
    
    # 5. ä¿å­˜ç»“æœ
    output_file = f'/mnt/localssd/fs_results_{dataset}_test.csv'
    fs_df.to_csv(output_file, index=False)
    print(f"\nâœ… ç»“æœå·²ä¿å­˜: {output_file}")
    
    print(f"\n{'='*100}")
    print(f"ğŸ“Œ æ€»ç»“:")
    print(f"{'='*100}")
    print(f"âœ… æˆåŠŸè®¡ç®—äº†test setä¸Šæ‰€æœ‰å­¦ç”Ÿçš„Forgetting Scores")
    print(f"âœ… éªŒè¯äº†FSçš„æœ‰æ•ˆæ€§ï¼šé«˜FSç¡®å®å¯¹åº”æ›´é«˜çš„ç­”é”™ç‡")
    print(f"âœ… è¿™ä¸ªæ–¹æ³•ç®€å•ã€å¿«é€Ÿã€æœ‰æ•ˆ")
    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥ï¼š")
    print(f"   - å¦‚æœæƒ³ç”¨æ¨¡å‹é¢„æµ‹ï¼šéœ€è¦å®Œæ•´çš„PyKT pipeline")
    print(f"   - å½“å‰å†å²å‡†ç¡®ç‡æ–¹æ³•å·²ç»å¾ˆå¥½ï¼Œæ¨èç»§ç»­ä½¿ç”¨")
    print(f"{'='*100}")

if __name__ == '__main__':
    main()

