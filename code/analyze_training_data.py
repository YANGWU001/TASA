#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åˆ†æè®­ç»ƒæ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯
"""

import pandas as pd
import numpy as np
import os
from collections import Counter

def analyze_dataset(dataset_name, data_path):
    """
    åˆ†ææ•°æ®é›†çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    """
    print(f"\n{'='*80}")
    print(f"ğŸ“Š æ•°æ®é›†: {dataset_name.upper()}")
    print(f"{'='*80}")
    
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        return None
    
    # è¯»å–æ•°æ®
    print(f"ğŸ“‚ è¯»å–æ•°æ®: {data_path}")
    df = pd.read_csv(data_path)
    
    stats = {}
    
    # åŸºæœ¬ç»Ÿè®¡
    stats['total_records'] = len(df)
    stats['unique_students'] = df['uid'].nunique()
    
    # æŒ‰foldç»Ÿè®¡
    print(f"\nğŸ“‹ Foldåˆ†å¸ƒ:")
    fold_counts = df['fold'].value_counts().sort_index()
    for fold, count in fold_counts.items():
        print(f"  Fold {fold}: {count:,} æ¡è®°å½•")
        stats[f'fold_{fold}_records'] = count
    
    # ç»Ÿè®¡æ¯ä¸ªå­¦ç”Ÿçš„ä¿¡æ¯
    print(f"\nğŸ‘¥ å­¦ç”Ÿç»Ÿè®¡:")
    print(f"  æ€»å­¦ç”Ÿæ•°: {stats['unique_students']:,}")
    
    # è§£ææ¯ä¸ªå­¦ç”Ÿçš„è¯¦ç»†ä¿¡æ¯
    total_interactions = 0
    total_questions = 0
    total_concepts = 0
    sequence_lengths = []
    response_correct = []
    timestamps_list = []
    all_concepts = set()
    all_questions = set()
    
    print(f"\nâ³ æ­£åœ¨è§£æå­¦ç”Ÿæ•°æ®...")
    
    for idx, row in df.iterrows():
        if idx % 1000 == 0:
            print(f"  å¤„ç†è¿›åº¦: {idx}/{len(df)} ({idx/len(df)*100:.1f}%)")
        
        # è§£æconcepts
        concepts_str = str(row['concepts'])
        if concepts_str != 'NA' and concepts_str != 'nan':
            concepts = [int(c) for c in concepts_str.split(',') if c and c != '-1']
            sequence_lengths.append(len(concepts))
            total_interactions += len(concepts)
            all_concepts.update(concepts)
        
        # è§£æquestions
        questions_str = str(row['questions'])
        if questions_str != 'NA' and questions_str != 'nan':
            questions = [int(q) for q in questions_str.split(',') if q and q != '-1']
            total_questions += len(questions)
            all_questions.update(questions)
        
        # è§£æresponses
        responses_str = str(row['responses'])
        if responses_str != 'NA' and responses_str != 'nan':
            responses = [int(r) for r in responses_str.split(',') if r and r != '-1']
            response_correct.extend(responses)
        
        # è§£ætimestamps
        timestamps_str = str(row['timestamps'])
        if timestamps_str != 'NA' and timestamps_str != 'nan':
            try:
                timestamps = [int(t) for t in timestamps_str.split(',') if t and t != '-1']
                timestamps_list.extend(timestamps)
            except:
                pass
    
    print(f"  å¤„ç†å®Œæˆ: {len(df)}/{len(df)} (100.0%)")
    
    # ç»Ÿè®¡ç»“æœ
    stats['total_interactions'] = total_interactions
    stats['unique_concepts'] = len(all_concepts)
    stats['unique_questions'] = len(all_questions)
    stats['avg_sequence_length'] = np.mean(sequence_lengths) if sequence_lengths else 0
    stats['median_sequence_length'] = np.median(sequence_lengths) if sequence_lengths else 0
    stats['min_sequence_length'] = np.min(sequence_lengths) if sequence_lengths else 0
    stats['max_sequence_length'] = np.max(sequence_lengths) if sequence_lengths else 0
    stats['std_sequence_length'] = np.std(sequence_lengths) if sequence_lengths else 0
    
    # æ­£ç¡®ç‡ç»Ÿè®¡
    if response_correct:
        stats['overall_accuracy'] = np.mean(response_correct)
        stats['total_correct'] = sum(response_correct)
        stats['total_incorrect'] = len(response_correct) - sum(response_correct)
    
    # æ—¶é—´è·¨åº¦ç»Ÿè®¡
    if timestamps_list:
        timestamps_array = np.array(timestamps_list)
        stats['earliest_timestamp'] = int(np.min(timestamps_array))
        stats['latest_timestamp'] = int(np.max(timestamps_array))
        time_span_days = (stats['latest_timestamp'] - stats['earliest_timestamp']) / 1000 / 60 / 60 / 24
        stats['time_span_days'] = time_span_days
    
    # æ‰“å°è¯¦ç»†ç»Ÿè®¡
    print(f"\nğŸ“ˆ è¯¦ç»†ç»Ÿè®¡:")
    print(f"\n  ğŸ”¢ æ•°é‡ç»Ÿè®¡:")
    print(f"    - æ€»å­¦ç”Ÿæ•°: {stats['unique_students']:,}")
    print(f"    - æ€»äº¤äº’æ•°: {stats['total_interactions']:,}")
    print(f"    - å”¯ä¸€Concepts: {stats['unique_concepts']:,}")
    print(f"    - å”¯ä¸€Questions: {stats['unique_questions']:,}")
    print(f"    - å¹³å‡æ¯ä¸ªå­¦ç”Ÿäº¤äº’æ•°: {stats['total_interactions']/stats['unique_students']:.1f}")
    
    print(f"\n  ğŸ“ åºåˆ—é•¿åº¦ç»Ÿè®¡:")
    print(f"    - å¹³å‡é•¿åº¦: {stats['avg_sequence_length']:.1f}")
    print(f"    - ä¸­ä½æ•°é•¿åº¦: {stats['median_sequence_length']:.1f}")
    print(f"    - æœ€å°é•¿åº¦: {stats['min_sequence_length']}")
    print(f"    - æœ€å¤§é•¿åº¦: {stats['max_sequence_length']}")
    print(f"    - æ ‡å‡†å·®: {stats['std_sequence_length']:.1f}")
    
    if 'overall_accuracy' in stats:
        print(f"\n  âœ… æ­£ç¡®ç‡ç»Ÿè®¡:")
        print(f"    - æ€»ä½“æ­£ç¡®ç‡: {stats['overall_accuracy']*100:.2f}%")
        print(f"    - æ­£ç¡®ç­”é¢˜æ•°: {stats['total_correct']:,}")
        print(f"    - é”™è¯¯ç­”é¢˜æ•°: {stats['total_incorrect']:,}")
    
    if 'time_span_days' in stats:
        print(f"\n  â±ï¸  æ—¶é—´è·¨åº¦:")
        print(f"    - æœ€æ—©æ—¶é—´: {pd.to_datetime(stats['earliest_timestamp'], unit='ms')}")
        print(f"    - æœ€æ™šæ—¶é—´: {pd.to_datetime(stats['latest_timestamp'], unit='ms')}")
        print(f"    - æ—¶é—´è·¨åº¦: {stats['time_span_days']:.1f} å¤©")
    
    # åºåˆ—é•¿åº¦åˆ†å¸ƒ
    print(f"\n  ğŸ“Š åºåˆ—é•¿åº¦åˆ†å¸ƒ:")
    percentiles = [10, 25, 50, 75, 90, 95, 99]
    for p in percentiles:
        value = np.percentile(sequence_lengths, p) if sequence_lengths else 0
        print(f"    - {p}th percentile: {value:.0f}")
    
    # Concepté¢‘ç‡ç»Ÿè®¡ï¼ˆTop 10ï¼‰
    if response_correct:
        print(f"\n  ğŸ” æœ€å¸¸è§çš„10ä¸ªConcepts:")
        concept_counter = Counter()
        for idx, row in df.iterrows():
            concepts_str = str(row['concepts'])
            if concepts_str != 'NA' and concepts_str != 'nan':
                concepts = [int(c) for c in concepts_str.split(',') if c and c != '-1']
                concept_counter.update(concepts)
        
        for concept, count in concept_counter.most_common(10):
            percentage = count / stats['total_interactions'] * 100
            print(f"    - Concept {concept}: {count:,} æ¬¡ ({percentage:.2f}%)")
    
    return stats


def compare_datasets(stats_dict):
    """
    å¯¹æ¯”å¤šä¸ªæ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯
    """
    print(f"\n{'='*80}")
    print(f"ğŸ“Š æ•°æ®é›†å¯¹æ¯”")
    print(f"{'='*80}\n")
    
    comparison_df = pd.DataFrame(stats_dict).T
    
    # é€‰æ‹©å…³é”®æŒ‡æ ‡è¿›è¡Œå¯¹æ¯”
    key_metrics = [
        'unique_students',
        'total_interactions',
        'unique_concepts',
        'unique_questions',
        'avg_sequence_length',
        'overall_accuracy',
        'time_span_days'
    ]
    
    print("ğŸ“‹ å…³é”®æŒ‡æ ‡å¯¹æ¯”:")
    print("-" * 80)
    
    for metric in key_metrics:
        if metric in comparison_df.columns:
            print(f"\n{metric}:")
            for dataset in comparison_df.index:
                value = comparison_df.loc[dataset, metric]
                if isinstance(value, float):
                    if 'accuracy' in metric:
                        print(f"  {dataset:15s}: {value*100:10.2f}%")
                    else:
                        print(f"  {dataset:15s}: {value:10.1f}")
                else:
                    print(f"  {dataset:15s}: {value:10,}")
    
    return comparison_df


if __name__ == "__main__":
    print("ğŸ” è®­ç»ƒæ•°æ®ç»Ÿè®¡åˆ†æ")
    print("=" * 80)
    
    datasets = {
        'EdNet': '/mnt/localssd/pykt-toolkit/data/ednet/train_valid_sequences.csv',
        'ASSISTments2017': '/mnt/localssd/pykt-toolkit/data/assist2017/train_valid_sequences.csv'
    }
    
    stats_dict = {}
    
    for dataset_name, data_path in datasets.items():
        stats = analyze_dataset(dataset_name, data_path)
        if stats:
            stats_dict[dataset_name] = stats
    
    # å¯¹æ¯”æ•°æ®é›†
    if len(stats_dict) > 1:
        comparison_df = compare_datasets(stats_dict)
        
        # ä¿å­˜å¯¹æ¯”ç»“æœ
        output_path = "/tmp/dataset_comparison.csv"
        comparison_df.to_csv(output_path)
        print(f"\nâœ… å¯¹æ¯”ç»“æœå·²ä¿å­˜: {output_path}")
    
    print(f"\n{'='*80}")
    print("âœ… åˆ†æå®Œæˆï¼")
    print(f"{'='*80}")

