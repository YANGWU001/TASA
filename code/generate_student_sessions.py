#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä¸ºæ¯ä¸ªå­¦ç”Ÿç”ŸæˆSessionæ•°æ®
- é€‰æ‹©interactionæ¬¡æ•°ä¸ºä¸­ä½æ•°çš„concept
- åŒ…å«persona, memory, delta_t, äº”ç§methodçš„s_tc/fs/level
"""

import os
import json
import numpy as np
from collections import defaultdict
from tqdm import tqdm
import argparse

# æ•°æ®é›†é…ç½®
DATASET_MAPPING = {
    'assist2017': 'assist2017',
    'nips_task34': 'nips_task34',
    'algebra2005': 'algebra2005',
    'bridge2006': 'bridge2algebra2006'
}

def load_concept_mapping(dataset):
    """åŠ è½½concept IDåˆ°æ–‡æœ¬çš„æ˜ å°„"""
    actual_dataset = DATASET_MAPPING.get(dataset, dataset)
    keyid_file = f'/mnt/localssd/pykt-toolkit/data/{actual_dataset}/keyid2idx.json'
    
    if not os.path.exists(keyid_file):
        return {}
    
    with open(keyid_file) as f:
        data = json.load(f)
    
    # conceptså­—æ®µï¼š{concept_text: concept_id}
    concepts_dict = data.get('concepts', {})
    
    # åå‘æ˜ å°„ï¼š{concept_id: concept_text}
    id_to_text = {v: k for k, v in concepts_dict.items()}
    
    return id_to_text

def concept_id_to_text(concept_key, id_to_text_map):
    """å°†concept_Xæ ¼å¼è½¬æ¢ä¸ºå®é™…æ–‡æœ¬"""
    # concept_keyæ ¼å¼: "concept_0", "concept_1", etc.
    if concept_key.startswith('concept_'):
        try:
            concept_id = int(concept_key.split('_')[1])
            return id_to_text_map.get(concept_id, concept_key)
        except:
            return concept_key
    return concept_key

def load_student_interactions(dataset):
    """åŠ è½½å­¦ç”Ÿçš„interactionæ•°æ®ï¼Œç»Ÿè®¡æ¯ä¸ªconceptçš„æ¬¡æ•°"""
    # ä»overall.jsonä¸­åŠ è½½æ•°æ®
    overall_file = f'/mnt/localssd/bank/forgetting/{dataset}/overall.json'
    
    if not os.path.exists(overall_file):
        print(f"  âŒ Overall.jsonä¸å­˜åœ¨: {overall_file}")
        return {}
    
    with open(overall_file) as f:
        overall_data = json.load(f)
    
    # ç»Ÿè®¡æ¯ä¸ªå­¦ç”Ÿæ¯ä¸ªconceptçš„interactionæ¬¡æ•°
    student_concept_attempts = {}
    
    for uid, concepts in overall_data.items():
        student_concept_attempts[uid] = {}
        
        for concept_text, data in concepts.items():
            num_attempts = data.get('num_attempts', 0)
            if num_attempts > 0:
                student_concept_attempts[uid][concept_text] = num_attempts
    
    return student_concept_attempts

def select_median_concept(student_attempts):
    """é€‰æ‹©interactionæ¬¡æ•°ä¸ºä¸­ä½æ•°çš„concept"""
    if not student_attempts:
        return None
    
    # è·å–æ‰€æœ‰attemptæ¬¡æ•°
    attempts_list = list(student_attempts.values())
    
    # è®¡ç®—ä¸­ä½æ•°
    median_attempts = np.median(attempts_list)
    
    # æ‰¾åˆ°æœ€æ¥è¿‘ä¸­ä½æ•°çš„concept
    closest_concept = None
    min_diff = float('inf')
    
    for concept, attempts in student_attempts.items():
        diff = abs(attempts - median_attempts)
        if diff < min_diff:
            min_diff = diff
            closest_concept = concept
    
    return closest_concept

def load_persona(dataset, uid, concept_text):
    """åŠ è½½å­¦ç”Ÿåœ¨è¯¥conceptä¸Šçš„persona"""
    persona_file = f'/mnt/localssd/bank/persona/{dataset}/data/{uid}.json'
    
    if not os.path.exists(persona_file):
        return None
    
    with open(persona_file) as f:
        persona_data = json.load(f)
    
    # persona_dataæ˜¯ä¸€ä¸ªlistï¼Œéœ€è¦æ‰¾åˆ°å¯¹åº”conceptçš„è®°å½•
    if isinstance(persona_data, list):
        for item in persona_data:
            if item.get('concept_text') == concept_text:
                return {
                    'description': item.get('description'),
                    'keywords': item.get('keywords'),
                    'stats': item.get('stats')
                }
    
    return None

def load_memory(dataset, uid, concept_text):
    """åŠ è½½å­¦ç”Ÿåœ¨è¯¥conceptä¸Šçš„memoryï¼Œè¿”å›æŒ‰timestampæ’åºçš„descriptionåˆ—è¡¨"""
    memory_file = f'/mnt/localssd/bank/memory/{dataset}/data/{uid}.json'
    
    if not os.path.exists(memory_file):
        return None
    
    with open(memory_file) as f:
        memory_data = json.load(f)
    
    # memoryæ˜¯ä¸€ä¸ªlistï¼Œéœ€è¦æ‰¾åˆ°å¯¹åº”conceptçš„æ‰€æœ‰è®°å½•
    memories = []
    
    if isinstance(memory_data, list):
        for mem in memory_data:
            if mem.get('concept_text') == concept_text:
                memories.append({
                    'description': mem.get('description'),
                    'timestamp': mem.get('timestamp'),
                    'response': mem.get('response')
                })
    
    if not memories:
        return None
    
    # æŒ‰timestampæ’åº
    memories.sort(key=lambda x: x.get('timestamp', 0))
    
    # è¿”å›descriptionåˆ—è¡¨ï¼ˆä¿ç•™timestampå’Œresponseç”¨äºå‚è€ƒï¼‰
    return memories

def load_forgetting(dataset, uid, concept_text):
    """åŠ è½½å­¦ç”Ÿåœ¨è¯¥conceptä¸Šçš„forgettingä¿¡æ¯"""
    overall_file = f'/mnt/localssd/bank/forgetting/{dataset}/overall.json'
    
    if not os.path.exists(overall_file):
        return None
    
    with open(overall_file) as f:
        overall_data = json.load(f)
    
    if uid not in overall_data:
        return None
    
    if concept_text not in overall_data[uid]:
        return None
    
    concept_data = overall_data[uid][concept_text]
    
    # æå–éœ€è¦çš„ä¿¡æ¯
    delta_t_minutes = concept_data.get('delta_t')
    delta_t_days = delta_t_minutes / 60 / 24 if delta_t_minutes is not None else None
    
    methods_data = {}
    for method in ['history', 'lpkt', 'dkt', 'akt', 'simplekt']:
        if method in concept_data.get('methods', {}):
            methods_data[method] = concept_data['methods'][method]
    
    return {
        'delta_t_days': delta_t_days,
        'delta_t_minutes': delta_t_minutes,
        'tau_minutes': concept_data.get('tau'),
        'last_response': concept_data.get('last_response'),
        'num_attempts': concept_data.get('num_attempts'),
        'methods': methods_data
    }

def generate_session_for_dataset(dataset):
    """ä¸ºæ•´ä¸ªæ•°æ®é›†ç”Ÿæˆsession"""
    print("="*100)
    print(f"ğŸ“š ä¸º {dataset.upper()} ç”ŸæˆStudent Sessions")
    print("="*100)
    print()
    
    # 1. åŠ è½½conceptæ˜ å°„
    print("ğŸ“‚ åŠ è½½Conceptæ˜ å°„...")
    id_to_text_map = load_concept_mapping(dataset)
    print(f"  âœ… åŠ è½½äº† {len(id_to_text_map)} ä¸ªconceptæ˜ å°„")
    print()
    
    # 2. åŠ è½½å­¦ç”Ÿçš„interactionç»Ÿè®¡
    print("ğŸ“‚ åŠ è½½å­¦ç”ŸInteractionæ•°æ®...")
    student_attempts = load_student_interactions(dataset)
    
    if not student_attempts:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®ï¼Œé€€å‡º")
        return
    
    print(f"  âœ… åŠ è½½äº† {len(student_attempts)} ä¸ªå­¦ç”Ÿ")
    print()
    
    # 3. ä¸ºæ¯ä¸ªå­¦ç”Ÿç”Ÿæˆsession
    print("ğŸ¯ ç”ŸæˆStudent Sessions...")
    print()
    
    sessions = {}
    skipped_students = []
    
    for uid in tqdm(student_attempts.keys(), desc="ç”ŸæˆSessions", ncols=100):
        # é€‰æ‹©ä¸­ä½æ•°concept (æ ¼å¼: concept_X)
        median_concept_key = select_median_concept(student_attempts[uid])
        
        if not median_concept_key:
            skipped_students.append(uid)
            continue
        
        # ä»concept_Xä¸­æå–concept_idæ•°å­—
        try:
            concept_id = int(median_concept_key.split('_')[1])
        except:
            skipped_students.append(uid)
            continue
        
        # å°†concept_idè½¬æ¢ä¸ºå®é™…æ–‡æœ¬
        concept_text = id_to_text_map.get(concept_id, median_concept_key)
        
        # åŠ è½½persona (ä½¿ç”¨å®é™…æ–‡æœ¬)
        persona = load_persona(dataset, uid, concept_text)
        
        # åŠ è½½memory (ä½¿ç”¨å®é™…æ–‡æœ¬)
        memory = load_memory(dataset, uid, concept_text)
        
        # åŠ è½½forgettingä¿¡æ¯ (ä½¿ç”¨åŸå§‹concept_Xæ ¼å¼)
        forgetting = load_forgetting(dataset, uid, median_concept_key)
        
        if not forgetting:
            skipped_students.append(uid)
            continue
        
        # æ„å»ºsessionæ•°æ®
        session_data = {
            'student_id': uid,
            'concept_id': concept_id,  # ä½¿ç”¨æ•°å­—ID
            'concept_text': concept_text,
            'persona': persona,
            'memory': memory,
            'delta_t_days': forgetting['delta_t_days'],
            'delta_t_minutes': forgetting['delta_t_minutes'],
            'tau_minutes': forgetting['tau_minutes'],
            'last_response': forgetting['last_response'],
            'num_attempts': forgetting['num_attempts'],
            'methods': forgetting['methods']
        }
        
        sessions[uid] = session_data
    
    print()
    print(f"âœ… æˆåŠŸç”Ÿæˆ {len(sessions)} ä¸ªsessions")
    if skipped_students:
        print(f"âš ï¸  è·³è¿‡ {len(skipped_students)} ä¸ªå­¦ç”Ÿ (ç¼ºå°‘æ•°æ®)")
    print()
    
    # 3. ä¿å­˜sessions
    output_dir = f'/mnt/localssd/bank/session/{dataset}'
    os.makedirs(output_dir, exist_ok=True)
    
    print("ğŸ’¾ ä¿å­˜Sessions...")
    
    for uid, session_data in tqdm(sessions.items(), desc="ä¿å­˜æ–‡ä»¶", ncols=100):
        output_file = os.path.join(output_dir, f'{uid}.json')
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(session_data, f, indent=2, ensure_ascii=False)
    
    print()
    
    # 4. ç»Ÿè®¡ä¿¡æ¯
    print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  å­¦ç”Ÿæ€»æ•°: {len(sessions)}")
    
    # ç»Ÿè®¡delta_tåˆ†å¸ƒ
    delta_t_days = [s['delta_t_days'] for s in sessions.values() if s['delta_t_days'] is not None]
    if delta_t_days:
        print(f"  Delta_t (å¤©):")
        print(f"    ä¸­ä½æ•°: {np.median(delta_t_days):.2f}")
        print(f"    å¹³å‡å€¼: {np.mean(delta_t_days):.2f}")
        print(f"    èŒƒå›´: {np.min(delta_t_days):.2f} - {np.max(delta_t_days):.2f}")
    
    # ç»Ÿè®¡num_attemptsåˆ†å¸ƒ
    num_attempts = [s['num_attempts'] for s in sessions.values() if s['num_attempts'] is not None]
    if num_attempts:
        print(f"  Attempts (æ¬¡æ•°):")
        print(f"    ä¸­ä½æ•°: {np.median(num_attempts):.0f}")
        print(f"    å¹³å‡å€¼: {np.mean(num_attempts):.1f}")
        print(f"    èŒƒå›´: {int(np.min(num_attempts))} - {int(np.max(num_attempts))}")
    
    print()
    
    # 5. æ˜¾ç¤ºç¤ºä¾‹
    if sessions:
        sample_uid = list(sessions.keys())[0]
        sample_data = sessions[sample_uid]
        
        print("ğŸ“‹ ç¤ºä¾‹Session:")
        print(f"  å­¦ç”ŸID: {sample_data['student_id']}")
        print(f"  Concept ID: {sample_data['concept_id']}")
        print(f"  Concept Text: {sample_data['concept_text']}")
        
        if sample_data['persona']:
            print(f"  Persona:")
            print(f"    Description: {sample_data['persona'].get('description', 'N/A')[:100]}...")
            print(f"    Stats: {sample_data['persona'].get('stats', 'N/A')}")
        else:
            print(f"  Persona: N/A")
        
        if sample_data['memory']:
            print(f"  Memory ({len(sample_data['memory'])} æ¡è®°å½•):")
            for i, mem in enumerate(sample_data['memory'][:3], 1):
                print(f"    {i}. {mem['description'][:60]}...")
            if len(sample_data['memory']) > 3:
                print(f"    ... (è¿˜æœ‰ {len(sample_data['memory']) - 3} æ¡è®°å½•)")
        else:
            print(f"  Memory: N/A")
        
        print(f"  Delta_t: {sample_data['delta_t_days']:.2f} å¤©")
        print(f"  Attempts: {sample_data['num_attempts']}")
        print(f"  Last Response: {sample_data['last_response']}")
        print(f"  Methods:")
        for method, values in sample_data['methods'].items():
            print(f"    {method:10} - s_tc={values['s_tc']:.4f}, fs={values['fs']:.4f}, level={values.get('level', 'N/A')}")
    
    print()
    print(f"ğŸ’¾ ä¿å­˜ä½ç½®: {output_dir}/")
    
    # ç»Ÿè®¡æ–‡ä»¶å¤§å°
    total_size = sum(os.path.getsize(os.path.join(output_dir, f'{uid}.json')) 
                     for uid in sessions.keys())
    print(f"ğŸ“Š æ€»å¤§å°: {total_size / 1024 / 1024:.2f}MB")

def main():
    parser = argparse.ArgumentParser(description='ä¸ºæ¯ä¸ªå­¦ç”Ÿç”ŸæˆSessionæ•°æ®')
    parser.add_argument('--dataset', type=str, 
                       choices=['assist2017', 'nips_task34', 'algebra2005', 'bridge2006', 'all'],
                       default='all',
                       help='æ•°æ®é›†åç§° (é»˜è®¤: all)')
    
    args = parser.parse_args()
    
    if args.dataset == 'all':
        datasets = ['assist2017', 'nips_task34', 'algebra2005', 'bridge2006']
    else:
        datasets = [args.dataset]
    
    for dataset in datasets:
        generate_session_for_dataset(dataset)
        print()
    
    print("="*100)
    print("âœ… æ‰€æœ‰Sessionç”Ÿæˆå®Œæˆï¼")
    print("="*100)
    print()
    print("æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  ls -lh /mnt/localssd/bank/session/*/")
    print()
    print("ç¤ºä¾‹:")
    print("  cat /mnt/localssd/bank/session/assist2017/0.json")

if __name__ == '__main__':
    main()

