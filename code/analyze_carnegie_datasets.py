#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Carnegie Learningæ•°æ®é›†ç»Ÿè®¡åˆ†æ
åˆ†æAlgebra2005å’ŒBridge2Algebra2006æ•°æ®é›†
"""

import pandas as pd
import os
from collections import defaultdict, Counter

def parse_csv_field(field_str):
    """è§£æCSVå­—æ®µï¼Œå¤„ç†é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²"""
    if pd.isna(field_str) or field_str == 'NA' or field_str == '':
        return []
    
    try:
        # å°è¯•ç›´æ¥åˆ†å‰²
        values = str(field_str).strip().split(',')
        result = []
        for v in values:
            v = v.strip()
            if v and v != '-1' and v != 'NA':
                try:
                    result.append(int(v))
                except ValueError:
                    # å¦‚æœä¸èƒ½è½¬æ¢ä¸ºintï¼Œä¿ç•™å­—ç¬¦ä¸²ï¼ˆç”¨äºskillsï¼‰
                    result.append(v)
        return result
    except Exception as e:
        print(f"è­¦å‘Š: è§£æå­—æ®µå¤±è´¥ {field_str}: {e}")
        return []

def analyze_dataset(dataset_name, data_path):
    """åˆ†æå•ä¸ªæ•°æ®é›†"""
    print(f"\n{'='*60}")
    print(f"  {dataset_name} æ•°æ®é›†åˆ†æ")
    print(f"{'='*60}\n")
    
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}\n")
        return None
    
    try:
        # è¯»å–æ•°æ®ï¼ˆCSVæ ¼å¼ï¼Œæœ‰headerï¼‰
        df = pd.read_csv(data_path)
        
        # è§£æå­—æ®µ
        all_students = []
        all_questions = []
        all_concepts = []
        all_responses = []
        all_timestamps = []
        total_interactions = 0
        sequence_lengths = []
        
        print(f"æ­£åœ¨åˆ†æ {len(df)} ä¸ªåºåˆ—...")
        
        for idx, row in df.iterrows():
            # å­¦ç”ŸID
            student_id = row['uid']
            
            # è§£æå„ä¸ªå­—æ®µ
            questions = parse_csv_field(row['questions'])
            concepts = parse_csv_field(row['concepts'])
            responses = parse_csv_field(row['responses'])
            timestamps = parse_csv_field(row['timestamps'])
            
            # è®¡ç®—åºåˆ—é•¿åº¦
            seq_len = len(responses)
            
            # å¯¹äºconceptsï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            if len(concepts) > 0 and isinstance(concepts[0], str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²å½¢å¼çš„conceptï¼ˆå¦‚"Skill~~Name"ï¼‰ï¼Œéœ€è¦æ‹†åˆ†
                expanded_concepts = []
                for c in concepts:
                    if '~~' in str(c):
                        expanded_concepts.extend(str(c).split('~~'))
                    else:
                        expanded_concepts.append(str(c))
                concepts = expanded_concepts
            
            # ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
            if len(responses) != seq_len:
                print(f"  è­¦å‘Š: å­¦ç”Ÿ {student_id} çš„åºåˆ—é•¿åº¦ä¸ä¸€è‡´: {len(responses)} vs {seq_len}")
                continue
            
            all_students.append(student_id)
            all_questions.extend(questions)
            all_concepts.extend(concepts)
            all_responses.extend(responses)
            all_timestamps.extend([t for t in timestamps if isinstance(t, (int, float))])
            total_interactions += seq_len
            sequence_lengths.append(seq_len)
        
        # ç»Ÿè®¡ä¿¡æ¯
        num_students = len(set(all_students))
        num_unique_questions = len(set(all_questions))
        num_unique_concepts = len(set(all_concepts))
        
        print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯")
        print(f"{'â”€'*60}")
        print(f"  å­¦ç”Ÿæ•°é‡:        {num_students:,}")
        print(f"  å”¯ä¸€é—®é¢˜æ•°:      {num_unique_questions:,}")
        print(f"  å”¯ä¸€æ¦‚å¿µ/æŠ€èƒ½æ•°: {num_unique_concepts:,}")
        print(f"  æ€»äº¤äº’æ•°:        {total_interactions:,}")
        
        # åºåˆ—é•¿åº¦ç»Ÿè®¡
        if sequence_lengths:
            avg_seq_len = sum(sequence_lengths) / len(sequence_lengths)
            min_seq_len = min(sequence_lengths)
            max_seq_len = max(sequence_lengths)
            median_seq_len = sorted(sequence_lengths)[len(sequence_lengths)//2]
            
            print(f"\nğŸ“ åºåˆ—é•¿åº¦ç»Ÿè®¡")
            print(f"{'â”€'*60}")
            print(f"  å¹³å‡åºåˆ—é•¿åº¦:    {avg_seq_len:.1f}")
            print(f"  ä¸­ä½æ•°åºåˆ—é•¿åº¦:  {median_seq_len}")
            print(f"  æœ€å°åºåˆ—é•¿åº¦:    {min_seq_len}")
            print(f"  æœ€å¤§åºåˆ—é•¿åº¦:    {max_seq_len}")
        
        # ç­”é¢˜æ­£ç¡®ç‡
        if all_responses:
            correct_responses = sum(1 for r in all_responses if r == 1)
            accuracy = correct_responses / len(all_responses) * 100
            
            print(f"\nâœ… ç­”é¢˜æ­£ç¡®ç‡")
            print(f"{'â”€'*60}")
            print(f"  æ­£ç¡®ç­”é¢˜æ•°:      {correct_responses:,}")
            print(f"  é”™è¯¯ç­”é¢˜æ•°:      {len(all_responses) - correct_responses:,}")
            print(f"  æ€»ä½“æ­£ç¡®ç‡:      {accuracy:.2f}%")
        
        # æ—¶é—´æˆ³ä¿¡æ¯
        if all_timestamps:
            print(f"\nâ±ï¸  æ—¶é—´æˆ³ä¿¡æ¯")
            print(f"{'â”€'*60}")
            print(f"  æœ‰æ—¶é—´æˆ³çš„äº¤äº’: {len(all_timestamps):,}")
            print(f"  æ—¶é—´æˆ³è¦†ç›–ç‡:   {len(all_timestamps)/total_interactions*100:.1f}%")
        
        # æ¦‚å¿µ/æŠ€èƒ½åˆ†å¸ƒ
        if all_concepts:
            concept_counts = Counter(all_concepts)
            top_10_concepts = concept_counts.most_common(10)
            
            print(f"\nğŸ¯ Top 10 æœ€å¸¸è§çš„æ¦‚å¿µ/æŠ€èƒ½")
            print(f"{'â”€'*60}")
            for i, (concept, count) in enumerate(top_10_concepts, 1):
                # æˆªæ–­è¿‡é•¿çš„conceptåç§°
                concept_str = str(concept)[:40] + '...' if len(str(concept)) > 40 else str(concept)
                percentage = count / len(all_concepts) * 100
                print(f"  {i:2d}. {concept_str:45s} {count:6,} ({percentage:5.2f}%)")
        
        # æ•°æ®ç¨€ç–æ€§
        if num_students > 0 and num_unique_questions > 0:
            potential_interactions = num_students * num_unique_questions
            sparsity = (1 - total_interactions / potential_interactions) * 100
            
            print(f"\nğŸ“‰ æ•°æ®ç¨€ç–æ€§")
            print(f"{'â”€'*60}")
            print(f"  æ½œåœ¨äº¤äº’æ•°:      {potential_interactions:,}")
            print(f"  å®é™…äº¤äº’æ•°:      {total_interactions:,}")
            print(f"  æ•°æ®ç¨€ç–åº¦:      {sparsity:.2f}%")
        
        print(f"\n{'='*60}\n")
        
        return {
            'dataset_name': dataset_name,
            'num_students': num_students,
            'num_questions': num_unique_questions,
            'num_concepts': num_unique_concepts,
            'total_interactions': total_interactions,
            'avg_seq_len': avg_seq_len if sequence_lengths else 0,
            'accuracy': accuracy if all_responses else 0,
            'has_timestamps': len(all_timestamps) > 0
        }
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*60)
    print("  Carnegie Learning æ•°æ®é›†ç»Ÿè®¡åˆ†æ")
    print("="*60)
    
    datasets = {
        'Algebra2005': '/mnt/localssd/pykt-toolkit/data/algebra2005/train_valid_sequences.csv',
        'Bridge2Algebra2006': '/mnt/localssd/pykt-toolkit/data/bridge2algebra2006/train_valid_sequences.csv'
    }
    
    results = []
    
    for dataset_name, data_path in datasets.items():
        result = analyze_dataset(dataset_name, data_path)
        if result:
            results.append(result)
    
    # å¯¹æ¯”æ€»ç»“
    if len(results) >= 2:
        print("\n" + "="*60)
        print("  æ•°æ®é›†å¯¹æ¯”æ€»ç»“")
        print("="*60 + "\n")
        
        print(f"{'æŒ‡æ ‡':<25} {'Algebra2005':>15} {'Bridge2Algebra2006':>20}")
        print("â”€"*60)
        
        for r in results:
            if r['dataset_name'] == 'Algebra2005':
                alg2005 = r
            else:
                bridge2006 = r
        
        if 'alg2005' in locals() and 'bridge2006' in locals():
            print(f"{'å­¦ç”Ÿæ•°':<25} {alg2005['num_students']:>15,} {bridge2006['num_students']:>20,}")
            print(f"{'é—®é¢˜æ•°':<25} {alg2005['num_questions']:>15,} {bridge2006['num_questions']:>20,}")
            print(f"{'æ¦‚å¿µæ•°':<25} {alg2005['num_concepts']:>15,} {bridge2006['num_concepts']:>20,}")
            print(f"{'æ€»äº¤äº’æ•°':<25} {alg2005['total_interactions']:>15,} {bridge2006['total_interactions']:>20,}")
            print(f"{'å¹³å‡åºåˆ—é•¿åº¦':<25} {alg2005['avg_seq_len']:>15.1f} {bridge2006['avg_seq_len']:>20.1f}")
            print(f"{'æ­£ç¡®ç‡ (%)':<25} {alg2005['accuracy']:>15.2f} {bridge2006['accuracy']:>20.2f}")
            print(f"{'æ—¶é—´æˆ³':<25} {'âœ…' if alg2005['has_timestamps'] else 'âŒ':>15} {'âœ…' if bridge2006['has_timestamps'] else 'âŒ':>20}")
            print()
    
    # ä¿å­˜ç»“æœ
    if results:
        result_df = pd.DataFrame(results)
        output_file = '/mnt/localssd/carnegie_datasets_statistics.csv'
        result_df.to_csv(output_file, index=False)
        print(f"âœ… ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {output_file}\n")

if __name__ == '__main__':
    main()

