#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨å®é™…çš„ç­”é¢˜é—´éš”è®¡ç®—Forgetting Score
Î”t_c = æœ€åä¸€æ¬¡ç­”é¢˜æ—¶é—´ - å€’æ•°ç¬¬äºŒæ¬¡ç­”é¢˜æ—¶é—´
"""

import pandas as pd
import numpy as np
from collections import defaultdict
import random

# è®¾ç½®éšæœºç§å­
random.seed(42)
np.random.seed(42)

DATASET = 'nips_task34'
DATA_PATH = '/mnt/localssd/pykt-toolkit/data/nips_task34/test_sequences.csv'

print("="*100)
print(f"ä½¿ç”¨å®é™…ç­”é¢˜é—´éš”è®¡ç®—Forgetting Score")
print(f"æ•°æ®é›†: {DATASET.upper()}")
print(f"Î”t_c = æœ€åä¸€æ¬¡ç­”é¢˜æ—¶é—´ - å€’æ•°ç¬¬äºŒæ¬¡ç­”é¢˜æ—¶é—´")
print("="*100)

# è¾…åŠ©å‡½æ•°
def parse_field(field_str):
    """è§£æCSVå­—æ®µ"""
    if pd.isna(field_str) or field_str == '' or str(field_str) == '-1':
        return []
    return [int(x) for x in str(field_str).split(',') if x.strip() != '-1' and x.strip() != '']

def calculate_forgetting_score(s_tc, delta_t_minutes, tau):
    """è®¡ç®—forgetting score"""
    if delta_t_minutes <= 0:
        return 0.0
    time_factor = delta_t_minutes / (delta_t_minutes + tau)
    return (1 - s_tc) * time_factor

# ç¬¬1æ­¥ï¼šåˆ†æå®é™…æ—¶é—´é—´éš”åˆ†å¸ƒ
print("\nç¬¬1æ­¥ï¼šåˆ†ææ•°æ®é›†ä¸­å®é™…çš„ç­”é¢˜æ—¶é—´é—´éš”åˆ†å¸ƒ")
print("-"*100)

df = pd.read_csv(DATA_PATH)
all_intervals = []

for _, row in df.iterrows():
    timestamps = parse_field(row['timestamps'])
    concepts = parse_field(row['concepts'])
    
    if len(timestamps) < 2:
        continue
    
    # æŒ‰conceptåˆ†ç»„
    concept_timestamps = defaultdict(list)
    for i, cid in enumerate(concepts):
        concept_timestamps[cid].append(timestamps[i])
    
    # è®¡ç®—æ¯ä¸ªconceptçš„æœ€åä¸¤æ¬¡é—´éš”
    for cid, ts_list in concept_timestamps.items():
        if len(ts_list) >= 2:
            ts_list_sorted = sorted(ts_list)
            interval_ms = ts_list_sorted[-1] - ts_list_sorted[-2]
            interval_minutes = interval_ms / (1000 * 60)
            all_intervals.append(interval_minutes)

all_intervals = np.array(all_intervals)

print(f"âœ… å…±æ”¶é›†åˆ° {len(all_intervals)} ä¸ªå®é™…ç­”é¢˜é—´éš”")
print(f"\næ—¶é—´é—´éš”ç»Ÿè®¡ (åˆ†é’Ÿ):")
print(f"  - å¹³å‡å€¼: {np.mean(all_intervals):.2f} åˆ†é’Ÿ = {np.mean(all_intervals)/60:.2f} å°æ—¶ = {np.mean(all_intervals)/(60*24):.2f} å¤©")
print(f"  - ä¸­ä½æ•°: {np.median(all_intervals):.2f} åˆ†é’Ÿ = {np.median(all_intervals)/60:.2f} å°æ—¶ = {np.median(all_intervals)/(60*24):.2f} å¤©")
print(f"  - æ ‡å‡†å·®: {np.std(all_intervals):.2f} åˆ†é’Ÿ = {np.std(all_intervals)/(60*24):.2f} å¤©")
print(f"  - æœ€å°å€¼: {np.min(all_intervals):.2f} åˆ†é’Ÿ = {np.min(all_intervals)/60:.2f} å°æ—¶")
print(f"  - æœ€å¤§å€¼: {np.max(all_intervals):.2f} åˆ†é’Ÿ = {np.max(all_intervals)/(60*24):.2f} å¤©")
print(f"  - 25åˆ†ä½: {np.percentile(all_intervals, 25):.2f} åˆ†é’Ÿ = {np.percentile(all_intervals, 25)/60:.2f} å°æ—¶")
print(f"  - 75åˆ†ä½: {np.percentile(all_intervals, 75):.2f} åˆ†é’Ÿ = {np.percentile(all_intervals, 75)/60:.2f} å°æ—¶")
print(f"  - 90åˆ†ä½: {np.percentile(all_intervals, 90):.2f} åˆ†é’Ÿ = {np.percentile(all_intervals, 90)/(60*24):.2f} å¤©")

# ç¬¬2æ­¥ï¼šé€‰æ‹©åˆé€‚çš„Ï„å€¼
print("\nç¬¬2æ­¥ï¼šæ ¹æ®å®é™…é—´éš”åˆ†å¸ƒé€‰æ‹©åˆé€‚çš„Ï„å€¼")
print("-"*100)

# æ¨èÏ„ä¸ºä¸­ä½æ•°é™„è¿‘ï¼Œè¿™æ ·æ—¶é—´å› å­åœ¨0.5å·¦å³
tau_options = {
    'ä¸­ä½æ•°': np.median(all_intervals),
    'å¹³å‡å€¼': np.mean(all_intervals),
    '75åˆ†ä½æ•°': np.percentile(all_intervals, 75),
    '1å¤© (1440åˆ†é’Ÿ)': 1440,
    '12å°æ—¶ (720åˆ†é’Ÿ)': 720,
    '6å°æ—¶ (360åˆ†é’Ÿ)': 360,
}

print("ä¸åŒÏ„å€¼ä¸‹çš„æ—¶é—´å› å­åˆ†å¸ƒ:")
print(f"{'Ï„é€‰æ‹©':<20} {'Ï„å€¼(åˆ†é’Ÿ)':<15} {'Ï„å€¼(å¤©)':<12} {'ä¸­ä½é—´éš”æ—¶çš„æ—¶é—´å› å­':<25} {'å¹³å‡é—´éš”æ—¶çš„æ—¶é—´å› å­':<25}")
print("-"*100)

for name, tau_val in tau_options.items():
    median_interval = np.median(all_intervals)
    mean_interval = np.mean(all_intervals)
    
    time_factor_median = median_interval / (median_interval + tau_val)
    time_factor_mean = mean_interval / (mean_interval + tau_val)
    
    print(f"{name:<20} {tau_val:<15.2f} {tau_val/(60*24):<12.2f} {time_factor_median:<25.4f} {time_factor_mean:<25.4f}")

# é€‰æ‹©ä¸­ä½æ•°ä½œä¸ºÏ„
tau_selected = np.median(all_intervals)
print(f"\nâœ… æ¨èé€‰æ‹©: Ï„ = {tau_selected:.2f} åˆ†é’Ÿ = {tau_selected/60:.2f} å°æ—¶ = {tau_selected/(60*24):.2f} å¤©")
print(f"   ç†ç”±: è¿™æ ·åœ¨ä¸­ä½æ•°é—´éš”ä¸‹ï¼Œæ—¶é—´å› å­ â‰ˆ 0.5ï¼Œå¯¹é—å¿˜çš„æ•æ„Ÿåº¦é€‚ä¸­")

# ç¬¬3æ­¥ï¼šä½¿ç”¨æ–°çš„æ—¶é—´å·®è®¡ç®—forgetting score
print("\nç¬¬3æ­¥ï¼šä½¿ç”¨å®é™…ç­”é¢˜é—´éš”é‡æ–°è®¡ç®—Forgetting Score")
print("="*100)

def analyze_student_with_actual_intervals(student_row, tau):
    """ä½¿ç”¨å®é™…ç­”é¢˜é—´éš”åˆ†æå­¦ç”Ÿ"""
    questions = parse_field(student_row['questions'])
    concepts = parse_field(student_row['concepts'])
    responses = parse_field(student_row['responses'])
    timestamps = parse_field(student_row['timestamps'])
    
    if len(concepts) < 2:  # éœ€è¦è‡³å°‘2æ¬¡äº¤äº’æ‰èƒ½è®¡ç®—é—´éš”
        return None
    
    # æŒ‰conceptåˆ†ç»„ï¼Œä¿ç•™æ—¶é—´é¡ºåº
    concept_data = defaultdict(list)
    for i in range(len(concepts)):
        concept_data[concepts[i]].append({
            'index': i,
            'question': questions[i],
            'response': responses[i],
            'timestamp': timestamps[i]
        })
    
    # è®¡ç®—æ¯ä¸ªconceptçš„forgetting score
    results = []
    skipped_concepts = 0
    
    for cid, interactions in concept_data.items():
        if len(interactions) < 2:
            skipped_concepts += 1
            continue  # åªæœ‰1æ¬¡äº¤äº’ï¼Œæ— æ³•è®¡ç®—é—´éš”
        
        # æŒ‰æ—¶é—´æ’åº
        interactions_sorted = sorted(interactions, key=lambda x: x['timestamp'])
        
        # è®¡ç®—å†å²æ­£ç¡®ç‡ï¼ˆä½¿ç”¨å€’æ•°ç¬¬äºŒæ¬¡ä¹‹å‰çš„æ‰€æœ‰æ•°æ®ï¼‰
        historical_responses = [inter['response'] for inter in interactions_sorted[:-1]]
        s_tc = sum(historical_responses) / len(historical_responses)
        
        # è®¡ç®—æœ€åä¸¤æ¬¡çš„æ—¶é—´é—´éš”
        last_timestamp = interactions_sorted[-1]['timestamp']
        second_last_timestamp = interactions_sorted[-2]['timestamp']
        delta_t_ms = last_timestamp - second_last_timestamp
        delta_t_minutes = max(0, delta_t_ms / (1000 * 60))
        
        # è®¡ç®—forgetting score
        forgetting_score = calculate_forgetting_score(s_tc, delta_t_minutes, tau)
        
        # æœ€åä¸€æ¬¡æ˜¯å¦ç­”å¯¹
        last_response = interactions_sorted[-1]['response']
        
        results.append({
            'concept_id': cid,
            'total_attempts': len(interactions),
            'historical_correct': sum(historical_responses),
            'historical_accuracy': s_tc,
            'last_response': last_response,
            'delta_t_minutes': delta_t_minutes,
            'delta_t_hours': delta_t_minutes / 60,
            'delta_t_days': delta_t_minutes / (60 * 24),
            'forgetting_score': forgetting_score,
        })
    
    if len(results) == 0:
        return None
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    fs_values = [r['forgetting_score'] for r in results]
    acc_values = [r['historical_accuracy'] for r in results]
    intervals = [r['delta_t_minutes'] for r in results]
    
    diversity_stats = {
        'fs_mean': np.mean(fs_values),
        'fs_std': np.std(fs_values),
        'fs_min': np.min(fs_values),
        'fs_max': np.max(fs_values),
        'fs_range': np.max(fs_values) - np.min(fs_values),
        'acc_mean': np.mean(acc_values),
        'interval_mean_minutes': np.mean(intervals),
        'interval_std_minutes': np.std(intervals),
    }
    
    return {
        'uid': student_row['uid'],
        'total_interactions': len(concepts),
        'unique_concepts': len(concept_data),
        'concepts_with_2plus': len(results),
        'skipped_concepts': skipped_concepts,
        'overall_accuracy': sum(responses) / len(responses),
        'concept_results': results,
        'diversity_stats': diversity_stats
    }

# é€‰æ‹©æœ‰è¶³å¤Ÿäº¤äº’çš„å­¦ç”Ÿ
print("\nç­›é€‰æ¡ä»¶ï¼šé€‰æ‹©æœ‰5ä¸ªä»¥ä¸Šconceptsä¸”æ¯ä¸ªconceptè‡³å°‘2æ¬¡äº¤äº’çš„å­¦ç”Ÿ")
qualified_students = []

for uid in df['uid'].unique():
    student_row = df[df['uid'] == uid].iloc[0]
    analysis = analyze_student_with_actual_intervals(student_row, tau_selected)
    if analysis and analysis['concepts_with_2plus'] >= 5:
        qualified_students.append(uid)

print(f"âœ… å…±æœ‰ {len(qualified_students)} ä¸ªå­¦ç”Ÿæ»¡è¶³æ¡ä»¶")

# éšæœºé€‰æ‹©5ä¸ªå­¦ç”Ÿ
selected_students = random.sample(qualified_students, min(5, len(qualified_students)))
print(f"âœ… éšæœºé€‰æ‹©5ä¸ªå­¦ç”Ÿè¿›è¡Œè¯¦ç»†åˆ†æ:")
for i, uid in enumerate(selected_students, 1):
    print(f"   {i}. å­¦ç”ŸID: {uid}")

# åˆ†ææ¯ä¸ªå­¦ç”Ÿ
print("\n" + "="*100)
print("ç¬¬4æ­¥ï¼šè¯¦ç»†åˆ†æç»“æœ")
print("="*100)

student_analyses = []
for uid in selected_students:
    student_row = df[df['uid'] == uid].iloc[0]
    analysis = analyze_student_with_actual_intervals(student_row, tau_selected)
    if analysis:
        student_analyses.append(analysis)

# å±•ç¤ºæ¯ä¸ªå­¦ç”Ÿçš„ç»“æœ
for idx, analysis in enumerate(student_analyses, 1):
    print(f"\n{'='*100}")
    print(f"å­¦ç”Ÿ #{idx}: ID {analysis['uid']}")
    print(f"{'='*100}")
    
    div = analysis['diversity_stats']
    print(f"\næ€»ä½“ä¿¡æ¯:")
    print(f"  - æ€»äº¤äº’æ•°: {analysis['total_interactions']}")
    print(f"  - å”¯ä¸€concepts: {analysis['unique_concepts']}")
    print(f"  - å¯è®¡ç®—FSçš„concepts: {analysis['concepts_with_2plus']} (éœ€è¦â‰¥2æ¬¡äº¤äº’)")
    print(f"  - è·³è¿‡çš„concepts: {analysis['skipped_concepts']} (åªæœ‰1æ¬¡äº¤äº’)")
    print(f"  - æ€»ä½“æ­£ç¡®ç‡: {analysis['overall_accuracy']*100:.1f}%")
    
    print(f"\nç­”é¢˜é—´éš”ç»Ÿè®¡:")
    print(f"  - å¹³å‡é—´éš”: {div['interval_mean_minutes']/60:.2f} å°æ—¶ = {div['interval_mean_minutes']/(60*24):.2f} å¤©")
    print(f"  - é—´éš”æ ‡å‡†å·®: {div['interval_std_minutes']/60:.2f} å°æ—¶")
    
    print(f"\nForgetting Scoreç»Ÿè®¡:")
    print(f"  - å¹³å‡å€¼: {div['fs_mean']:.4f}")
    print(f"  - æ ‡å‡†å·®: {div['fs_std']:.4f}")
    print(f"  - èŒƒå›´: [{div['fs_min']:.4f}, {div['fs_max']:.4f}]")
    print(f"  - å·®å€¼: {div['fs_range']:.4f}")
    
    results = analysis['concept_results']
    results_sorted = sorted(results, key=lambda x: x['forgetting_score'], reverse=True)
    
    print(f"\nå‰10ä¸ªæœ€éœ€è¦å¤ä¹ çš„concepts (Forgetting Scoreæœ€é«˜):")
    print(f"{'-'*100}")
    print(f"{'Concept':<10} {'æ¬¡æ•°':<6} {'å†å²æ­£ç¡®ç‡':<12} {'æœ€åç­”é¢˜':<10} "
          f"{'ç­”é¢˜é—´éš”':<18} {'FS':<12} {'åˆ†ç±»':<10}")
    print(f"{'-'*100}")
    
    for result in results_sorted[:10]:
        cid = result['concept_id']
        attempts = result['total_attempts']
        hist_acc = result['historical_accuracy'] * 100
        last_resp = "âœ…" if result['last_response'] == 1 else "âŒ"
        interval_str = f"{result['delta_t_hours']:.1f}h"
        if result['delta_t_days'] >= 1:
            interval_str = f"{result['delta_t_days']:.1f}d"
        fs = result['forgetting_score']
        
        # åˆ†ç±»
        if fs >= 0.3:
            category = "ğŸ”´ ç´§æ€¥"
        elif fs >= 0.2:
            category = "ğŸŸ  é‡è¦"
        elif fs >= 0.1:
            category = "ğŸŸ¡ ä¸€èˆ¬"
        else:
            category = "ğŸŸ¢ ç»´æŒ"
        
        print(f"{cid:<10} {attempts:<6} {hist_acc:<11.1f}% {last_resp:<10} "
              f"{interval_str:<18} {fs:<12.4f} {category:<10}")
    
    # åˆ†æï¼šé—´éš”æ—¶é—´å’Œé—å¿˜çš„å…³ç³»
    print(f"\nå…³é”®æ´å¯Ÿ:")
    print(f"{'-'*100}")
    
    # 1. çŸ­é—´éš” vs é•¿é—´éš”
    short_interval = [r for r in results if r['delta_t_hours'] < 24]
    long_interval = [r for r in results if r['delta_t_hours'] >= 24]
    
    if short_interval:
        avg_fs_short = np.mean([r['forgetting_score'] for r in short_interval])
        print(f"  çŸ­é—´éš” (<24å°æ—¶): {len(short_interval)}ä¸ªconcepts, å¹³å‡FS = {avg_fs_short:.4f}")
    
    if long_interval:
        avg_fs_long = np.mean([r['forgetting_score'] for r in long_interval])
        print(f"  é•¿é—´éš” (â‰¥24å°æ—¶): {len(long_interval)}ä¸ªconcepts, å¹³å‡FS = {avg_fs_long:.4f}")
    
    # 2. æŒæ¡å¥½ vs æŒæ¡å·®
    high_mastery = [r for r in results if r['historical_accuracy'] >= 0.7]
    low_mastery = [r for r in results if r['historical_accuracy'] <= 0.3]
    
    if high_mastery:
        avg_fs_high = np.mean([r['forgetting_score'] for r in high_mastery])
        print(f"  æŒæ¡è‰¯å¥½ (æ­£ç¡®ç‡â‰¥70%): {len(high_mastery)}ä¸ªconcepts, å¹³å‡FS = {avg_fs_high:.4f}")
    
    if low_mastery:
        avg_fs_low = np.mean([r['forgetting_score'] for r in low_mastery])
        print(f"  æŒæ¡è¾ƒå·® (æ­£ç¡®ç‡â‰¤30%): {len(low_mastery)}ä¸ªconcepts, å¹³å‡FS = {avg_fs_low:.4f}")

# ç¬¬5æ­¥ï¼šè·¨å­¦ç”Ÿå¯¹æ¯”
print("\n" + "="*100)
print("ç¬¬5æ­¥ï¼šè·¨å­¦ç”Ÿå¯¹æ¯”")
print("="*100)

print(f"\n{'å­¦ç”ŸID':<12} {'Concepts':<10} {'å¹³å‡é—´éš”':<15} {'FSå‡å€¼':<12} "
      f"{'FSæ ‡å‡†å·®':<12} {'FSèŒƒå›´':<25}")
print("-"*100)

for analysis in student_analyses:
    uid = analysis['uid']
    n_concepts = analysis['concepts_with_2plus']
    div = analysis['diversity_stats']
    
    interval_str = f"{div['interval_mean_minutes']/60:.1f}h"
    if div['interval_mean_minutes'] >= 60*24:
        interval_str = f"{div['interval_mean_minutes']/(60*24):.1f}d"
    
    fs_range_str = f"[{div['fs_min']:.3f}, {div['fs_max']:.3f}]"
    
    print(f"{uid:<12} {n_concepts:<10} {interval_str:<15} {div['fs_mean']:<12.4f} "
          f"{div['fs_std']:<12.4f} {fs_range_str:<25}")

# ç¬¬6æ­¥ï¼šå…³é”®æ´å¯Ÿ
print("\n" + "="*100)
print("ç¬¬6æ­¥ï¼šä½¿ç”¨å®é™…ç­”é¢˜é—´éš”çš„å…³é”®æ´å¯Ÿ")
print("="*100)

print(f"""
ä½¿ç”¨"æœ€åä¸€æ¬¡å’Œå€’æ•°ç¬¬äºŒæ¬¡ç­”é¢˜é—´éš”"è®¡ç®—Forgetting Scoreçš„ä¼˜åŠ¿ï¼š

1. âœ… åæ˜ çœŸå®å­¦ä¹ èŠ‚å¥
   - åŸºäºå­¦ç”Ÿå®é™…çš„ç­”é¢˜é—´éš”
   - ä¸éœ€è¦å‡è®¾"å½“å‰è¯„ä¼°æ—¶é—´"
   - æ›´ç¬¦åˆå®é™…åº”ç”¨åœºæ™¯

2. âœ… Ï„å€¼é€‰æ‹©æ›´åˆç†
   - Ï„ = {tau_selected/(60*24):.2f}å¤© (æ•°æ®ä¸­ä½æ•°)
   - åœ¨ä¸­ä½æ•°é—´éš”ä¸‹ï¼Œæ—¶é—´å› å­ â‰ˆ 0.5
   - å¯¹é—å¿˜çš„æ•æ„Ÿåº¦é€‚ä¸­

3. âœ… å·®å¼‚æ¥æºæ›´æ¸…æ™°
   - æŒæ¡ç¨‹åº¦å·®å¼‚ (s_{{t,c}}): å½±å“ (1 - s_{{t,c}})
   - ç­”é¢˜é—´éš”å·®å¼‚ (Î”t_c): å½±å“æ—¶é—´å› å­
   - ä¸¤ä¸ªå› ç´ éƒ½ç›´æ¥æ¥è‡ªæ•°æ®

4. âœ… å¯é¢„æµ‹æ€§æ›´å¼º
   - å¯ä»¥é¢„æµ‹ï¼šå¦‚æœå­¦ç”Ÿåœ¨ä¸‹æ¬¡ç­”é¢˜å‰é—´éš”Xå¤©ï¼Œé—å¿˜ç¨‹åº¦å¦‚ä½•
   - å¯ç”¨äºæ¨èç³»ç»Ÿï¼šå»ºè®®å­¦ç”Ÿåœ¨åˆé€‚çš„æ—¶é—´é—´éš”å¤ä¹ 

5. âš ï¸  æ³¨æ„äº‹é¡¹
   - éœ€è¦æ¯ä¸ªconceptè‡³å°‘2æ¬¡äº¤äº’
   - æœ€åä¸€æ¬¡ç­”é¢˜ç»“æœå¯ä½œä¸ºéªŒè¯ï¼ˆå®é™…é—å¿˜ä¸å¦ï¼‰

æ¨èä½¿ç”¨åœºæ™¯ï¼š
â€¢ ä¸ªæ€§åŒ–å­¦ä¹ é—´éš”æ¨è (Spaced Repetition)
â€¢ é¢„æµ‹å­¦ç”Ÿåœ¨ä¸åŒå¤ä¹ é—´éš”ä¸‹çš„è¡¨ç°
â€¢ ä¼˜åŒ–è¯¾ç¨‹è®¾è®¡ä¸­çš„ç»ƒä¹ é¢˜é—´éš”
""")

print("="*100)
print("âœ… åˆ†æå®Œæˆï¼")
print("="*100)

