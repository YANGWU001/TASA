#!/usr/bin/env python3
"""
åˆ†ædelta_tåˆ†å¸ƒå¹¶æ¨èåˆç†çš„tauå€¼
"""

import os
import json
import numpy as np
import pandas as pd
from collections import defaultdict

def load_and_analyze_delta_t(dataset_name):
    """åŠ è½½æ•°æ®å¹¶åˆ†ædelta_tåˆ†å¸ƒ"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š åˆ†æ {dataset_name.upper()}")
    print('='*80)
    
    data_dir = f'/mnt/localssd/pykt-toolkit/data/{dataset_name}'
    
    all_data = []
    
    # åŠ è½½train+valid
    train_valid_file = os.path.join(data_dir, 'train_valid_sequences.csv')
    if os.path.exists(train_valid_file):
        df_tv = pd.read_csv(train_valid_file)
        all_data.append(df_tv)
    
    # åŠ è½½test
    test_file = os.path.join(data_dir, 'test_sequences.csv')
    if os.path.exists(test_file):
        df_test = pd.read_csv(test_file)
        all_data.append(df_test)
    
    if not all_data:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®æ–‡ä»¶")
        return None
    
    df_all = pd.concat(all_data, ignore_index=True)
    
    # æ”¶é›†æ‰€æœ‰çš„delta_t
    all_delta_t = []
    
    for idx, row in df_all.iterrows():
        # è§£ætimestamps
        if 'timestamps' in row and pd.notna(row['timestamps']):
            timestamps = [int(t) for t in str(row['timestamps']).split(',')]
            
            if len(timestamps) >= 2:
                # è®¡ç®—ç›¸é‚»timestampsçš„å·®å€¼
                for i in range(1, len(timestamps)):
                    delta = timestamps[i] - timestamps[i-1]
                    if delta > 0:
                        all_delta_t.append(delta)
    
    if not all_delta_t:
        print(f"âŒ æ²¡æœ‰æœ‰æ•ˆçš„delta_tæ•°æ®")
        return None
    
    # ç»Ÿè®¡åˆ†æ
    all_delta_t = np.array(all_delta_t)
    
    print(f"\nğŸ“ˆ Delta_t ç»Ÿè®¡ (åŸå§‹å€¼):")
    print(f"  æ ·æœ¬æ•°: {len(all_delta_t):,}")
    print(f"  Min: {np.min(all_delta_t):.2f}")
    print(f"  Max: {np.max(all_delta_t):.2f}")
    print(f"  Mean: {np.mean(all_delta_t):.2f}")
    print(f"  Median (P50): {np.median(all_delta_t):.2f}")
    print(f"  P25: {np.percentile(all_delta_t, 25):.2f}")
    print(f"  P75: {np.percentile(all_delta_t, 75):.2f}")
    print(f"  P90: {np.percentile(all_delta_t, 90):.2f}")
    print(f"  P95: {np.percentile(all_delta_t, 95):.2f}")
    
    # åˆ¤æ–­æ—¶é—´æˆ³çš„å•ä½
    max_val = np.max(all_delta_t)
    if max_val > 1e9:
        unit = "æ¯«ç§’"
        scale = 1000 * 60  # ms -> minutes
    elif max_val > 1e6:
        unit = "ç§’"
        scale = 60  # seconds -> minutes
    else:
        unit = "åºåˆ—ç´¢å¼•æˆ–åˆ†é’Ÿ"
        scale = 1
    
    print(f"\nğŸ” æ¨æ–­æ—¶é—´å•ä½: {unit}")
    
    # è½¬æ¢ä¸ºåˆ†é’Ÿ
    delta_t_minutes = all_delta_t / scale
    
    print(f"\nğŸ“ˆ Delta_t ç»Ÿè®¡ (åˆ†é’Ÿ):")
    print(f"  Mean: {np.mean(delta_t_minutes):.2f} åˆ†é’Ÿ = {np.mean(delta_t_minutes)/60:.2f} å°æ—¶")
    print(f"  Median (P50): {np.median(delta_t_minutes):.2f} åˆ†é’Ÿ = {np.median(delta_t_minutes)/60:.2f} å°æ—¶")
    print(f"  P75: {np.percentile(delta_t_minutes, 75):.2f} åˆ†é’Ÿ = {np.percentile(delta_t_minutes, 75)/60:.2f} å°æ—¶")
    print(f"  P90: {np.percentile(delta_t_minutes, 90):.2f} åˆ†é’Ÿ = {np.percentile(delta_t_minutes, 90)/60:.2f} å°æ—¶")
    
    # æ¨ètauå€¼ï¼ˆä½¿ç”¨P50æˆ–P75ï¼‰
    tau_p50 = np.median(delta_t_minutes)
    tau_p75 = np.percentile(delta_t_minutes, 75)
    
    print(f"\nğŸ’¡ æ¨èçš„Tauå€¼:")
    print(f"  ä¿å®ˆé€‰æ‹© (P50): {tau_p50:.2f} åˆ†é’Ÿ = {tau_p50/60:.2f} å°æ—¶ = {tau_p50/60/24:.4f} å¤©")
    print(f"  å®½æ¾é€‰æ‹© (P75): {tau_p75:.2f} åˆ†é’Ÿ = {tau_p75/60:.2f} å°æ—¶ = {tau_p75/60/24:.4f} å¤©")
    
    return {
        'dataset': dataset_name,
        'n_samples': len(all_delta_t),
        'unit': unit,
        'scale': scale,
        'mean_minutes': np.mean(delta_t_minutes),
        'median_minutes': np.median(delta_t_minutes),
        'p75_minutes': np.percentile(delta_t_minutes, 75),
        'p90_minutes': np.percentile(delta_t_minutes, 90),
        'tau_p50': tau_p50,
        'tau_p75': tau_p75,
        'tau_p50_days': tau_p50 / 60 / 24,
        'tau_p75_days': tau_p75 / 60 / 24
    }

def main():
    print("="*80)
    print("ğŸ“Š åˆ†ææ‰€æœ‰æ•°æ®é›†çš„Delta_tåˆ†å¸ƒå¹¶æ¨èTauå€¼")
    print("="*80)
    
    datasets = ['assist2017', 'nips_task34', 'algebra2005', 'bridge2algebra2006']
    
    results = []
    for dataset in datasets:
        result = load_and_analyze_delta_t(dataset)
        if result:
            results.append(result)
    
    # æ±‡æ€»æ¨è
    print(f"\n\n{'='*80}")
    print("ğŸ“‹ æ¨èTauå€¼æ±‡æ€» (å»ºè®®ä½¿ç”¨P50ä½œä¸ºä¿å®ˆä¼°è®¡)")
    print("="*80)
    print()
    print(f"{'æ•°æ®é›†':<20} {'Tau (P50åˆ†é’Ÿ)':<20} {'Tau (P50å¤©)':<20}")
    print("-"*80)
    
    for r in results:
        dataset_display = r['dataset'].replace('bridge2algebra2006', 'bridge2006')
        print(f"{dataset_display:<20} {r['tau_p50']:<20.2f} {r['tau_p50_days']:<20.6f}")
    
    print()
    print("="*80)
    print("ğŸ’¡ å»ºè®®:")
    print("  1. ä½¿ç”¨P50 (ä¸­ä½æ•°) ä½œä¸ºtauï¼Œä½¿å¾—ä¸€åŠçš„é—´éš”ä¼šæœ‰æ˜¾è‘—çš„é—å¿˜åˆ†æ•°")
    print("  2. å¦‚æœæƒ³è¦æ›´æ•æ„Ÿçš„é—å¿˜æ£€æµ‹ï¼Œå¯ä»¥ä½¿ç”¨æ›´å°çš„tau")
    print("  3. å¦‚æœå½“å‰FSå¤ªå°ï¼Œè¯´æ˜tauå¤ªå¤§äº†")
    print("="*80)

if __name__ == '__main__':
    main()

