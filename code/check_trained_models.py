#!/usr/bin/env python
"""
æ£€æŸ¥è®­ç»ƒå¥½çš„KTæ¨¡å‹å¹¶å±•ç¤ºå¦‚ä½•ä½¿ç”¨
ä¸éœ€è¦å¯¼å…¥PyKTï¼Œåªæ£€æŸ¥æ–‡ä»¶å’Œè¯»å–ç»“æœ
"""

import os
import json
import pandas as pd

def find_all_trained_models():
    """æŸ¥æ‰¾æ‰€æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹"""
    base_dir = '/mnt/localssd/pykt-toolkit/examples/saved_model'
    
    if not os.path.exists(base_dir):
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {base_dir}")
        return []
    
    models = []
    
    for dirname in os.listdir(base_dir):
        if '_saved_model' in dirname:
            model_dir = os.path.join(base_dir, dirname)
            
            # è§£æç›®å½•å
            parts = dirname.split('_')
            if len(parts) >= 2:
                dataset = parts[0]
                model_name = parts[1]
                
                # æ£€æŸ¥checkpoint
                ckpt_files = [f for f in os.listdir(model_dir) if f.endswith('.ckpt')]
                config_exists = os.path.exists(os.path.join(model_dir, 'config.json'))
                
                if ckpt_files and config_exists:
                    # è¯»å–é…ç½®
                    with open(os.path.join(model_dir, 'config.json'), 'r') as f:
                        config = json.load(f)
                    
                    data_config = config.get('data_config', {})
                    
                    models.append({
                        'dataset': dataset,
                        'model': model_name,
                        'dir': model_dir,
                        'checkpoint': ckpt_files[0],
                        'num_q': data_config.get('num_q', 'N/A'),
                        'num_c': data_config.get('num_c', 'N/A'),
                    })
    
    return models

def check_training_logs(model_dir):
    """æ£€æŸ¥è®­ç»ƒæ—¥å¿—"""
    log_files = ['train.log', 'training.log', 'output.log']
    
    for log_file in log_files:
        log_path = os.path.join(model_dir, log_file)
        if os.path.exists(log_path):
            with open(log_path, 'r') as f:
                lines = f.readlines()
                # æ‰¾æœ€åå‡ è¡Œï¼ˆé€šå¸¸åŒ…å«æœ€ç»ˆç»“æœï¼‰
                return ''.join(lines[-20:])
    
    return None

def main():
    print("="*100)
    print("ğŸ” æ£€æŸ¥è®­ç»ƒå¥½çš„KTæ¨¡å‹")
    print("="*100)
    
    models = find_all_trained_models()
    
    if not models:
        print("\nâŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
        return
    
    print(f"\nâœ… æ‰¾åˆ° {len(models)} ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹:\n")
    
    # æŒ‰æ•°æ®é›†åˆ†ç»„
    datasets = {}
    for m in models:
        if m['dataset'] not in datasets:
            datasets[m['dataset']] = []
        datasets[m['dataset']].append(m)
    
    # æ˜¾ç¤ºæ¯ä¸ªæ•°æ®é›†çš„æ¨¡å‹
    for dataset, dataset_models in sorted(datasets.items()):
        print(f"\n{'='*100}")
        print(f"ğŸ“š æ•°æ®é›†: {dataset.upper()}")
        print(f"{'='*100}")
        
        for m in dataset_models:
            print(f"\n  ğŸ¤– æ¨¡å‹: {m['model'].upper()}")
            print(f"     ç›®å½•: {os.path.basename(m['dir'])}")
            print(f"     Checkpoint: {m['checkpoint']}")
            print(f"     num_q={m['num_q']}, num_c={m['num_c']}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰nohupæ—¥å¿—
            nohup_files = []
            parent_dir = '/mnt/localssd/pykt-toolkit/examples'
            for f in os.listdir(parent_dir):
                if 'nohup' in f and dataset in f and m['model'] in f:
                    nohup_files.append(os.path.join(parent_dir, f))
            
            if nohup_files:
                print(f"     è®­ç»ƒæ—¥å¿—: {os.path.basename(nohup_files[0])}")
                
                # è¯»å–æœ€åå‡ è¡Œçœ‹æ˜¯å¦æœ‰AUC/ACC
                try:
                    with open(nohup_files[0], 'r') as f:
                        lines = f.readlines()
                        for line in lines[-30:]:
                            if 'auc' in line.lower() or 'acc' in line.lower():
                                print(f"     {line.strip()}")
                except:
                    pass
    
    print(f"\n{'='*100}")
    print(f"ğŸ’¡ å¦‚ä½•ä½¿ç”¨è¿™äº›æ¨¡å‹:")
    print(f"{'='*100}\n")
    
    print(f"1ï¸âƒ£  æŸ¥çœ‹è®­ç»ƒæ—¥å¿—å’Œæ€§èƒ½:")
    print(f"   cd /mnt/localssd/pykt-toolkit/examples")
    print(f"   tail -100 nohup_assist2017_lpkt_*.out | grep -i 'auc\\|acc'\n")
    
    print(f"2ï¸âƒ£  ä½¿ç”¨æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼ˆæ ‡å‡†æ–¹å¼ï¼‰:")
    print(f"   cd /mnt/localssd/pykt-toolkit/examples")
    print(f"   python wandb_lpkt_train.py \\")
    print(f"       --dataset_name=assist2017 \\")
    print(f"       --fold=0 \\")
    print(f"       --use_wandb=0\n")
    
    print(f"3ï¸âƒ£  æ¨¡å‹å·²ç»å¯ä»¥ç”¨äº:")
    print(f"   âœ… Test setæ€§èƒ½è¯„ä¼°ï¼ˆAUC/ACCï¼‰")
    print(f"   âœ… é¢„æµ‹å­¦ç”Ÿä¸‹ä¸€é¢˜è¡¨ç°")
    print(f"   âœ… æ¨¡å‹å¯¹æ¯”ç ”ç©¶")
    print(f"   âœ… Forgetting Scoreè®¡ç®—ï¼ˆä½†å†å²å‡†ç¡®ç‡æ›´ç®€å•ï¼‰\n")
    
    print(f"4ï¸âƒ£  å¯¹äºForgetting Score:")
    print(f"   âœ… æ¨èï¼šç»§ç»­ä½¿ç”¨å†å²å‡†ç¡®ç‡ï¼ˆå·²éªŒè¯æœ‰æ•ˆï¼Œ58.3% vs 30%ï¼‰")
    print(f"   âš ï¸  æ¨¡å‹é¢„æµ‹ï¼šéœ€è¦è§£å†³Question IDæ˜ å°„é—®é¢˜\n")
    
    print(f"{'='*100}")
    print(f"ğŸ“– è¯¦ç»†æ–‡æ¡£:")
    print(f"   /mnt/localssd/HOW_TO_USE_TRAINED_MODELS.md")
    print(f"{'='*100}")

if __name__ == '__main__':
    main()

