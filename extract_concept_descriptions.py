#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æå–å’Œå±•ç¤ºæ•°æ®é›†ä¸­çš„Conceptæè¿°ä¿¡æ¯
"""

import pandas as pd
import json
import os
from collections import Counter

def analyze_ednet_concepts(data_dir):
    """
    åˆ†æEdNetçš„conceptä¿¡æ¯
    """
    print(f"\n{'='*80}")
    print(f"ğŸ“Š EdNet æ•°æ®é›† - Conceptåˆ†æ")
    print(f"{'='*80}\n")
    
    # è¯»å–keyid2idx.json
    keyid_path = os.path.join(data_dir, "keyid2idx.json")
    with open(keyid_path, 'r') as f:
        keyid2idx = json.load(f)
    
    concepts_map = keyid2idx.get('concepts', {})
    
    print(f"ğŸ“‹ Concept ID æ˜ å°„:")
    print(f"  - æ€»Conceptæ•°: {len(concepts_map)}")
    
    # EdNetçš„conceptæ˜¯æ•°å­—IDï¼ˆè¡¨ç¤ºçŸ¥è¯†ç‚¹tagï¼‰
    # åŸå§‹EdNetæ•°æ®æ²¡æœ‰æä¾›conceptçš„æ–‡å­—æè¿°
    print(f"\nâš ï¸  **EdNetæ•°æ®é›†çš„å±€é™æ€§**:")
    print(f"  - Conceptsåªæ˜¯æ•°å­—ID (å¦‚: 1, 2, 3...188)")
    print(f"  - åŸå§‹æ•°æ®é›†**æ²¡æœ‰æä¾›**conceptçš„æ–‡å­—æè¿°")
    print(f"  - è¿™äº›IDå¯¹åº”EdNetå¹³å°å†…éƒ¨çš„çŸ¥è¯†ç‚¹æ ‡ç­¾")
    print(f"  - æ— æ³•çŸ¥é“æ¯ä¸ªconceptçš„å…·ä½“å«ä¹‰ï¼ˆå¦‚ \"ä»£æ•°\"ã€\"å‡ ä½•\" ç­‰ï¼‰")
    
    # å±•ç¤ºéƒ¨åˆ†concept ID
    sorted_concepts = sorted([(k, v) for k, v in concepts_map.items()], key=lambda x: x[1])
    print(f"\n  Concept ID ç¤ºä¾‹ï¼ˆåŸå§‹æ ‡ç­¾ -> ç´¢å¼•ï¼‰:")
    for orig_tag, idx in sorted_concepts[:20]:
        print(f"    - Tag {orig_tag} -> Index {idx}")
    
    print(f"\nğŸ’¡ å»ºè®®:")
    print(f"  - å¯ä»¥è”ç³»EdNetæ•°æ®é›†æä¾›æ–¹è·å–æ ‡ç­¾æè¿°")
    print(f"  - æˆ–æ ¹æ®ç›¸å…³é—®é¢˜å†…å®¹æ¨æ–­conceptå«ä¹‰")
    print(f"  - åœ¨ç ”ç©¶ä¸­å¯ä»¥ç”¨\"Concept X\"æ¥æŒ‡ä»£")
    
    return concepts_map


def analyze_assistments_concepts(data_dir):
    """
    åˆ†æASSISTments2017çš„concept (skill) ä¿¡æ¯
    """
    print(f"\n{'='*80}")
    print(f"ğŸ“Š ASSISTments2017 æ•°æ®é›† - Concept (Skill) åˆ†æ")
    print(f"{'='*80}\n")
    
    # è¯»å–åŸå§‹æ•°æ®
    raw_data_path = os.path.join(data_dir, "anonymized_full_release_competition_dataset.csv")
    print(f"ğŸ“‚ è¯»å–åŸå§‹æ•°æ®: {raw_data_path}")
    print(f"â³ æ­£åœ¨åŠ è½½ï¼ˆå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰...")
    
    df = pd.read_csv(raw_data_path)
    
    # æå–skillä¿¡æ¯
    skills = df['skill'].dropna().unique()
    skill_counts = df['skill'].value_counts()
    
    print(f"\nâœ… ASSISTments2017 **æœ‰å®Œæ•´çš„Skillæ–‡å­—æè¿°**ï¼")
    print(f"\nğŸ“‹ Skillç»Ÿè®¡:")
    print(f"  - æ€»Skillæ•°: {len(skills)}")
    print(f"  - æ€»äº¤äº’æ•°: {len(df):,}")
    
    # è¯»å–keyid2idx.jsonæŸ¥çœ‹æ˜ å°„
    keyid_path = os.path.join(data_dir, "keyid2idx.json")
    with open(keyid_path, 'r') as f:
        keyid2idx = json.load(f)
    
    concepts_map = keyid2idx.get('concepts', {})
    
    # åˆ›å»ºåå‘æ˜ å°„ï¼šç´¢å¼• -> skillåç§°
    idx_to_skill = {v: k for k, v in concepts_map.items()}
    
    print(f"\nğŸ” æœ€å¸¸è§çš„20ä¸ªSkillsï¼ˆæœ‰æ–‡å­—æè¿°ï¼‰:")
    print(f"{'='*80}")
    for i, (skill, count) in enumerate(skill_counts.head(20).items(), 1):
        # æ‰¾åˆ°å¯¹åº”çš„ç´¢å¼•
        idx = concepts_map.get(skill, '?')
        print(f"{i:2d}. [{idx:3}] {skill}")
        print(f"     å‡ºç°æ¬¡æ•°: {count:,} ({count/len(df)*100:.2f}%)")
    
    print(f"\nğŸ“„ æ‰€æœ‰Skillsåˆ—è¡¨ï¼ˆæŒ‰ç´¢å¼•æ’åºï¼‰:")
    print(f"{'='*80}")
    sorted_skills = sorted([(idx, skill) for skill, idx in concepts_map.items()])
    for idx, skill in sorted_skills:
        count = skill_counts.get(skill, 0)
        print(f"  [{idx:3d}] {skill:50s} ({count:,} æ¬¡)")
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    output_path = "/tmp/assistments2017_skill_descriptions.txt"
    with open(output_path, 'w') as f:
        f.write("ASSISTments2017 Skills æè¿°åˆ—è¡¨\n")
        f.write("="*80 + "\n\n")
        for idx, skill in sorted_skills:
            count = skill_counts.get(skill, 0)
            f.write(f"[{idx:3d}] {skill:50s} ({count:,} æ¬¡)\n")
    
    print(f"\nâœ… Skillsæè¿°å·²ä¿å­˜åˆ°: {output_path}")
    
    return concepts_map, idx_to_skill, skill_counts


def create_concept_mapping_summary(assistments_skills):
    """
    åˆ›å»ºconcept IDåˆ°æè¿°çš„æ˜ å°„æ‘˜è¦
    """
    print(f"\n{'='*80}")
    print(f"ğŸ“Š Conceptæè¿°å¯ç”¨æ€§æ€»ç»“")
    print(f"{'='*80}\n")
    
    print("| æ•°æ®é›† | Conceptæ•°é‡ | æœ‰æ–‡å­—æè¿° | æè¿°ç±»å‹ |")
    print("|--------|-------------|-----------|----------|")
    print("| EdNet | 188 | âŒ å¦ | ä»…æ•°å­—ID (1-188) |")
    print(f"| ASSISTments2017 | {len(assistments_skills)} | âœ… æ˜¯ | è‹±æ–‡skillåç§° |")
    
    print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print(f"\n  **å¯¹äºEdNet:**")
    print(f"  - Conceptä»¥æ•°å­—IDè¡¨ç¤ºï¼Œå¦‚ \"Concept 7\"ã€\"Concept 24\"")
    print(f"  - å¯ä»¥é€šè¿‡åˆ†æé«˜é¢‘conceptå¯¹åº”çš„é¢˜ç›®å†…å®¹æ¥æ¨æ–­å«ä¹‰")
    print(f"  - åœ¨è®ºæ–‡/æŠ¥å‘Šä¸­ç›´æ¥ä½¿ç”¨\"Concept X\"å³å¯")
    
    print(f"\n  **å¯¹äºASSISTments2017:**")
    print(f"  - Conceptæœ‰å®Œæ•´è‹±æ–‡æè¿°ï¼Œå¦‚:")
    print(f"    â€¢ \"properties-of-geometric-figures\" (å‡ ä½•å›¾å½¢æ€§è´¨)")
    print(f"    â€¢ \"sum-of-interior-angles-more-than-3-sides\" (å¤šè¾¹å½¢å†…è§’å’Œ)")
    print(f"    â€¢ \"transformations-rotations\" (å˜æ¢-æ—‹è½¬)")
    print(f"  - é¢„å¤„ç†æ—¶ä¼šè½¬æ¢ä¸ºæ•°å­—ç´¢å¼•")
    print(f"  - å¯ä»¥é€šè¿‡keyid2idx.jsonæŸ¥çœ‹æ˜ å°„å…³ç³»")


if __name__ == "__main__":
    print("ğŸ” Conceptæè¿°ä¿¡æ¯æå–")
    print("=" * 80)
    
    # åˆ†æEdNet
    ednet_dir = "/mnt/localssd/pykt-toolkit/data/ednet"
    ednet_concepts = analyze_ednet_concepts(ednet_dir)
    
    # åˆ†æASSISTments2017
    assistments_dir = "/mnt/localssd/pykt-toolkit/data/assist2017"
    assistments_concepts, idx_to_skill, skill_counts = analyze_assistments_concepts(assistments_dir)
    
    # åˆ›å»ºæ€»ç»“
    create_concept_mapping_summary(assistments_concepts)
    
    print(f"\n{'='*80}")
    print("âœ… åˆ†æå®Œæˆï¼")
    print(f"{'='*80}")

