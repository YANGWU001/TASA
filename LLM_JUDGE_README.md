# LLM as Judge: Personalization Evaluation

## ğŸ“‹ åŠŸèƒ½è¯´æ˜

ä½¿ç”¨**gpt-5-chat**ä½œä¸ºjudgeï¼Œè¯„ä¼°ä¸åŒtutoringæ–¹æ³•çš„dialogueä¸ªæ€§åŒ–ç¨‹åº¦ã€‚

### æ¯”è¾ƒé€»è¾‘
- **Target Methods**: å„ç§tutoringæ–¹æ³•ï¼ˆTASA, TutorLLM, PSS-MV, MathChatç­‰ï¼‰
- **Baseline**: Vanilla-ICLï¼ˆä¸‰ç§backboneç‰ˆæœ¬ï¼‰
- **è¯„ä¼°æ ‡å‡†**: æ ¹æ®å­¦ç”Ÿçš„personaå’Œmemoryï¼Œåˆ¤æ–­å“ªä¸ªdialogueæ›´ä¸ªæ€§åŒ–
- **è¾“å‡º**: Win Rate = Targetèƒœåˆ©æ¬¡æ•° / æ€»æ¯”è¾ƒæ¬¡æ•°

### è¯„ä¼°ç»´åº¦
1. **Adaptation to Student's Level**: éš¾åº¦å’ŒèŠ‚å¥æ˜¯å¦é€‚åˆå­¦ç”Ÿ
2. **Relevance to Past Learning**: æ˜¯å¦åˆ©ç”¨å­¦ç”Ÿçš„å†å²å­¦ä¹ ç»éªŒ
3. **Pedagogical Alignment**: æ•™å­¦é£æ ¼æ˜¯å¦åŒ¹é…å­¦ç”Ÿéœ€æ±‚
4. **Appropriate Scaffolding**: æ”¯æŒç¨‹åº¦æ˜¯å¦åˆé€‚
5. **Engagement Strategy**: ç­–ç•¥æ˜¯å¦å¯¹è¯¥å­¦ç”Ÿæœ‰æ•ˆ

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. æµ‹è¯•å•ä¸ªå­¦ç”Ÿï¼ˆå¿«é€ŸéªŒè¯ï¼‰
```bash
cd /mnt/localssd
python3 test_llm_judge.py
```

### 2. è¿è¡Œå®Œæ•´è¯„ä¼°ï¼ˆæ‰€æœ‰methods Ã— æ‰€æœ‰datasetsï¼‰
```bash
cd /mnt/localssd
nohup python3 llm_as_judge_personalization.py > logs/llm_judge.log 2>&1 &
```

### 3. è¯„ä¼°ç‰¹å®šmethod
```python
from llm_as_judge_personalization import batch_judge

# ä¾‹å¦‚ï¼šåªè¯„ä¼°TASA-llamaåœ¨assist2017ä¸Š
result = batch_judge('TASA-llama', dataset='assist2017', max_workers=20)
```

## ğŸ“Š è¾“å‡ºç»“æœ

### ç»“æœæ–‡ä»¶ä½ç½®
```
/mnt/localssd/llm_judge_results/
â”œâ”€â”€ TASA-llama_vs_Vanilla-ICL-llama_assist2017.json
â”œâ”€â”€ TutorLLM_vs_Vanilla-ICL_assist2017.json
â””â”€â”€ ...
```

### ç»“æœæ ¼å¼
```json
{
  "target_method": "TASA-llama",
  "baseline_method": "Vanilla-ICL-llama",
  "dataset": "assist2017",
  "backbone": "llama",
  "total_comparisons": 10,
  "target_wins": 7,
  "baseline_wins": 2,
  "ties": 1,
  "win_rate": 0.7,
  "detailed_results": [...]
}
```

## ğŸ¯ Target Methodsåˆ—è¡¨

### æŒ‰Backboneåˆ†ç»„

**GPT-oss-120b** (æ— åç¼€):
- Vanilla-ICL
- TutorLLM
- PSS-MV
- MathChat

**Llama3.1-8B-Instruct** (-llama):
- Vanilla-ICL-llama
- TutorLLM-llama
- PSS-MV-llama
- MathChat-llama
- TASA-llama
- TASA-woForgetting-llama
- TASA-woMemory-llama
- TASA-woPersona-llama

**Qwen3-4B-Instruct** (-qwen):
- Vanilla-ICL-qwen
- TutorLLM-qwen
- PSS-MV-qwen
- MathChat-qwen
- TASA-lambda0.5-qwen

**GPT Lambda Ablation**:
- TASA-lambda0.5-gpt

## âš™ï¸ é…ç½®å‚æ•°

- **Judge Model**: gpt-5-chat
- **Temperature**: 0.0 (ç¡®å®šæ€§è¾“å‡º)
- **Max Tokens**: æ— é™åˆ¶ï¼ˆå…è®¸å®Œæ•´è¾“å‡ºé•¿dialogueåˆ†æï¼‰
- **Max Workers**: 20ï¼ˆå¹¶è¡Œè¯„ä¼°20ä¸ªå­¦ç”Ÿï¼‰

## ğŸ“ˆ é¢„è®¡æ—¶é—´

- **å•ä¸ªå­¦ç”Ÿ**: ~30-60ç§’ï¼ˆå–å†³äºdialogueé•¿åº¦ï¼‰
- **å•ä¸ªmethodÃ—dataset**: ~5-15åˆ†é’Ÿï¼ˆ10ä¸ªå­¦ç”Ÿ Ã— 30-60ç§’ / 20 workersï¼‰
- **æ‰€æœ‰methodsÃ—datasets**: ~2-4å°æ—¶

## ğŸ” Judge Promptæ ¸å¿ƒé€»è¾‘

Judgeä¼šæ”¶åˆ°ï¼š
1. å­¦ç”Ÿçš„personaï¼ˆå­¦ä¹ é£æ ¼ã€å†å²è¡¨ç°ï¼‰
2. å­¦ç”Ÿçš„memoryï¼ˆè¿‡å»çš„å­¦ä¹ è®°å½•ï¼‰
3. Target dialogueï¼ˆæ ¼å¼åŒ–ä¸ºStudent/Tutoräº¤æ›¿ï¼‰
4. Baseline dialogueï¼ˆæ ¼å¼åŒ–ä¸ºStudent/Tutoräº¤æ›¿ï¼‰

ç„¶ååˆ¤æ–­å“ªä¸ªdialogueåœ¨ä»¥ä¸‹æ–¹é¢æ›´å¥½ï¼š
- æ˜¯å¦é’ˆå¯¹è¯¥å­¦ç”Ÿçš„ç‰¹ç‚¹è°ƒæ•´æ•™å­¦
- æ˜¯å¦åˆ©ç”¨äº†å­¦ç”Ÿçš„å†å²å­¦ä¹ ç»éªŒ
- æ˜¯å¦é‡‡ç”¨äº†é€‚åˆè¯¥å­¦ç”Ÿçš„æ•™å­¦ç­–ç•¥

è¾“å‡ºæ ¼å¼ï¼š
```
Winner: [A or B or Tie]
Reasoning: [è¯¦ç»†åˆ†æ]
Confidence: [High/Medium/Low]
```

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **ç›¸åŒbackboneæ¯”è¾ƒ**: Targetå’Œbaselineå¿…é¡»ä½¿ç”¨ç›¸åŒçš„LLM backbone
2. **Dialogueæ ¼å¼**: è‡ªåŠ¨æ ¼å¼åŒ–ä¸º"Student: ...\nTutor: ..."
3. **ç¼ºå¤±æ•°æ®å¤„ç†**: å¦‚æœdialogueæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯¥å­¦ç”Ÿä¼šè¢«è·³è¿‡
4. **Tokené™åˆ¶**: ä¸è®¾ç½®max_tokensï¼Œå…è®¸judgeå……åˆ†åˆ†æé•¿dialogue

## ğŸ› ï¸ æ•…éšœæ’æŸ¥

### é—®é¢˜1: dialogueæ–‡ä»¶æ‰¾ä¸åˆ°
```bash
# æ£€æŸ¥dialogueç›®å½•ç»“æ„
ls -la /mnt/localssd/bank/dialogue/TASA-llama/assist2017/
```

### é—®é¢˜2: APIè°ƒç”¨å¤±è´¥
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $API_KEY
echo $ENDPOINT
```

### é—®é¢˜3: ç»“æœè§£æå¤±è´¥
æŸ¥çœ‹logs/llm_judge.logä¸­çš„è¯¦ç»†é”™è¯¯ä¿¡æ¯

