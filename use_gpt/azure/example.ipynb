{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502213f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code BHAM7TGWU to authenticate.\n",
      "{\n",
      "  \"id\": \"chatcmpl-BfVmRe1PnmWsA5nhw2W0EwkCw4bCw\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Hello! How can I assist you today?\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": []\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1749233311,\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_ee1d74bde0\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 10,\n",
      "    \"prompt_tokens\": 9,\n",
      "    \"total_tokens\": 19,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# pip install openai azure-identity\n",
    "\n",
    "import time\n",
    "\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DeviceCodeCredential\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "endpoint = 'https://epic-dms-aoai.openai.azure.com/'\n",
    "\n",
    "scope = \"https://cognitiveservices.azure.com/.default\"\n",
    "\n",
    "tp = DeviceCodeCredential()\n",
    "tr = None\n",
    "client = None\n",
    "tp.authenticate()\n",
    "tr = tp.get_token(scope)\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    azure_ad_token = tr.token,\n",
    "    api_version = \"2025-04-01-preview\",  # Use the latest API version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a225786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# ðŸŽ¯ å‡½æ•°ï¼šå¯¹ä¸€ä¸ª prompt å‘èµ·è¯·æ±‚ï¼ˆåŒ…å« system promptï¼‰\n",
    "\n",
    "def run_prompt(system_prompt, user_prompt):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=messages\n",
    "        )\n",
    "        return user_prompt, completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return user_prompt, f\"[ERROR] {str(e)}\"\n",
    "\n",
    "# âœ¨ å¤šçº¿ç¨‹å¤„ç†å¤šä¸ª prompt\n",
    "def run_multiple_prompts(prompts, system_prompt, max_workers=5):\n",
    "    results = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(run_prompt, system_prompt, p) for p in prompts\n",
    "        ]\n",
    "\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing Prompts\", ncols=100):\n",
    "            prompt, response = future.result()\n",
    "            # print(f\"Prompt: {prompt}\\nResponse: {response}\\n\")\n",
    "            results.append((prompt, response))\n",
    "\n",
    "    return results\n",
    "\n",
    "deployment = \"gpt-4o\"\n",
    "# âœ… ç¤ºä¾‹\n",
    "prompts = [\n",
    "    \"Hello World\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"Explain quantum computing in simple terms.\",\n",
    "    \"Give me a creative idea for a short film.\",\n",
    "    \"What's a good lens for night-time shooting?\"\n",
    "]\n",
    "\n",
    "system_prompt = \"You are a helpful assistant who always answers concisely.\"\n",
    "\n",
    "# ðŸš€ æ‰§è¡Œ\n",
    "result = run_multiple_prompts(prompts, system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18735ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
