#!/usr/bin/env python3
"""
ç”Ÿæˆ overall.json - æ•´åˆæ‰€æœ‰æ–¹æ³•çš„forgetting score
ä»¥ history.json ä½œä¸ºåŸºå‡†ï¼ŒåŒ…å«æ‰€æœ‰æ¨¡å‹çš„ s_tc å’Œ fs
"""

import os
import json
import argparse
from collections import defaultdict

def load_method_data(dataset, method):
    """åŠ è½½æŸä¸ªæ–¹æ³•çš„æ•°æ®"""
    file_path = f'/mnt/localssd/bank/forgetting/{dataset}/{method}.json'
    
    if not os.path.exists(file_path):
        print(f"  âš ï¸  {method}.json ä¸å­˜åœ¨ï¼Œè·³è¿‡")
        return None
    
    try:
        with open(file_path) as f:
            data = json.load(f)
        print(f"  âœ… {method:10} - {len(data)} å­¦ç”Ÿ")
        return data
    except Exception as e:
        print(f"  âŒ {method:10} - åŠ è½½å¤±è´¥: {e}")
        return None

def generate_overall(dataset):
    """ç”Ÿæˆoverall.json"""
    print("="*100)
    print(f"ğŸ“Š ç”Ÿæˆ Overall.json for {dataset.upper()}")
    print("="*100)
    print()
    
    # 1. åŠ è½½æ‰€æœ‰æ–¹æ³•çš„æ•°æ®
    print("ğŸ“‚ åŠ è½½æ•°æ®...")
    methods = ['history', 'lpkt', 'dkt', 'akt', 'simplekt']
    method_data = {}
    
    for method in methods:
        data = load_method_data(dataset, method)
        if data is not None:
            method_data[method] = data
    
    if 'history' not in method_data:
        print("âŒ History.json ä¸å­˜åœ¨ï¼Œæ— æ³•ä½œä¸ºåŸºå‡†ï¼")
        return
    
    print(f"\nâœ… æˆåŠŸåŠ è½½ {len(method_data)} ä¸ªæ–¹æ³•")
    print()
    
    # 2. ä»¥historyä¸ºåŸºå‡†ï¼Œæ•´åˆæ‰€æœ‰æ–¹æ³•
    print("ğŸ”„ æ•´åˆæ•°æ®...")
    history_data = method_data['history']
    overall_data = {}
    
    total_students = len(history_data)
    total_concepts = 0
    missing_stats = defaultdict(int)
    
    for uid, concepts in history_data.items():
        overall_data[uid] = {}
        
        for concept_text, history_info in concepts.items():
            total_concepts += 1
            
            # åˆ›å»ºconceptæ¡ç›®ï¼ŒåŒ…å«æ‰€æœ‰æ–¹æ³•çš„s_tcå’Œfs
            concept_entry = {
                'methods': {}
            }
            
            # æ·»åŠ æ‰€æœ‰æ–¹æ³•çš„s_tcå’Œfs
            for method in methods:
                if method not in method_data:
                    missing_stats[method] += 1
                    continue
                
                # æ£€æŸ¥è¯¥å­¦ç”Ÿçš„è¯¥conceptåœ¨è¯¥æ–¹æ³•ä¸­æ˜¯å¦å­˜åœ¨
                if uid in method_data[method] and concept_text in method_data[method][uid]:
                    method_info = method_data[method][uid][concept_text]
                    concept_entry['methods'][method] = {
                        's_tc': method_info.get('s_tc'),
                        'fs': method_info.get('fs')
                    }
                else:
                    missing_stats[method] += 1
            
            # æ·»åŠ å…±åŒå­—æ®µï¼ˆæ¥è‡ªhistoryï¼‰
            concept_entry['delta_t'] = history_info.get('delta_t')
            concept_entry['tau'] = history_info.get('tau')
            concept_entry['last_response'] = history_info.get('last_response')
            concept_entry['num_attempts'] = history_info.get('num_attempts')
            concept_entry['level'] = history_info.get('level')  # ä½¿ç”¨historyçš„level
            
            overall_data[uid][concept_text] = concept_entry
    
    print(f"  âœ… æ•´åˆå®Œæˆ: {total_students} å­¦ç”Ÿ, {total_concepts} conceptæ¡ç›®")
    
    # 3. ç»Ÿè®¡ç¼ºå¤±æƒ…å†µ
    if missing_stats:
        print(f"\nğŸ“Š æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡:")
        for method in methods:
            if method in method_data:
                missing = missing_stats.get(method, 0)
                coverage = (total_concepts - missing) / total_concepts * 100
                print(f"  {method:10} - è¦†ç›–ç‡: {coverage:5.1f}% ({total_concepts - missing}/{total_concepts})")
    
    # 4. ä¿å­˜
    print(f"\nğŸ’¾ ä¿å­˜åˆ°Bank...")
    output_dir = f'/mnt/localssd/bank/forgetting/{dataset}'
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, 'overall.json')
    
    with open(output_file, 'w') as f:
        json.dump(overall_data, f, indent=2)
    
    file_size = os.path.getsize(output_file) / 1024 / 1024
    print(f"  âœ… å·²ä¿å­˜: {output_file}")
    print(f"  ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.1f}MB")
    
    # 5. ç¤ºä¾‹æ•°æ®
    print(f"\nğŸ“‹ æ•°æ®ç¤ºä¾‹:")
    sample_uid = list(overall_data.keys())[0]
    sample_concept = list(overall_data[sample_uid].keys())[0]
    sample_data = overall_data[sample_uid][sample_concept]
    
    print(f"  å­¦ç”ŸID: {sample_uid}")
    print(f"  Concept: {sample_concept}")
    print(f"  Methods:")
    for method, values in sample_data['methods'].items():
        print(f"    {method:10} - s_tc={values['s_tc']:.4f}, fs={values['fs']:.4f}")
    print(f"  å…±åŒå­—æ®µ:")
    print(f"    delta_t={sample_data['delta_t']}, tau={sample_data['tau']}")
    print(f"    last_response={sample_data['last_response']}, num_attempts={sample_data['num_attempts']}")
    print(f"    level={sample_data['level']}")

def main():
    parser = argparse.ArgumentParser(description='Generate overall.json with all methods')
    parser.add_argument('--dataset', type=str, required=True,
                       help='Dataset name')
    
    args = parser.parse_args()
    
    generate_overall(args.dataset)
    
    print("\n" + "="*100)
    print("âœ… å®Œæˆï¼")
    print("="*100)

if __name__ == '__main__':
    main()

