"""
TASA RAGæ¨¡å—
ä»personaå’Œmemoryä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œå¹¶è¿›è¡Œé‡æ’
"""

import json
import numpy as np
from typing import List, Dict, Tuple
from FlagEmbedding import BGEM3FlagModel, FlagReranker
import os

from tasa_config import *

class TASARAG:
    def __init__(self):
        """åˆå§‹åŒ–RAGæ¨¡å—"""
        print("ğŸ”§ åˆå§‹åŒ–TASA RAGæ¨¡å—...")
        
        # åŠ è½½embeddingæ¨¡å‹ (ä½¿ç”¨GPU)
        print(f"   åŠ è½½Embeddingæ¨¡å‹: {EMBEDDING_MODEL}")
        self.embed_model = BGEM3FlagModel(EMBEDDING_MODEL, use_fp16=True, device='cuda')
        
        # åŠ è½½rerankeræ¨¡å‹ (ä½¿ç”¨GPU)
        print(f"   åŠ è½½Rerankeræ¨¡å‹: {RERANKER_MODEL}")
        self.reranker = FlagReranker(RERANKER_MODEL, use_fp16=True, device='cuda')
        
        print("âœ… TASA RAGæ¨¡å—åˆå§‹åŒ–å®Œæˆ (GPUåŠ é€Ÿ)")
    
    def load_student_data(self, student_id: int, dataset: str, concept_text: str) -> Tuple[List[Dict], List[Dict]]:
        """
        åŠ è½½å­¦ç”Ÿçš„personaå’Œmemoryæ•°æ®
        
        Returns:
            persona_items: List of {description, keywords, description_emb, keywords_emb, stats, ...}
            memory_items: List of {description, keywords, description_emb, keywords_emb, timestamp, ...}
        """
        # åŠ è½½persona
        persona_file = f"{PERSONA_DIR}/{dataset}/data/{student_id}.json"
        with open(persona_file) as f:
            persona_data = json.load(f)
        
        # åŠ è½½persona embeddings
        persona_desc_emb_file = f"{PERSONA_DIR}/{dataset}/embeddings/{student_id}_description.npz"
        persona_kw_emb_file = f"{PERSONA_DIR}/{dataset}/embeddings/{student_id}_keywords.npz"
        
        persona_desc_embs = np.load(persona_desc_emb_file, allow_pickle=True)['embeddings']
        persona_kw_embs = np.load(persona_kw_emb_file, allow_pickle=True)['embeddings']
        
        # ç»„è£…persona items
        persona_items = []
        for i, concept_data in enumerate(persona_data):
            if concept_data['concept_text'] == concept_text:
                # åªåŠ è½½ç›¸å…³conceptçš„personaï¼ˆä½†å®é™…ä¸Šæˆ‘ä»¬å¯èƒ½æƒ³è¦æ‰€æœ‰ç›¸å…³çš„ï¼‰
                pass
            persona_items.append({
                'concept_text': concept_data['concept_text'],
                'description': concept_data['description'],
                'keywords': concept_data['keywords'],
                'description_emb': persona_desc_embs[i],
                'keywords_emb': persona_kw_embs[i],
                'stats': concept_data['stats']
            })
        
        # åŠ è½½memory
        memory_file = f"{MEMORY_DIR}/{dataset}/data/{student_id}.json"
        with open(memory_file) as f:
            memory_data = json.load(f)
        
        # åŠ è½½memory embeddings
        memory_desc_emb_file = f"{MEMORY_DIR}/{dataset}/embeddings/{student_id}_description.npz"
        memory_desc_embs = np.load(memory_desc_emb_file)['embeddings']
        
        # æ³¨æ„ï¼šmemoryå¯èƒ½æ²¡æœ‰keywords embeddingsï¼Œæˆ‘ä»¬åªç”¨description
        memory_items = []
        for i, mem in enumerate(memory_data):
            if mem['concept_text'] == concept_text:
                # åªä¿ç•™ç›®æ ‡conceptçš„memory
                memory_items.append({
                    'concept_text': mem['concept_text'],
                    'description': mem['description'],
                    'keywords': mem.get('keywords', mem['description']),  # å¦‚æœæ²¡æœ‰keywordsç”¨description
                    'description_emb': memory_desc_embs[i],
                    'keywords_emb': memory_desc_embs[i],  # memoryå¯èƒ½æ²¡æœ‰å•ç‹¬çš„keywords embedding
                    'timestamp': mem.get('timestamp', 0),
                    'response': mem.get('response', 0)
                })
        
        return persona_items, memory_items
    
    def compute_similarity(self, query_emb: np.ndarray, desc_emb: np.ndarray, 
                          kw_emb: np.ndarray, lambda_weight: float = LAMBDA_WEIGHT) -> float:
        """
        è®¡ç®—ç›¸ä¼¼åº¦: total_score = lambda * sim(query, desc) + (1-lambda) * sim(query, kw)
        """
        # ä½™å¼¦ç›¸ä¼¼åº¦
        sim_desc = np.dot(query_emb, desc_emb) / (np.linalg.norm(query_emb) * np.linalg.norm(desc_emb))
        sim_kw = np.dot(query_emb, kw_emb) / (np.linalg.norm(query_emb) * np.linalg.norm(kw_emb))
        
        total_score = lambda_weight * sim_desc + (1 - lambda_weight) * sim_kw
        return float(total_score)
    
    def retrieve_and_rerank(self, query: str, student_id: int, dataset: str, 
                           concept_text: str) -> Tuple[List[Dict], List[Dict]]:
        """
        RAGæ£€ç´¢å¹¶é‡æ’
        
        Returns:
            top_persona: Top 3 persona items
            top_memory: Top 3 memory items
        """
        # 1. ç¼–ç query
        query_emb = self.embed_model.encode(query)['dense_vecs']
        
        # 2. åŠ è½½å­¦ç”Ÿæ•°æ®
        persona_items, memory_items = self.load_student_data(student_id, dataset, concept_text)
        
        # 3. è®¡ç®—personaç›¸ä¼¼åº¦å¹¶æ’åº
        persona_scores = []
        for item in persona_items:
            score = self.compute_similarity(query_emb, item['description_emb'], item['keywords_emb'])
            persona_scores.append((score, item))
        
        # å–top-K
        persona_scores.sort(key=lambda x: x[0], reverse=True)
        top_k_persona = persona_scores[:TOP_K_RETRIEVE]
        
        # 4. è®¡ç®—memoryç›¸ä¼¼åº¦å¹¶æ’åº
        memory_scores = []
        for item in memory_items:
            score = self.compute_similarity(query_emb, item['description_emb'], item['keywords_emb'])
            memory_scores.append((score, item))
        
        memory_scores.sort(key=lambda x: x[0], reverse=True)
        top_k_memory = memory_scores[:TOP_K_RETRIEVE]
        
        # 5. ä½¿ç”¨rerankerç²¾æ’personaï¼ˆåªç”¨descriptionï¼‰
        if len(top_k_persona) > 0:
            persona_pairs = [[query, item['description']] for _, item in top_k_persona]
            persona_rerank_scores = self.reranker.compute_score(persona_pairs, normalize=True)
            
            # é‡æ–°æ’åº
            persona_reranked = list(zip(persona_rerank_scores, [item for _, item in top_k_persona]))
            persona_reranked.sort(key=lambda x: x[0], reverse=True)
            top_persona = [item for _, item in persona_reranked[:TOP_K_RERANK]]
        else:
            top_persona = []
        
        # 6. ä½¿ç”¨rerankerç²¾æ’memory
        if len(top_k_memory) > 0:
            memory_pairs = [[query, item['description']] for _, item in top_k_memory]
            memory_rerank_scores = self.reranker.compute_score(memory_pairs, normalize=True)
            
            # é‡æ–°æ’åº
            memory_reranked = list(zip(memory_rerank_scores, [item for _, item in top_k_memory]))
            memory_reranked.sort(key=lambda x: x[0], reverse=True)
            top_memory = [item for _, item in memory_reranked[:TOP_K_RERANK]]
        else:
            top_memory = []
        
        return top_persona, top_memory

# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    rag = TASARAG()
    
    # æµ‹è¯•æ£€ç´¢
    query = "I want to learn about rotations in geometry"
    top_persona, top_memory = rag.retrieve_and_rerank(
        query=query,
        student_id=1,
        dataset="assist2017",
        concept_text="transformations-rotations"
    )
    
    print(f"\næŸ¥è¯¢: {query}")
    print(f"\nTop 3 Persona:")
    for i, item in enumerate(top_persona, 1):
        print(f"{i}. {item['description']}")
    
    print(f"\nTop 3 Memory:")
    for i, item in enumerate(top_memory, 1):
        print(f"{i}. {item['description']}")

