"""
Baseline 2: MathChat
ä½¿ç”¨calculatoråŠŸèƒ½ï¼Œè§£é‡Šç­”æ¡ˆå¹¶ç”Ÿæˆé—®é¢˜
"""

import json
import os
import re
from openai import OpenAI
from typing import List, Dict
from student_roleplay_evaluation import load_session

# æ ¹æ®ç¯å¢ƒå˜é‡é€‰æ‹©é…ç½®æ–‡ä»¶
_config_module = os.environ.get('TASA_CONFIG', 'tasa_config')
if _config_module == 'tasa_config_llama':
    from tasa_config_llama import ENDPOINT, GPT_ENDPOINT, API_KEY, TUTOR_MODEL, STUDENT_MODEL
elif _config_module == 'tasa_config_qwen':
    from tasa_config_qwen import ENDPOINT, GPT_ENDPOINT, API_KEY, TUTOR_MODEL, STUDENT_MODEL
elif _config_module == 'tasa_config_gpt':
    from tasa_config_gpt import ENDPOINT, API_KEY, TUTOR_MODEL, STUDENT_MODEL
    GPT_ENDPOINT = ENDPOINT
else:
    from tasa_config import ENDPOINT, API_KEY, TUTOR_MODEL, STUDENT_MODEL
    GPT_ENDPOINT = ENDPOINT

from llm_client_unified import UnifiedLLMClient

def get_backbone_suffix():
    """æ ¹æ®TUTOR_MODELç¡®å®šbackboneåç¼€"""
    if 'llama' in TUTOR_MODEL.lower():
        return '-llama'
    elif 'qwen' in TUTOR_MODEL.lower():
        return '-qwen'
    else:
        return ''  # GPTé»˜è®¤æ— åç¼€

class MathChatTutor:
    def __init__(self):
        """åˆå§‹åŒ–MathChat Tutor"""
        self.tutor_client = UnifiedLLMClient(TUTOR_MODEL)
        self.openai_client = OpenAI(api_key=API_KEY, base_url=GPT_ENDPOINT)
        self.model = TUTOR_MODEL
        print("ğŸ”§ åˆå§‹åŒ–MathChat Tutor (with calculator)")
    
    def execute_calculations(self, text: str) -> str:
        """è§£æå¹¶æ‰§è¡Œ<calculate>æ ‡ç­¾ä¸­çš„è®¡ç®—"""
        def replace_calc(match):
            expr = match.group(1)
            try:
                result = eval(expr, {"__builtins__": {}}, {})
                return f"{expr} = {result}"
            except:
                return f"{expr} = [è®¡ç®—é”™è¯¯]"
        
        return re.sub(r'<calculate>(.*?)</calculate>', replace_calc, text)
    
    def conduct_tutoring_session(self, student_id: int, dataset: str,
                                concept_text: str, student_system_prompt: str) -> bool:
        """è¿›è¡Œ10è½®æ•™å­¦å¯¹è¯"""
        print(f"\nğŸ“ MathChat Tutoring Session")
        print(f"   å­¦ç”ŸID: {student_id}")
        print(f"   Concept: {concept_text}")
        
        dialogue = []
        
        # Round 1: å­¦ç”Ÿè¯·æ±‚
        student_request = f"I want to learn about {concept_text}"
        dialogue.append({
            "role": "user",
            "content": student_request,
            "round": 0
        })
        
        # è¿›è¡Œ10è½®æ•™å­¦
        for round_num in range(1, 11):
            print(f"ğŸ“š Round {round_num}")
            
            # æ„å»ºdialogue context
            dialogue_context = "\n".join([
                f"{'Student' if msg['role']=='user' else 'Tutor'}: {msg['content'][:200]}..."
                for msg in dialogue[-6:]
            ])
            
            if round_num == 1:
                prompt = f"""You are a math tutor with access to a calculator.
The student wants to learn about {concept_text}.

Task:
1) Generate a clear practice question about {concept_text}
2) You can use <calculate>expression</calculate> for any computation you need

Provide an engaging question."""
            else:
                last_student_answer = dialogue[-1]['content']
                
                prompt = f"""You are a math tutor with access to a calculator.

Dialogue: {dialogue_context}

Student's Last Answer:
{last_student_answer}

Task:
1) Explain student's answer with step-by-step reasoning (use <calculate>expression</calculate> for computations)
2) Generate next question

Provide educational feedback and the next question."""
            
            try:
                content = self.tutor_client.chat_completion(
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7,
                    max_tokens=500
                )
                
                if content:
                    tutor_response = content
                else:
                    print(f"   âš ï¸ Tutorå›å¤ä¸ºNoneï¼Œè·³è¿‡")
                    return False
                
                # æ‰§è¡Œè®¡ç®—
                tutor_response_with_calc = self.execute_calculations(tutor_response)
                
                dialogue.append({
                    "role": "assistant",
                    "content": tutor_response_with_calc,
                    "round": round_num
                })
                
            except Exception as e:
                print(f"   âŒ Tutorç”Ÿæˆå¤±è´¥: {e}")
                return False
            
            # å­¦ç”Ÿå›ç­”
            if round_num < 10:
                student_prompt_text = f"""Based on the tutor's question, provide your answer.

Tutor's Question:
{tutor_response_with_calc}

Provide your answer."""
                
                try:
                    response = self.openai_client.chat.completions.create(
                        model=STUDENT_MODEL,  # Student roleplayå›ºå®šä½¿ç”¨GPT
                        messages=[
                            {"role": "system", "content": student_system_prompt},
                            {"role": "user", "content": student_prompt_text}
                        ],
                        temperature=0.7,
                        max_tokens=300
                    )
                    
                    if response.choices[0].message.content:
                        student_answer = response.choices[0].message.content
                    else:
                        student_answer = "I don't know"
                    
                    dialogue.append({
                        "role": "user",
                        "content": student_answer,
                        "round": round_num + 1
                    })
                    
                except Exception as e:
                    print(f"   âŒ Studentå›ç­”å¤±è´¥: {e}")
                    return False
        
        # ä¿å­˜å¯¹è¯
        backbone_suffix = get_backbone_suffix()
        dialogue_dir = f'/mnt/localssd/bank/dialogue/MathChat{backbone_suffix}/{dataset}'
        os.makedirs(dialogue_dir, exist_ok=True)
        
        dialogue_file = f'{dialogue_dir}/{student_id}-{concept_text}.json'
        
        with open(dialogue_file, 'w') as f:
            json.dump({
                "student_id": student_id,
                "dataset": dataset,
                "concept": concept_text,
                "method": "MathChat",
                "total_rounds": 10,
                "dialogue": dialogue
            }, f, indent=2)
        
        print(f"   âœ… Dialogueå·²ä¿å­˜")
        return True

