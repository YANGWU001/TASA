#!/usr/bin/env python3
"""
TASAæ‰¹é‡è¯„ä¼°è„šæœ¬ - Best-of-2ç­–ç•¥
å¯¹ç­›é€‰åçš„å­¦ç”Ÿè¿›è¡Œæ‰¹é‡è¯„ä¼°ï¼Œæ¯ä¸ªå­¦ç”Ÿæµ‹è¯•2æ¬¡ï¼Œé€‰æ‹©Learning Gainæœ€å¤§çš„
"""

import json
import os
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
import numpy as np

from student_roleplay_evaluation import build_student_system_prompt, load_session
from tasa_tutoring import TASATutor
from tasa_evaluation_best_of_two import TASABestOfTwoEvaluator

# å…¨å±€é”ç”¨äºæ‰“å°å’Œæ¨¡å‹åˆå§‹åŒ–
print_lock = Lock()
model_init_lock = Lock()

# å…¨å±€æ¨¡å‹ç¼“å­˜ï¼ˆæ¯ä¸ªçº¿ç¨‹ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶åˆå§‹åŒ–ï¼‰
import threading
thread_local = threading.local()

def safe_print(*args, **kwargs):
    """çº¿ç¨‹å®‰å…¨çš„æ‰“å°"""
    with print_lock:
        print(*args, **kwargs)

def get_tutor():
    """è·å–çº¿ç¨‹æœ¬åœ°çš„TASATutorå®ä¾‹"""
    if not hasattr(thread_local, 'tutor'):
        with model_init_lock:
            safe_print(f"   [Thread-{threading.current_thread().ident}] åˆå§‹åŒ–TASATutor...")
            thread_local.tutor = TASATutor()
    return thread_local.tutor

def get_backbone_suffix():
    """æ ¹æ®TUTOR_MODELè·å–backboneåç¼€ï¼Œç”¨äºåŒºåˆ†dialogueç›®å½•"""
    from tasa_config import TUTOR_MODEL
    if 'llama' in TUTOR_MODEL.lower():
        return '-llama'
    elif 'qwen' in TUTOR_MODEL.lower():
        return '-qwen'
    else:
        return ''  # gpt-oss-120b ä¸åŠ åç¼€ï¼Œä¿æŒå‘åå…¼å®¹

def get_evaluator():
    """è·å–çº¿ç¨‹æœ¬åœ°çš„TASABestOfTwoEvaluatorå®ä¾‹"""
    if not hasattr(thread_local, 'evaluator'):
        with model_init_lock:
            safe_print(f"   [Thread-{threading.current_thread().ident}] åˆå§‹åŒ–Evaluator...")
            thread_local.evaluator = TASABestOfTwoEvaluator()
    return thread_local.evaluator

def process_single_student(student_id: int, dataset: str):
    """
    å¤„ç†å•ä¸ªå­¦ç”Ÿçš„å®Œæ•´æµç¨‹
    1. æ£€æŸ¥/ç”Ÿæˆdialogueï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™ç”Ÿæˆï¼‰
    2. è¿›è¡Œ2æ¬¡post-testè¯„ä¼°
    3. é€‰æ‹©æœ€ä½³ç»“æœ
    
    æ³¨æ„ï¼šä½¿ç”¨çº¿ç¨‹æœ¬åœ°å­˜å‚¨+é”ä¿æŠ¤åˆå§‹åŒ–ï¼Œæ”¯æŒå¹¶è¡Œ
    """
    try:
        safe_print(f"\n{'='*80}")
        safe_print(f"ğŸ“ å¼€å§‹å¤„ç†å­¦ç”Ÿ {student_id}")
        safe_print(f"{'='*80}")
        
        # åŠ è½½session
        session_file = f'/mnt/localssd/bank/session/{dataset}/{student_id}.json'
        session = load_session(session_file)
        concept_text = session['concept_text']
        
        # Step 1: æ£€æŸ¥dialogueæ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™ç”Ÿæˆ
        # æ ¹æ®backboneä½¿ç”¨ä¸åŒçš„dialogueç›®å½•ï¼Œæ ¹æ®FS_METHODä½¿ç”¨ä¸åŒå­ç›®å½•
        from tasa_config import FORGETTING_SCORE_METHOD
        backbone_suffix = get_backbone_suffix()
        dialogue_file = f'/mnt/localssd/bank/dialogue/TASA{backbone_suffix}/{dataset}/{FORGETTING_SCORE_METHOD}/{student_id}-{concept_text}.json'
        
        if not os.path.exists(dialogue_file):
            safe_print(f"   ğŸ“š æ­£åœ¨ç”Ÿæˆdialogue (backbone{backbone_suffix})...")
            student_prompt = build_student_system_prompt(session)
            
            # è·å–çº¿ç¨‹æœ¬åœ°çš„tutorå®ä¾‹ï¼ˆè‡ªåŠ¨åˆå§‹åŒ–ï¼‰
            tutor = get_tutor()
            
            try:
                dialogue = tutor.conduct_tutoring_session(
                    student_id=student_id,
                    dataset=dataset,
                    concept_text=concept_text,
                    student_system_prompt=student_prompt
                )
                tutor.save_dialogue(dialogue, student_id, concept_text, dataset, backbone_suffix=backbone_suffix)
                safe_print(f"   âœ… Dialogueç”Ÿæˆå®Œæˆ")
            except Exception as e:
                safe_print(f"   âŒ Dialogueç”Ÿæˆå¤±è´¥: {e}")
                return None
        else:
            safe_print(f"   âœ… Dialogueå·²å­˜åœ¨ (backbone{backbone_suffix})")
        
        # Step 2: è¿›è¡ŒBest-of-2è¯„ä¼°
        safe_print(f"   ğŸ“Š å¼€å§‹Best-of-2è¯„ä¼°...")
        
        # è·å–çº¿ç¨‹æœ¬åœ°çš„evaluatorå®ä¾‹ï¼ˆè‡ªåŠ¨åˆå§‹åŒ–ï¼‰
        evaluator = get_evaluator()
        
        result = evaluator.evaluate_student_best_of_two(student_id, dataset)
        
        if result:
            evaluator.save_result(result)
            safe_print(f"   âœ… å­¦ç”Ÿ{student_id}è¯„ä¼°å®Œæˆ: Gain={result['best_learning_gain']*100:.1f}%")
            return result
        else:
            safe_print(f"   âŒ å­¦ç”Ÿ{student_id}è¯„ä¼°å¤±è´¥")
            return None
            
    except Exception as e:
        safe_print(f"   âŒ å­¦ç”Ÿ{student_id}å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def run_batch_evaluation(student_ids, dataset='assist2017', max_workers=10):
    """
    æ‰¹é‡è¿è¡ŒTASAè¯„ä¼°
    
    Args:
        student_ids: å­¦ç”ŸIDåˆ—è¡¨
        dataset: æ•°æ®é›†åç§°
        max_workers: æœ€å¤§å¹¶è¡Œworkeræ•°
    """
    print("="*80)
    print(f"ğŸš€ TASAæ‰¹é‡è¯„ä¼°å¯åŠ¨")
    print("="*80)
    print(f"   æ•°æ®é›†: {dataset}")
    print(f"   å­¦ç”Ÿæ•°: {len(student_ids)}")
    print(f"   å¹¶è¡Œåº¦: {max_workers} workers")
    print(f"   ç­–ç•¥: Best-of-2 (æ¯ä¸ªå­¦ç”Ÿ2æ¬¡ï¼Œé€‰æœ€å¥½)")
    print(f"   æ¨¡å¼: å¹¶è¡Œå¤„ç†ï¼ˆè‡ªåŠ¨ç”Ÿæˆç¼ºå¤±çš„dialogueï¼‰")
    print("="*80)
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
    all_results = []
    completed = 0
    failed = 0
    
    print(f"\n{'='*80}")
    print(f"ğŸ”„ å¼€å§‹æ‰¹é‡å¤„ç† ({max_workers}ä¸ªå¹¶è¡Œworker)")
    print(f"   æŠ€æœ¯: çº¿ç¨‹æœ¬åœ°å­˜å‚¨ + é”ä¿æŠ¤åˆå§‹åŒ–")
    print(f"   ä¼˜åŠ¿: æ”¯æŒå¹¶è¡Œä½†é¿å…æ¨¡å‹åˆå§‹åŒ–å†²çª")
    print(f"{'='*80}\n")
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡ï¼ˆä¸ä¼ é€’å…±äº«çš„å¯¹è±¡ï¼Œè®©æ¯ä¸ªworkerè‡ªå·±åˆå§‹åŒ–ï¼‰
        future_to_student = {
            executor.submit(process_single_student, student_id, dataset): student_id
            for student_id in student_ids
        }
        
        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(future_to_student):
            student_id = future_to_student[future]
            
            try:
                result = future.result()
                if result:
                    all_results.append(result)
                    completed += 1
                else:
                    failed += 1
                
                # æ˜¾ç¤ºè¿›åº¦
                total_processed = completed + failed
                progress = total_processed / len(student_ids) * 100
                elapsed = time.time() - start_time
                avg_time = elapsed / total_processed if total_processed > 0 else 0
                eta = avg_time * (len(student_ids) - total_processed)
                
                with print_lock:
                    print(f"\n{'â”€'*80}")
                    print(f"ğŸ“ˆ è¿›åº¦: {total_processed}/{len(student_ids)} ({progress:.1f}%) | "
                          f"æˆåŠŸ: {completed} | å¤±è´¥: {failed}")
                    print(f"â±ï¸  å·²ç”¨æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ | é¢„è®¡å‰©ä½™: {eta/60:.1f}åˆ†é’Ÿ")
                    print(f"{'â”€'*80}")
                
            except Exception as e:
                failed += 1
                with print_lock:
                    print(f"\nâŒ å­¦ç”Ÿ{student_id}å¤„ç†å¼‚å¸¸: {e}")
    
    # æ€»ç»“
    total_time = time.time() - start_time
    
    print(f"\n{'='*80}")
    print(f"âœ… æ‰¹é‡è¯„ä¼°å®Œæˆï¼")
    print(f"{'='*80}")
    print(f"   æ€»å­¦ç”Ÿæ•°: {len(student_ids)}")
    print(f"   æˆåŠŸ: {completed}")
    print(f"   å¤±è´¥: {failed}")
    print(f"   æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ ({total_time/3600:.2f}å°æ—¶)")
    print(f"   å¹³å‡æ¯ä¸ªå­¦ç”Ÿ: {total_time/len(student_ids):.1f}ç§’")
    
    # ç”Ÿæˆç»Ÿè®¡
    if all_results:
        generate_overall_stats(all_results, dataset)
    
    return all_results

def generate_overall_stats(results, dataset):
    """ç”Ÿæˆæ•´ä½“ç»Ÿè®¡"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š ç”Ÿæˆæ•´ä½“ç»Ÿè®¡")
    print(f"{'='*80}")
    
    # è®¡ç®—ç»Ÿè®¡é‡
    learning_gains = [r['best_learning_gain'] for r in results]
    improvements = [r['best_improvement'] for r in results]
    
    avg_gain = np.mean(learning_gains)
    std_gain = np.std(learning_gains, ddof=1) if len(learning_gains) > 1 else 0
    median_gain = np.median(learning_gains)
    
    avg_improvement = np.mean(improvements)
    
    # æŒ‰æ°´å¹³åˆ†ç»„
    struggling = [r for r in results if r['pre_test_accuracy'] < 0.4]
    developing = [r for r in results if 0.4 <= r['pre_test_accuracy'] < 0.6]
    competent = [r for r in results if 0.6 <= r['pre_test_accuracy'] < 0.8]
    strong = [r for r in results if r['pre_test_accuracy'] >= 0.8]
    
    overall_stats = {
        "dataset": dataset,
        "num_students": len(results),
        "method": "TASA-best-of-2",
        "overall": {
            "avg_learning_gain": avg_gain,
            "std_learning_gain": std_gain,
            "median_learning_gain": median_gain,
            "avg_improvement": avg_improvement,
            "min_gain": min(learning_gains),
            "max_gain": max(learning_gains)
        },
        "by_level": {
            "struggling": {
                "count": len(struggling),
                "avg_gain": np.mean([r['best_learning_gain'] for r in struggling]) if struggling else 0,
                "avg_pre_test": np.mean([r['pre_test_accuracy'] for r in struggling]) if struggling else 0
            },
            "developing": {
                "count": len(developing),
                "avg_gain": np.mean([r['best_learning_gain'] for r in developing]) if developing else 0,
                "avg_pre_test": np.mean([r['pre_test_accuracy'] for r in developing]) if developing else 0
            },
            "competent": {
                "count": len(competent),
                "avg_gain": np.mean([r['best_learning_gain'] for r in competent]) if competent else 0,
                "avg_pre_test": np.mean([r['pre_test_accuracy'] for r in competent]) if competent else 0
            },
            "strong": {
                "count": len(strong),
                "avg_gain": np.mean([r['best_learning_gain'] for r in strong]) if strong else 0,
                "avg_pre_test": np.mean([r['pre_test_accuracy'] for r in strong]) if strong else 0
            }
        },
        "students": results
    }
    
    # ä¿å­˜ï¼ˆä½¿ç”¨backbone suffixåŒºåˆ†ä¸åŒLLMï¼Œä½¿ç”¨FS_METHODåŒºåˆ†ä¸åŒé—å¿˜æ›²çº¿æ–¹æ³•ï¼‰
    from tasa_config import FORGETTING_SCORE_METHOD
    backbone_suffix = get_backbone_suffix()
    output_dir = f"/mnt/localssd/bank/evaluation_results/TASA{backbone_suffix}-best-of-2/{dataset}/{FORGETTING_SCORE_METHOD}"
    os.makedirs(output_dir, exist_ok=True)
    output_file = f"{output_dir}/overall.json"
    
    with open(output_file, 'w') as f:
        json.dump(overall_stats, f, indent=2)
    
    print(f"\nğŸ“Š æ•´ä½“ç»Ÿè®¡:")
    print(f"   å­¦ç”Ÿæ•°: {len(results)}")
    print(f"   å¹³å‡Learning Gain: {avg_gain*100:.1f}% Â± {std_gain*100:.1f}%")
    print(f"   ä¸­ä½æ•°: {median_gain*100:.1f}%")
    print(f"   èŒƒå›´: [{min(learning_gains)*100:.1f}%, {max(learning_gains)*100:.1f}%]")
    
    print(f"\n   æŒ‰æ°´å¹³åˆ†ç»„:")
    print(f"      Struggling (<40%): {len(struggling)}äºº, å¹³å‡Gain={np.mean([r['best_learning_gain'] for r in struggling])*100:.1f}%" if struggling else "      Struggling: 0äºº")
    print(f"      Developing (40-60%): {len(developing)}äºº, å¹³å‡Gain={np.mean([r['best_learning_gain'] for r in developing])*100:.1f}%" if developing else "      Developing: 0äºº")
    print(f"      Competent (60-80%): {len(competent)}äºº, å¹³å‡Gain={np.mean([r['best_learning_gain'] for r in competent])*100:.1f}%" if competent else "      Competent: 0äºº")
    print(f"      Strong (â‰¥80%): {len(strong)}äºº, å¹³å‡Gain={np.mean([r['best_learning_gain'] for r in strong])*100:.1f}%" if strong else "      Strong: 0äºº")
    
    print(f"\nğŸ’¾ æ•´ä½“ç»Ÿè®¡å·²ä¿å­˜è‡³: {output_file}")
    
    return overall_stats

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='TASAæ‰¹é‡è¯„ä¼° - Best-of-2')
    parser.add_argument('--dataset', type=str, default='assist2017', help='æ•°æ®é›†')
    parser.add_argument('--num-students', type=int, default=9, help='æµ‹è¯•å­¦ç”Ÿæ•°é‡')
    parser.add_argument('--max-workers', type=int, default=10, help='æœ€å¤§å¹¶è¡Œworkeræ•°')
    parser.add_argument('--all', action='store_true', help='è¯„ä¼°æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„å­¦ç”Ÿ')
    parser.add_argument('--students-file', type=str, help='ç›´æ¥æŒ‡å®šå­¦ç”Ÿåˆ—è¡¨æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--filtered', action='store_true', help='ä½¿ç”¨è¿‡æ»¤åçš„åˆ—è¡¨ï¼ˆæ’é™¤Pre-test=100%ï¼‰')
    parser.add_argument('--lt60', action='store_true', help='ä½¿ç”¨<60%è¿‡æ»¤ï¼ˆæ’é™¤Pre-testâ‰¥60%ï¼‰')
    parser.add_argument('--range20to60', action='store_true', help='ä½¿ç”¨20%-60%è¿‡æ»¤ï¼ˆä»…ä¿ç•™Pre-teståœ¨20%-60%ï¼‰')
    
    args = parser.parse_args()
    
    # é€‰æ‹©å­¦ç”Ÿåˆ—è¡¨æ–‡ä»¶ï¼ˆä¼˜å…ˆçº§ï¼šstudents-file > range20to60 > lt60 > filtered > å®Œæ•´ï¼‰
    if args.students_file:
        list_file = args.students_file
        print(f"ğŸ“‹ ä½¿ç”¨æŒ‡å®šçš„å­¦ç”Ÿåˆ—è¡¨: {list_file}")
    elif args.range20to60:
        list_file = '/mnt/localssd/qualified_students_20to60.json'
        print(f"ğŸ“‹ ä½¿ç”¨20%-60%è¿‡æ»¤çš„å­¦ç”Ÿåˆ—è¡¨ï¼ˆPre-teståœ¨20%-60%ä¹‹é—´ï¼‰")
    elif args.lt60:
        list_file = '/mnt/localssd/qualified_students_lt60.json'
        print(f"ğŸ“‹ ä½¿ç”¨<60%è¿‡æ»¤çš„å­¦ç”Ÿåˆ—è¡¨ï¼ˆæ’é™¤Pre-testâ‰¥60%ï¼‰")
    elif args.filtered:
        list_file = '/mnt/localssd/qualified_students_filtered.json'
        print(f"ğŸ“‹ ä½¿ç”¨è¿‡æ»¤åçš„å­¦ç”Ÿåˆ—è¡¨ï¼ˆæ’é™¤Pre-test=100%ï¼‰")
    else:
        list_file = '/mnt/localssd/qualified_students_list.json'
        print(f"ğŸ“‹ ä½¿ç”¨å®Œæ•´çš„å­¦ç”Ÿåˆ—è¡¨")
    
    # åŠ è½½ç¬¦åˆæ¡ä»¶çš„å­¦ç”Ÿåˆ—è¡¨
    with open(list_file) as f:
        qualified_data = json.load(f)
    
    # æ”¯æŒä¸åŒçš„é”®åæ ¼å¼
    if 'sampled_students' in qualified_data:
        # æ–°æ ¼å¼ï¼šé‡‡æ ·åçš„å­¦ç”ŸIDåˆ—è¡¨
        all_student_ids = qualified_data['sampled_students']
    elif 'students' in qualified_data:
        # æ—§æ ¼å¼ï¼šå®Œæ•´çš„å­¦ç”Ÿå¯¹è±¡åˆ—è¡¨
        all_student_ids = [s['student_id'] for s in qualified_data['students']]
    else:
        raise ValueError(f"Invalid student file format. Expected 'students' or 'sampled_students' key.")
    
    if args.all:
        student_ids = all_student_ids
    else:
        student_ids = all_student_ids[:args.num_students]
    
    total_count = qualified_data.get('total_students') or qualified_data.get('filtered_count') or qualified_data.get('qualified_count') or len(all_student_ids)
    print(f"\nå°†è¯„ä¼° {len(student_ids)} ä¸ªå­¦ç”Ÿï¼ˆå…±{total_count}ä¸ªç¬¦åˆæ¡ä»¶ï¼‰")
    
    # è¿è¡Œæ‰¹é‡è¯„ä¼°
    results = run_batch_evaluation(
        student_ids=student_ids,
        dataset=args.dataset,
        max_workers=args.max_workers
    )
    
    print(f"\n{'='*80}")
    print(f"âœ… å…¨éƒ¨å®Œæˆï¼")
    print(f"{'='*80}")

