#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é‡æ–°è®¡ç®— embeddings
ä»ç°æœ‰ JSON è¯»å–æ•°æ®ï¼Œè®¡ç®— embeddingsï¼Œä¿å­˜åˆ° .npz
"""

import os
import json
import numpy as np
from tqdm import tqdm
import argparse

try:
    from FlagEmbedding import BGEM3FlagModel
except ImportError:
    from FlagEmbedding import FlagModel as BGEM3FlagModel


def load_bge_model():
    """åŠ è½½ BGE æ¨¡å‹"""
    print("ğŸ¤– åˆå§‹åŒ–BGEæ¨¡å‹...")
    model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)
    print("  âœ… BGEæ¨¡å‹åŠ è½½å®Œæˆ")
    return model


def generate_embeddings_batch(texts, model):
    """æ‰¹é‡ç”Ÿæˆembeddingsï¼ˆä¸create_student_bank_final.pyä¿æŒä¸€è‡´ï¼‰"""
    if not texts:
        return np.zeros((0, 1024), dtype=np.float16)
    
    try:
        # ç¡®ä¿æ‰€æœ‰æ–‡æœ¬éƒ½æ˜¯å­—ç¬¦ä¸²
        texts = [str(t) if t is not None else "" for t in texts]
        # æ—§ç‰ˆFlagModel (v1.1.6) çš„encode()æ–¹æ³•ä¸æ¥å—return_denseç­‰å‚æ•°
        # ç›´æ¥è°ƒç”¨encodeä¼šè¿”å›dense embeddings
        result = model.encode(texts, batch_size=min(32, len(texts)))
        
        # ç¡®ä¿è¿”å›çš„æ˜¯numpyæ•°ç»„
        if isinstance(result, dict):
            # å¦‚æœè¿”å›çš„æ˜¯å­—å…¸ï¼Œå°è¯•è·å–'dense' embeddings
            result = result.get('dense', result.get('embeddings', result))
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶ç¡®ä¿æ˜¯float16ç±»å‹
        result = np.array(result, dtype=np.float16)
        return result
    except Exception as e:
        print(f"  âš ï¸  Embeddingç”Ÿæˆå¤±è´¥: {e}, è¿”å›é›¶å‘é‡")
        # è¿”å›é›¶å‘é‡ä½œä¸ºfallback
        return np.zeros((len(texts), 1024), dtype=np.float16)


def process_file(filepath, data_type, dataset_name, bge_model):
    """
    å¤„ç†å•ä¸ªæ–‡ä»¶ï¼š
    1. è¯»å– JSON
    2. æå– description å’Œ keywords
    3. ç”Ÿæˆ embeddings
    4. ä¿å­˜åˆ° .npz
    """
    student_id = os.path.basename(filepath).replace('.json', '')
    
    try:
        # 1. è¯»å– JSON
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if not data:
            return False
        
        # 2. æå–æ–‡æœ¬ï¼ˆç¡®ä¿æ˜¯å­—ç¬¦ä¸²ï¼‰
        descriptions = []
        keywords_list = []
        
        for item in data:
            desc = item.get('description', '')
            kw = item.get('keywords', item.get('concept_text', ''))
            
            # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
            descriptions.append(str(desc) if desc else '')
            keywords_list.append(str(kw) if kw else '')
        
        # 3. ç”Ÿæˆ embeddings
        desc_embeddings = generate_embeddings_batch(descriptions, bge_model)
        kw_embeddings = generate_embeddings_batch(keywords_list, bge_model)
        
        if desc_embeddings is None or kw_embeddings is None:
            return False
        
        # 4. ä¿å­˜åˆ° .npz
        emb_dir = f'/mnt/localssd/bank/{data_type}/{dataset_name}/embeddings'
        os.makedirs(emb_dir, exist_ok=True)
        
        # ä¿å­˜description embeddings
        desc_emb_file = os.path.join(emb_dir, f'{student_id}_description.npz')
        np.savez_compressed(desc_emb_file, embeddings=desc_embeddings)
        
        # ä¿å­˜keywords embeddings  
        key_emb_file = os.path.join(emb_dir, f'{student_id}_keywords.npz')
        np.savez_compressed(key_emb_file, embeddings=kw_embeddings)
        
        return True
        
    except Exception as e:
        print(f"  âš ï¸  å¤„ç†å¤±è´¥ {filepath}: {e}")
        return False


def process_dataset(dataset_name, data_type, bge_model):
    """å¤„ç†æ•´ä¸ªæ•°æ®é›†"""
    data_dir = f'/mnt/localssd/bank/{data_type}/{dataset_name}/data'
    
    if not os.path.exists(data_dir):
        print(f"  âš ï¸  ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return 0
    
    files = sorted([f for f in os.listdir(data_dir) if f.endswith('.json')])
    
    print(f"  å¤„ç† {len(files)} ä¸ªæ–‡ä»¶...")
    success_count = 0
    failed_count = 0
    
    for filename in tqdm(files, desc=f"{dataset_name} {data_type}"):
        filepath = os.path.join(data_dir, filename)
        if process_file(filepath, data_type, dataset_name, bge_model):
            success_count += 1
        else:
            failed_count += 1
    
    if failed_count > 0:
        print(f"  âš ï¸  å¤±è´¥: {failed_count} ä¸ªæ–‡ä»¶")
    
    return success_count


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--dataset', type=str, default='nips_task34',
                       help='æ•°æ®é›†åç§°')
    parser.add_argument('--type', type=str, choices=['memory', 'persona', 'both'],
                       default='both', help='å¤„ç†ç±»å‹')
    args = parser.parse_args()
    
    print("=" * 100)
    print(f"é‡æ–°è®¡ç®— Embeddings - {args.dataset}")
    print("=" * 100)
    print()
    
    # åŠ è½½ BGE æ¨¡å‹
    bge_model = load_bge_model()
    print()
    
    total_success = 0
    
    if args.type in ['persona', 'both']:
        print(f"ğŸ‘¤ å¤„ç† Persona:")
        count = process_dataset(args.dataset, 'persona', bge_model)
        print(f"  âœ… æˆåŠŸå¤„ç† {count} ä¸ªæ–‡ä»¶")
        total_success += count
        print()
    
    if args.type in ['memory', 'both']:
        print(f"ğŸ“ å¤„ç† Memory:")
        count = process_dataset(args.dataset, 'memory', bge_model)
        print(f"  âœ… æˆåŠŸå¤„ç† {count} ä¸ªæ–‡ä»¶")
        total_success += count
        print()
    
    print("=" * 100)
    print(f"âœ… å®Œæˆï¼æ€»å…±å¤„ç†äº† {total_success} ä¸ªæ–‡ä»¶")
    print("=" * 100)


if __name__ == '__main__':
    main()
