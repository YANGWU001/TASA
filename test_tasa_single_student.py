#!/usr/bin/env python3
"""
æµ‹è¯•å•ä¸ªå­¦ç”Ÿçš„å®Œæ•´TASAæµç¨‹
"""

import json
import sys
from student_roleplay_evaluation import build_student_system_prompt, load_session

# ç¡®ä¿å¯¼å…¥è·¯å¾„æ­£ç¡®
sys.path.insert(0, '/mnt/localssd')

from tasa_config import *
from tasa_tutoring import TASATutor
from tasa_evaluation import TASAEvaluator

def test_single_student(student_id: int = 1, dataset: str = "assist2017"):
    """
    æµ‹è¯•å•ä¸ªå­¦ç”Ÿçš„å®Œæ•´TASAæµç¨‹
    """
    print("="*80)
    print(f"ğŸ§ª æµ‹è¯•TASAæµç¨‹ - å­¦ç”Ÿ {student_id}")
    print("="*80)
    
    # Step 1: åŠ è½½å­¦ç”Ÿsession
    print(f"\nğŸ“‚ Step 1: åŠ è½½å­¦ç”Ÿæ•°æ®")
    session_file = f'{SESSION_DIR}/{dataset}/{student_id}.json'
    session = load_session(session_file)
    
    concept_text = session['concept_text']
    concept_id = str(session['concept_id'])
    
    print(f"   å­¦ç”ŸID: {student_id}")
    print(f"   Concept: {concept_text} (ID: {concept_id})")
    print(f"   å†å²å‡†ç¡®ç‡: {session['persona']['stats']['correct']/session['persona']['stats']['total']*100:.1f}%")
    
    # Step 2: æ„å»ºå­¦ç”Ÿçš„system prompt
    print(f"\nğŸ­ Step 2: æ„å»ºå­¦ç”ŸRole-play Prompt")
    student_prompt = build_student_system_prompt(session)
    print(f"   âœ… Student promptå·²ç”Ÿæˆ")
    
    # Step 3: åˆå§‹åŒ–Tutorå¹¶è¿›è¡ŒTutoring
    print(f"\nğŸ“ Step 3: è¿›è¡ŒTutoring Session (10è½®)")
    tutor = TASATutor()
    
    try:
        dialogue = tutor.conduct_tutoring_session(
            student_id=student_id,
            dataset=dataset,
            concept_text=concept_text,
            student_system_prompt=student_prompt
        )
        
        # ä¿å­˜å¯¹è¯
        dialogue_file = tutor.save_dialogue(dialogue, student_id, concept_text, dataset)
        
        print(f"\nâœ… Tutoringå®Œæˆï¼")
        print(f"   å¯¹è¯è½®æ•°: {len([m for m in dialogue if m['role']=='assistant'])}è½®")
        print(f"   æ€»æ¶ˆæ¯æ•°: {len(dialogue)}æ¡")
        
    except Exception as e:
        print(f"\nâŒ Tutoringå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    # Step 4: åŠ è½½æµ‹è¯•é¢˜ç›®
    print(f"\nğŸ“ Step 4: å‡†å¤‡Post-test")
    questions_file = f'/mnt/localssd/bank/test_data/{dataset}/concept_questions.json'
    
    with open(questions_file) as f:
        all_questions = json.load(f)
    
    concept_data = all_questions.get(concept_id, {})
    questions = concept_data.get('questions', [])
    
    if not questions:
        print(f"   âŒ æœªæ‰¾åˆ°concept {concept_id} çš„é¢˜ç›®")
        return None
    
    print(f"   âœ… æ‰¾åˆ° {len(questions)} é“é¢˜ç›®")
    
    # Step 5: è¿›è¡ŒPost-testè¯„ä¼°
    print(f"\nğŸ“Š Step 5: è¿›è¡ŒPost-testè¯„ä¼°")
    evaluator = TASAEvaluator()
    
    try:
        result = evaluator.evaluate_single_student(
            student_id=student_id,
            dataset=dataset,
            concept_text=concept_text,
            concept_id=concept_id,
            questions=questions,
            student_system_prompt=student_prompt
        )
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        eval_file = evaluator.save_evaluation_result(result, method="TASA")
        
        # Step 6: æ˜¾ç¤ºç»“æœ
        print(f"\n{'='*80}")
        print(f"âœ… TASAæµ‹è¯•å®Œæˆï¼")
        print(f"{'='*80}")
        
        print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
        print(f"   Pre-test (æ— æ•™å­¦):  {result['pre_test_accuracy']*100:.1f}%")
        print(f"   Post-test (æœ‰æ•™å­¦): {result['post_test_accuracy']*100:.1f}%")
        print(f"   ç»å¯¹æå‡:          {result['improvement']*100:+.1f}%")
        print(f"   Learning Gain:     {result['learning_gain']:.3f}")
        
        if result['learning_gain'] <= 0:
            print(f"\nâš ï¸  æ³¨æ„: Learning Gain â‰¤ 0ï¼Œè¯´æ˜æ•™å­¦æ²¡æœ‰å¸¦æ¥æå‡ï¼")
        
        print(f"\nğŸ’¾ æ–‡ä»¶å·²ä¿å­˜:")
        print(f"   å¯¹è¯: {dialogue_file}")
        print(f"   è¯„ä¼°: {eval_file}")
        
        print(f"\n{'='*80}")
        
        return result
        
    except Exception as e:
        print(f"\nâŒ Post-testå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='æµ‹è¯•å•ä¸ªå­¦ç”Ÿçš„TASAæµç¨‹')
    parser.add_argument('--student-id', type=int, default=1, help='å­¦ç”ŸID')
    parser.add_argument('--dataset', type=str, default='assist2017', help='æ•°æ®é›†åç§°')
    
    args = parser.parse_args()
    
    result = test_single_student(
        student_id=args.student_id,
        dataset=args.dataset
    )
    
    if result:
        print("\nâœ… æµ‹è¯•æˆåŠŸå®Œæˆï¼")
        sys.exit(0)
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥")
        sys.exit(1)

